{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654b235f",
   "metadata": {},
   "source": [
    "## 1. 임베딩 & Qdrant 업서트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c307f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loaded model: bge-ko (dragonkue/bge-m3-ko), dim=1024\n",
      "[INFO] Loaded corpus: 2292 chunks\n",
      "[INFO] Using existing collection: audit_chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting (bge-ko): 100%|██████████| 36/36 [00:18<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Upsert done: 2292 → DB path=/Users/dan/Desktop/snu_project/git_제출용/data/vector_store/final-sjchunk/bge-ko-qdrant_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models as qmodels\n",
    "\n",
    "# ===== 모델 매핑 =====\n",
    "MODEL_NAME = \"bge-ko\"   # ← 여기만 바꿔주면 됨 (\"e5\", \"koe5\", \"bge-ko\", \"bge-m3\", \"kure\")\n",
    "\n",
    "MODEL_MAP = {\n",
    "    \"e5\": \"intfloat/multilingual-e5-small\",\n",
    "    \"e5-base\": \"intfloat/multilingual-e5-base\",\n",
    "    \"koe5\": \"intfloat/KoE5-large\",\n",
    "    \"bge-ko\": \"dragonkue/bge-m3-ko\",\n",
    "    \"bge-m3\": \"BAAI/bge-m3\",\n",
    "    \"kure\": \"nlpai-lab/KURE-v1\",\n",
    "}\n",
    "\n",
    "EMBED_MODEL_NAME = MODEL_MAP[MODEL_NAME]\n",
    "COLLECTION       = \"audit_chunks\"\n",
    "BATCH            = 64\n",
    "QDRANT_PATH = f\"/Users/dan/Desktop/snu_project/git_제출용/data/vector_store/final-sjchunk/{MODEL_NAME}-qdrant_db\"\n",
    "CHUNK_FILE = Path(\"/Users/dan/Desktop/snu_project/git_제출용/data/processed/enhanced_vector_chunks_9_24.jsonl\")\n",
    "\n",
    "# 토크나이저 포크 경고 끄기 (권장)\n",
    "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
    "\n",
    "# ===== 디바이스 선택 (MPS > CUDA > CPU) =====\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"[INFO] Using device: {device}\")\n",
    "\n",
    "# ===== 모델 로드 =====\n",
    "model = SentenceTransformer(EMBED_MODEL_NAME, device=device)\n",
    "dim = model.get_sentence_embedding_dimension()\n",
    "print(f\"[INFO] Loaded model: {MODEL_NAME} ({EMBED_MODEL_NAME}), dim={dim}\")\n",
    "\n",
    "# ===== corpus 로드 =====\n",
    "assert CHUNK_FILE.exists(), f\"청킹 파일을 찾을 수 없습니다: {CHUNK_FILE}\"\n",
    "\n",
    "corpus = []\n",
    "with open(CHUNK_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        corpus.append(json.loads(line))\n",
    "\n",
    "print(f\"[INFO] Loaded corpus: {len(corpus)} chunks\")\n",
    "\n",
    "client = None\n",
    "try:\n",
    "    # ===== Qdrant 연결 (임베디드 모드) =====\n",
    "    client = QdrantClient(path=QDRANT_PATH)\n",
    "\n",
    "    # 컬렉션 생성 (존재하지 않을 때만)\n",
    "    if not client.collection_exists(COLLECTION):\n",
    "        client.create_collection(\n",
    "            collection_name=COLLECTION,\n",
    "            vectors_config=qmodels.VectorParams(\n",
    "                size=dim,\n",
    "                distance=qmodels.Distance.COSINE\n",
    "            ),\n",
    "            optimizers_config=qmodels.OptimizersConfigDiff(indexing_threshold=20000),\n",
    "            hnsw_config=qmodels.HnswConfigDiff(m=32, ef_construct=256),\n",
    "        )\n",
    "        print(f\"[INFO] Created collection: {COLLECTION}\")\n",
    "    else:\n",
    "        print(f\"[INFO] Using existing collection: {COLLECTION}\")\n",
    "\n",
    "    # ===== 업서트 =====\n",
    "    pending_points = []\n",
    "    for i in tqdm(range(0, len(corpus), BATCH), desc=f\"Upserting ({MODEL_NAME})\"):\n",
    "        batch = corpus[i:i+BATCH]\n",
    "        texts = [x[\"text\"] for x in batch]\n",
    "\n",
    "        vecs = model.encode(\n",
    "            texts,\n",
    "            normalize_embeddings=True,\n",
    "            convert_to_numpy=True,\n",
    "            show_progress_bar=False,\n",
    "            batch_size=BATCH,\n",
    "        ).astype(\"float32\")\n",
    "\n",
    "        pending_points.clear()\n",
    "        for x, v in zip(batch, vecs):\n",
    "            pid = str(uuid.uuid4())   # ✅ 무조건 올바른 UUID 생성\n",
    "            payload = {**x.get(\"metadata\", {}), \"text\": x[\"text\"]}\n",
    "            pending_points.append(\n",
    "                qmodels.PointStruct(id=pid, vector=v.tolist(), payload=payload)\n",
    "            )\n",
    "\n",
    "\n",
    "        client.upsert(collection_name=COLLECTION, points=pending_points, wait=False)\n",
    "\n",
    "    try:\n",
    "        client.update_collection(\n",
    "            collection_name=COLLECTION,\n",
    "            hnsw_config=qmodels.HnswConfigDiff(ef_construct=256),\n",
    "            optimizers_config=qmodels.OptimizersConfigDiff(default_segment_number=4),\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(f\"[INFO] Upsert done: {len(corpus)} → DB path={QDRANT_PATH}\")\n",
    "\n",
    "finally:\n",
    "    if client is not None:\n",
    "        try:\n",
    "            client.close()\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a07f17",
   "metadata": {},
   "source": [
    "## 2. Retriever 성능 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a34639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "질문: 2014년 재무상태표 상 당기 유동자산은 얼마인가?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 재무상태표에서 2014년 (당기) 유동자산는 62,054,773백만원입니다.\n",
      "   출처: 2014년, (score=0.8690)\n",
      "\n",
      "2위: 재무상태표에서 2014년 (당기) 유동자산는 62,054,773백만원입니다.\n",
      "   출처: 2014년, (score=0.8690)\n",
      "\n",
      "3위: 재무상태표에서 2014년 (당기) 유동자산는 62,054,773백만원입니다.\n",
      "   출처: 2014년, (score=0.8690)\n",
      "\n",
      "\n",
      "[정답]\n",
      "62,054,773\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2014년 현금흐름표 상 당기 영업활동 현금흐름은 얼마인가?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 현금흐름표에서 2014년 (당기) 영업활동현금흐름는 18,653,817백만원입니다.\n",
      "   출처: 2014년, (score=0.8249)\n",
      "\n",
      "2위: 현금흐름표에서 2014년 (당기) 영업활동현금흐름는 18,653,817백만원입니다.\n",
      "   출처: 2014년, (score=0.8249)\n",
      "\n",
      "3위: 현금흐름표에서 2014년 (당기) 영업활동현금흐름는 18,653,817백만원입니다.\n",
      "   출처: 2014년, (score=0.8249)\n",
      "\n",
      "\n",
      "[정답]\n",
      "18,653,817\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2015년 당기 비유동자산은 재무상태표에서 얼마인가?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 재무상태표에서 2015년 (당기) 비유동자산는 101,967,575백만원입니다.\n",
      "   출처: 2015년, (score=0.8659)\n",
      "\n",
      "2위: 재무상태표에서 2015년 (당기) 비유동자산는 101,967,575백만원입니다.\n",
      "   출처: 2015년, (score=0.8659)\n",
      "\n",
      "3위: 재무상태표에서 2015년 (당기) 비유동자산는 101,967,575백만원입니다.\n",
      "   출처: 2015년, (score=0.8659)\n",
      "\n",
      "\n",
      "[정답]\n",
      "101,967,575\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2015년 손익계산서 상 당기순이익은 얼마인가?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 손익계산서에서 2015년 (당기) 당기순이익는 12,238,469백만원입니다.\n",
      "   출처: 2015년, (score=0.8365)\n",
      "\n",
      "2위: 손익계산서에서 2015년 (당기) 당기순이익는 12,238,469백만원입니다.\n",
      "   출처: 2015년, (score=0.8365)\n",
      "\n",
      "3위: 손익계산서에서 2015년 (당기) 당기순이익는 12,238,469백만원입니다.\n",
      "   출처: 2015년, (score=0.8365)\n",
      "\n",
      "\n",
      "[정답]\n",
      "12,238,469\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2016년 재무상태표 상 당기 단기금융상품은 얼마인가요?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 재무상태표에서 2016년 (당기) 단기금융상품는 30,170,656백만원입니다. 주석: 5, 6, 7, 31\n",
      "   출처: 2016년, (score=0.8399)\n",
      "\n",
      "2위: 재무상태표에서 2016년 (당기) 단기금융상품는 30,170,656백만원입니다. 주석: 5, 6, 7, 31\n",
      "   출처: 2016년, (score=0.8399)\n",
      "\n",
      "3위: 재무상태표에서 2016년 (당기) 단기금융상품는 30,170,656백만원입니다. 주석: 5, 6, 7, 31\n",
      "   출처: 2016년, (score=0.8399)\n",
      "\n",
      "\n",
      "[정답]\n",
      "30,170,656\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2016년 포괄손익계산서 상 당기 총포괄이익은 얼마니?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 포괄손익계산서에서 2016년 (당기) 총포괄이익는 11,887,806백만원입니다.\n",
      "   출처: 2016년, (score=0.8544)\n",
      "\n",
      "2위: 포괄손익계산서에서 2016년 (당기) 총포괄이익는 11,887,806백만원입니다.\n",
      "   출처: 2016년, (score=0.8544)\n",
      "\n",
      "3위: 포괄손익계산서에서 2016년 (당기) 총포괄이익는 11,887,806백만원입니다.\n",
      "   출처: 2016년, (score=0.8544)\n",
      "\n",
      "\n",
      "[정답]\n",
      "11,887,806\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2016년 자본변동표 상 자기주식의 취득은 얼마인가?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 현금흐름표에서 2016년 (당기) 자기주식의취득는 -7,707,938백만원입니다.\n",
      "   출처: 2016년, (score=0.7548)\n",
      "\n",
      "2위: 현금흐름표에서 2016년 (당기) 자기주식의취득는 -7,707,938백만원입니다.\n",
      "   출처: 2016년, (score=0.7548)\n",
      "\n",
      "3위: 현금흐름표에서 2016년 (당기) 자기주식의취득는 -7,707,938백만원입니다.\n",
      "   출처: 2016년, (score=0.7548)\n",
      "\n",
      "\n",
      "[정답]\n",
      "(7,707,938)\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2017년 당기 매출채권은 재무상태표에 따르면 얼마냐?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 재무상태표에서 2017년 (당기) 매출채권는 27,881,777백만원입니다. 주석: 6, 7, 10, 31\n",
      "   출처: 2017년, (score=0.7888)\n",
      "\n",
      "2위: 재무상태표에서 2017년 (당기) 매출채권는 27,881,777백만원입니다. 주석: 6, 7, 10, 31\n",
      "   출처: 2017년, (score=0.7888)\n",
      "\n",
      "3위: 재무상태표에서 2017년 (당기) 매출채권는 27,881,777백만원입니다. 주석: 6, 7, 10, 31\n",
      "   출처: 2017년, (score=0.7888)\n",
      "\n",
      "\n",
      "[정답]\n",
      "27,881,777\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2017년 재무상태표상 전기 현금및현금성자산은 얼마입니까?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 재무상태표에서 2017년 (당기) 현금및현금성자산는 2,763,768백만원입니다. 주석: 4, 6, 7, 31\n",
      "   출처: 2017년, (score=0.7735)\n",
      "\n",
      "2위: 재무상태표에서 2017년 (당기) 현금및현금성자산는 2,763,768백만원입니다. 주석: 4, 6, 7, 31\n",
      "   출처: 2017년, (score=0.7735)\n",
      "\n",
      "3위: 재무상태표에서 2017년 (당기) 현금및현금성자산는 2,763,768백만원입니다. 주석: 4, 6, 7, 31\n",
      "   출처: 2017년, (score=0.7735)\n",
      "\n",
      "\n",
      "[정답]\n",
      "3,778,371\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.00, Recall@3=0.00, F1@3=0.00, nDCG@3=0.00, MRR=0.00\n",
      "====================================================================================================\n",
      "질문: 2018년 당기 미수금은 재무상태표에서 얼마인가?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 재무상태표에서 2018년 (당기) 미수금는 1,515,079백만원입니다.\n",
      "   출처: 2018년, (score=0.8794)\n",
      "\n",
      "2위: 재무상태표에서 2018년 (당기) 미수금는 1,515,079백만원입니다.\n",
      "   출처: 2018년, (score=0.8794)\n",
      "\n",
      "3위: 재무상태표에서 2018년 (당기) 미수금는 1,515,079백만원입니다.\n",
      "   출처: 2018년, (score=0.8794)\n",
      "\n",
      "\n",
      "[정답]\n",
      "1,515,079\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2018년 손익계산서상 매출총이익은 얼마인가요?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 손익계산서에서 2018년 (당기) 매출총이익는 68,715,364백만원입니다.\n",
      "   출처: 2018년, (score=0.8518)\n",
      "\n",
      "2위: 손익계산서에서 2018년 (당기) 매출총이익는 68,715,364백만원입니다.\n",
      "   출처: 2018년, (score=0.8518)\n",
      "\n",
      "3위: 손익계산서에서 2018년 (당기) 매출총이익는 68,715,364백만원입니다.\n",
      "   출처: 2018년, (score=0.8518)\n",
      "\n",
      "\n",
      "[정답]\n",
      "68,715,364\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2019년 재무상태표상 종속기업, 관계기업 및 공동기업 투자는 얼마인가요?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 재무상태표에서 2019년 (당기) 종속기업,관계기업및공동기업투자는 56,571,252백만원입니다.\n",
      "   출처: 2019년, (score=0.8636)\n",
      "\n",
      "2위: 재무상태표에서 2019년 (당기) 종속기업,관계기업및공동기업투자는 56,571,252백만원입니다.\n",
      "   출처: 2019년, (score=0.8636)\n",
      "\n",
      "3위: 재무상태표에서 2019년 (당기) 종속기업,관계기업및공동기업투자는 56,571,252백만원입니다.\n",
      "   출처: 2019년, (score=0.8636)\n",
      "\n",
      "\n",
      "[정답]\n",
      "56,571,252\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2019년 현금흐름표 상 이익잉여금 배당은 얼마인가요?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 현금흐름표에서 2019년 (당기) 배당금의지급는 -9,618,210백만원입니다.\n",
      "   출처: 2019년, (score=0.7412)\n",
      "\n",
      "2위: 현금흐름표에서 2019년 (당기) 배당금의지급는 -9,618,210백만원입니다.\n",
      "   출처: 2019년, (score=0.7412)\n",
      "\n",
      "3위: 현금흐름표에서 2019년 (당기) 배당금의지급는 -9,618,210백만원입니다.\n",
      "   출처: 2019년, (score=0.7412)\n",
      "\n",
      "\n",
      "[정답]\n",
      "(9,618,210)\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2019년 손익계산서상 기본주당이익은 얼마인가요?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 손익계산서에서 2019년 (당기) 기본주당이익(단위:원)는 2,260백만원입니다.\n",
      "   출처: 2019년, (score=0.8476)\n",
      "\n",
      "2위: 손익계산서에서 2019년 (당기) 기본주당이익(단위:원)는 2,260백만원입니다.\n",
      "   출처: 2019년, (score=0.8476)\n",
      "\n",
      "3위: 손익계산서에서 2019년 (당기) 기본주당이익(단위:원)는 2,260백만원입니다.\n",
      "   출처: 2019년, (score=0.8476)\n",
      "\n",
      "\n",
      "[정답]\n",
      "2,260\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2020년 재무상태표 상 자산총계는?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 재무상태표에서 2020년 (당기) 자산총계는 229,664,427백만원입니다.\n",
      "   출처: 2020년, (score=0.8454)\n",
      "\n",
      "2위: 재무상태표에서 2020년 (당기) 자산총계는 229,664,427백만원입니다.\n",
      "   출처: 2020년, (score=0.8454)\n",
      "\n",
      "3위: 재무상태표에서 2020년 (당기) 자산총계는 229,664,427백만원입니다.\n",
      "   출처: 2020년, (score=0.8454)\n",
      "\n",
      "\n",
      "[정답]\n",
      "229,664,427\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2020년 손익계산서 상 판매비와관리비는 얼마인가요?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 손익계산서에서 2020년 (당기) 판매비와관리비는 29,038,798백만원입니다.\n",
      "   출처: 2020년, (score=0.9002)\n",
      "\n",
      "2위: 손익계산서에서 2020년 (당기) 판매비와관리비는 29,038,798백만원입니다.\n",
      "   출처: 2020년, (score=0.9002)\n",
      "\n",
      "3위: 손익계산서에서 2020년 (당기) 판매비와관리비는 29,038,798백만원입니다.\n",
      "   출처: 2020년, (score=0.9002)\n",
      "\n",
      "\n",
      "[정답]\n",
      "29,038,798\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2021년 재무상태표상 당기 기타포괄손익-공정가치금융자산은 얼마인가요?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 재무상태표에서 2021년 (당기) 기타포괄손익-공정가치금융자산는 1,662,532백만원입니다. 주석: 4, 6, 28\n",
      "   출처: 2021년, (score=0.8443)\n",
      "\n",
      "2위: 재무상태표에서 2021년 (당기) 기타포괄손익-공정가치금융자산는 1,662,532백만원입니다. 주석: 4, 6, 28\n",
      "   출처: 2021년, (score=0.8443)\n",
      "\n",
      "3위: 재무상태표에서 2021년 (당기) 기타포괄손익-공정가치금융자산는 1,662,532백만원입니다. 주석: 4, 6, 28\n",
      "   출처: 2021년, (score=0.8443)\n",
      "\n",
      "\n",
      "[정답]\n",
      "1,662,532\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2021년 손익계산서 상 당기 금융비용은 얼마인가요?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 손익계산서에서 2021년 (당기) 금융비용는 3,698,675백만원입니다.\n",
      "   출처: 2021년, (score=0.8720)\n",
      "\n",
      "2위: 손익계산서에서 2021년 (당기) 금융비용는 3,698,675백만원입니다.\n",
      "   출처: 2021년, (score=0.8720)\n",
      "\n",
      "3위: 손익계산서에서 2021년 (당기) 금융비용는 3,698,675백만원입니다.\n",
      "   출처: 2021년, (score=0.8720)\n",
      "\n",
      "\n",
      "[정답]\n",
      "3,698,675\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2022년 재무상태표상 당기 비유동부채는 얼마인가?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 재무상태표에서 2022년 (당기) 비유동부채는 4,581,512백만원입니다.\n",
      "   출처: 2022년, (score=0.8602)\n",
      "\n",
      "2위: 재무상태표에서 2022년 (당기) 비유동부채는 4,581,512백만원입니다.\n",
      "   출처: 2022년, (score=0.8602)\n",
      "\n",
      "3위: 재무상태표에서 2022년 (당기) 비유동부채는 4,581,512백만원입니다.\n",
      "   출처: 2022년, (score=0.8602)\n",
      "\n",
      "\n",
      "[정답]\n",
      "4,581,512\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2022년 손익계산서 상 당기 법인세비용은 얼마니?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 손익계산서에서 2022년 (당기) 법인세비용는 4,273,142백만원입니다.\n",
      "   출처: 2022년, (score=0.8786)\n",
      "\n",
      "2위: 손익계산서에서 2022년 (당기) 법인세비용는 4,273,142백만원입니다.\n",
      "   출처: 2022년, (score=0.8786)\n",
      "\n",
      "3위: 손익계산서에서 2022년 (당기) 법인세비용는 4,273,142백만원입니다.\n",
      "   출처: 2022년, (score=0.8786)\n",
      "\n",
      "\n",
      "[정답]\n",
      "4,273,142\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2022년 당기 현금흐름표 상 투자활동 현금흐름은 얼마인가?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 현금흐름표에서 2022년 (당기) 투자활동현금흐름는 -28,123,886백만원입니다.\n",
      "   출처: 2022년, (score=0.8411)\n",
      "\n",
      "2위: 현금흐름표에서 2022년 (당기) 투자활동현금흐름는 -28,123,886백만원입니다.\n",
      "   출처: 2022년, (score=0.8411)\n",
      "\n",
      "3위: 현금흐름표에서 2022년 (당기) 투자활동현금흐름는 -28,123,886백만원입니다.\n",
      "   출처: 2022년, (score=0.8411)\n",
      "\n",
      "\n",
      "[정답]\n",
      "(28,123,886)\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2023년 재무상태표 상 재고자산은 얼마인가?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 재무상태표에서 2023년 (당기) 재고자산는 29,338,151백만원입니다. 주석: 8\n",
      "   출처: 2023년, (score=0.8332)\n",
      "\n",
      "2위: 재무상태표에서 2023년 (당기) 재고자산는 29,338,151백만원입니다. 주석: 8\n",
      "   출처: 2023년, (score=0.8332)\n",
      "\n",
      "3위: 재무상태표에서 2023년 (당기) 재고자산는 29,338,151백만원입니다. 주석: 8\n",
      "   출처: 2023년, (score=0.8332)\n",
      "\n",
      "\n",
      "[정답]\n",
      "29,338,151\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2023년 손익계산서 상 당기 영업이익은 얼마인가?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 손익계산서에서 2023년 (당기) 영업이익(손실)는 -11,526,297백만원입니다.\n",
      "   출처: 2023년, (score=0.8269)\n",
      "\n",
      "2위: 손익계산서에서 2023년 (당기) 영업이익(손실)는 -11,526,297백만원입니다.\n",
      "   출처: 2023년, (score=0.8269)\n",
      "\n",
      "3위: 손익계산서에서 2023년 (당기) 영업이익(손실)는 -11,526,297백만원입니다.\n",
      "   출처: 2023년, (score=0.8269)\n",
      "\n",
      "\n",
      "[정답]\n",
      "(11,526,297)\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2024년에는 재무상태표상 당기 무형자산이 얼마야?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 재무상태표에서 2024년 (당기) 무형자산는 10,496,956백만원입니다. 주석: 11\n",
      "   출처: 2024년, (score=0.7829)\n",
      "\n",
      "2위: 재무상태표에서 2024년 (당기) 무형자산는 10,496,956백만원입니다. 주석: 11\n",
      "   출처: 2024년, (score=0.7829)\n",
      "\n",
      "3위: 재무상태표에서 2024년 (당기) 무형자산는 10,496,956백만원입니다. 주석: 11\n",
      "   출처: 2024년, (score=0.7829)\n",
      "\n",
      "\n",
      "[정답]\n",
      "10,496,956\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2024년 재무상태표 상 당기 우선주자본금은 얼마인가?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 재무상태표에서 2024년 (당기) 우선주자본금는 119,467백만원입니다.\n",
      "   출처: 2024년, (score=0.8726)\n",
      "\n",
      "2위: 재무상태표에서 2024년 (당기) 우선주자본금는 119,467백만원입니다.\n",
      "   출처: 2024년, (score=0.8726)\n",
      "\n",
      "3위: 재무상태표에서 2024년 (당기) 우선주자본금는 119,467백만원입니다.\n",
      "   출처: 2024년, (score=0.8726)\n",
      "\n",
      "\n",
      "[정답]\n",
      "119,467\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2024년 손익계산서상 당기 법인세비용은 얼마야?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 손익계산서에서 2024년 (당기) 법인세비용(수익)는 -1,832,987백만원입니다.\n",
      "   출처: 2024년, (score=0.8317)\n",
      "\n",
      "2위: 손익계산서에서 2024년 (당기) 법인세비용(수익)는 -1,832,987백만원입니다.\n",
      "   출처: 2024년, (score=0.8317)\n",
      "\n",
      "3위: 손익계산서에서 2024년 (당기) 법인세비용(수익)는 -1,832,987백만원입니다.\n",
      "   출처: 2024년, (score=0.8317)\n",
      "\n",
      "\n",
      "[정답]\n",
      "(1,832,987)\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.33, Recall@3=1.00, F1@3=0.50, nDCG@3=1.00, MRR=1.00\n",
      "====================================================================================================\n",
      "질문: 2017년 재무상태표상 당기 매각예정분류자산은 얼마인가요?\n",
      "\n",
      "[검색 결과 Top-3]\n",
      "1위: 재무상태표에서 2016년 (전기) 매각예정분류자산는 283,690백만원입니다.\n",
      "   출처: 2017년, (score=0.6824)\n",
      "\n",
      "2위: 재무상태표에서 2016년 (전기) 매각예정분류자산는 283,690백만원입니다.\n",
      "   출처: 2017년, (score=0.6824)\n",
      "\n",
      "3위: 재무상태표에서 2016년 (전기) 매각예정분류자산는 283,690백만원입니다.\n",
      "   출처: 2017년, (score=0.6824)\n",
      "\n",
      "\n",
      "[정답]\n",
      "-\n",
      "\n",
      "[성능 지표]\n",
      " Precision@3=0.00, Recall@3=0.00, F1@3=0.00, nDCG@3=0.00, MRR=0.00\n",
      "\n",
      "====================================================================================================\n",
      "=== 평균 성능 지표 ===\n",
      "Precision@3    0.309\n",
      "Recall@3       0.926\n",
      "F1@3           0.463\n",
      "MRR            0.926\n",
      "nDCG@3         0.926\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import re\n",
    "from qdrant_client.http import models as qmodels\n",
    "\n",
    "\n",
    "# ===== 임베딩 모델 로드 =====\n",
    "embed_model = SentenceTransformer(\"dragonkue/bge-m3-ko\")\n",
    "\n",
    "# ===== 숫자만 추출 함수 =====\n",
    "def extract_numbers(text: str) -> str:\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    return \"\".join(re.findall(r\"\\d+\", text.replace(\",\", \"\")))\n",
    "\n",
    "# ===== Retriever 함수 =====\n",
    "def extract_year_from_query(query: str):\n",
    "    \"\"\"질문에서 연도(4자리 숫자) 추출\"\"\"\n",
    "    match = re.search(r\"(20\\d{2}|19\\d{2})\", query)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "    \n",
    "def dense_search(query: str, model, client, collection_name: str,\n",
    "                 top_k: int = 3, ground_truth=None):\n",
    "    \"\"\"\n",
    "    Qdrant query_points 기반 Dense Retriever 함수 + 성능지표 계산\n",
    "    \"\"\"\n",
    "    # 0. 질문에서 연도 추출\n",
    "    year = extract_year_from_query(query)\n",
    "    \n",
    "    # 1. 쿼리 임베딩 생성\n",
    "    qv = model.encode(query, normalize_embeddings=True).tolist()\n",
    "\n",
    "    # 2. Qdrant 검색 실행 (연도 필터 있으면 적용)\n",
    "    query_filter = None\n",
    "    if year:\n",
    "        query_filter = qmodels.Filter(\n",
    "            must=[\n",
    "                qmodels.FieldCondition(\n",
    "                    key=\"report_year\",\n",
    "                    match=qmodels.MatchValue(value=year)\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=qv,\n",
    "        limit=top_k,\n",
    "        with_payload=True,\n",
    "        query_filter=query_filter  # ✅ 필터 적용\n",
    "    )\n",
    "\n",
    "    # 3. 결과 정리 (payload 전체 반영)\n",
    "    output = []\n",
    "    for r in results.points:\n",
    "        payload = r.payload or {}\n",
    "        result_item = {\n",
    "            \"score\": r.score,\n",
    "            \"text\": payload.get(\"text\")\n",
    "        }\n",
    "        # metadata 안의 모든 키-값을 추가\n",
    "        if \"metadata\" in payload:\n",
    "            result_item.update(payload[\"metadata\"])\n",
    "        else:\n",
    "            # 혹시 metadata 키 없이 flat하게 들어온 경우\n",
    "            result_item.update(payload)\n",
    "        output.append(result_item)\n",
    "\n",
    "    # 4. 성능 지표 계산\n",
    "    metrics = {}\n",
    "    if ground_truth:\n",
    "        # 정답 숫자만 추출\n",
    "        normalized_gt = [extract_numbers(gt) for gt in ground_truth]\n",
    "\n",
    "        # 각 검색 결과가 정답과 매칭되는지 여부\n",
    "        used = set()\n",
    "        relevances = []\n",
    "        for r in output:\n",
    "            nums = extract_numbers(r[\"text\"])\n",
    "            hit = 0\n",
    "            for gt in normalized_gt:\n",
    "                if gt and gt in nums and gt not in used:\n",
    "                    hit = 1\n",
    "                    used.add(gt)\n",
    "                    break\n",
    "            relevances.append(hit)\n",
    "\n",
    "        # Precision@3\n",
    "        precision = sum(relevances) / top_k if top_k > 0 else 0.0\n",
    "        metrics[\"Precision@3\"] = precision\n",
    "\n",
    "        # Recall@3 (전체 정답 대비 비율)\n",
    "        recall = min(sum(relevances), len(normalized_gt)) / len(normalized_gt) if normalized_gt else 0.0\n",
    "        metrics[\"Recall@3\"] = recall\n",
    "\n",
    "        # F1@3\n",
    "        if precision + recall > 0:\n",
    "            metrics[\"F1@3\"] = 2 * (precision * recall) / (precision + recall)\n",
    "        else:\n",
    "            metrics[\"F1@3\"] = 0.0\n",
    "\n",
    "        # MRR\n",
    "        rr = 0.0\n",
    "        for rank, rel in enumerate(relevances, 1):\n",
    "            if rel == 1:\n",
    "                rr = 1.0 / rank\n",
    "                break\n",
    "        metrics[\"MRR\"] = rr\n",
    "\n",
    "        # nDCG@k\n",
    "        dcg = sum(rel / np.log2(idx + 2) for idx, rel in enumerate(relevances))\n",
    "        ideal_hits = min(len(normalized_gt), top_k)   # 최대 정답 수\n",
    "        idcg = sum(1.0 / np.log2(idx + 2) for idx in range(ideal_hits))\n",
    "        metrics[\"nDCG@3\"] = dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    return output, metrics\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 실행 예시\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    QDRANT_PATH = \"/Users/dan/Desktop/snu_project/git_제출용/data/vector_store/final-sjchunk/bge-ko-qdrant_db\"\n",
    "    client = QdrantClient(path=QDRANT_PATH)\n",
    "\n",
    "    collection_name = \"audit_chunks\"\n",
    "\n",
    "    questions = [\n",
    "    \"2014년 재무상태표 상 당기 유동자산은 얼마인가?\",\n",
    "    \"2014년 현금흐름표 상 당기 영업활동 현금흐름은 얼마인가?\",\n",
    "    \"2015년 당기 비유동자산은 재무상태표에서 얼마인가?\",\n",
    "    \"2015년 손익계산서 상 당기순이익은 얼마인가?\",\n",
    "    \"2016년 재무상태표 상 당기 단기금융상품은 얼마인가요?\",\n",
    "    \"2016년 포괄손익계산서 상 당기 총포괄이익은 얼마니?\",\n",
    "    \"2016년 자본변동표 상 자기주식의 취득은 얼마인가?\",\n",
    "    \"2017년 당기 매출채권은 재무상태표에 따르면 얼마냐?\",\n",
    "    \"2017년 재무상태표상 전기 현금및현금성자산은 얼마입니까?\",\n",
    "    \"2018년 당기 미수금은 재무상태표에서 얼마인가?\",\n",
    "    \"2018년 손익계산서상 매출총이익은 얼마인가요?\",\n",
    "    \"2019년 재무상태표상 종속기업, 관계기업 및 공동기업 투자는 얼마인가요?\",\n",
    "    \"2019년 현금흐름표 상 이익잉여금 배당은 얼마인가요?\",\n",
    "    \"2019년 손익계산서상 기본주당이익은 얼마인가요?\",\n",
    "    \"2020년 재무상태표 상 자산총계는?\",\n",
    "    \"2020년 손익계산서 상 판매비와관리비는 얼마인가요?\",\n",
    "    \"2021년 재무상태표상 당기 기타포괄손익-공정가치금융자산은 얼마인가요?\",\n",
    "    #\"2021년 재무상태표에서 당기 유동비율을 계산하면 얼마인가요?\",\n",
    "    \"2021년 손익계산서 상 당기 금융비용은 얼마인가요?\",\n",
    "    \"2022년 재무상태표상 당기 비유동부채는 얼마인가?\",\n",
    "    \"2022년 손익계산서 상 당기 법인세비용은 얼마니?\",\n",
    "    \"2022년 당기 현금흐름표 상 투자활동 현금흐름은 얼마인가?\",\n",
    "    \"2023년 재무상태표 상 재고자산은 얼마인가?\",\n",
    "    \"2023년 손익계산서 상 당기 영업이익은 얼마인가?\",\n",
    "    \"2024년에는 재무상태표상 당기 무형자산이 얼마야?\",\n",
    "    \"2024년 재무상태표 상 당기 우선주자본금은 얼마인가?\",\n",
    "    \"2024년 손익계산서상 당기 법인세비용은 얼마야?\",\n",
    "    \"2017년 재무상태표상 당기 매각예정분류자산은 얼마인가요?\",\n",
    "    ]\n",
    "    \n",
    "    answers = [\n",
    "        \"62,054,773\",\n",
    "        \"18,653,817\",\n",
    "        \"101,967,575\",\n",
    "        \"12,238,469\",\n",
    "        \"30,170,656\",\n",
    "        \"11,887,806\",\n",
    "        \"(7,707,938)\",\n",
    "        \"27,881,777\",\n",
    "        \"3,778,371\",\n",
    "        \"1,515,079\",\n",
    "        \"68,715,364\",\n",
    "        \"56,571,252\",\n",
    "        \"(9,618,210)\",\n",
    "        \"2,260\",\n",
    "        \"229,664,427\",\n",
    "        \"29,038,798\",\n",
    "        \"1,662,532\",\n",
    "        #\"1.38\",\n",
    "        \"3,698,675\",\n",
    "        \"4,581,512\",\n",
    "        \"4,273,142\",\n",
    "        \"(28,123,886)\",\n",
    "        \"29,338,151\",\n",
    "        \"(11,526,297)\",\n",
    "        \"10,496,956\",\n",
    "        \"119,467\",\n",
    "        \"(1,832,987)\",\n",
    "        \"-\"\n",
    "    ]\n",
    "\n",
    "    all_metrics = []\n",
    "\n",
    "    for q, a in zip(questions, answers):\n",
    "        results, metrics = dense_search(\n",
    "            query=q,\n",
    "            model=embed_model,\n",
    "            client=client,\n",
    "            collection_name=collection_name,\n",
    "            top_k=3,\n",
    "            ground_truth=[a]\n",
    "        )\n",
    "\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"질문: {q}\")\n",
    "\n",
    "        # Top-3 결과 모두 출력\n",
    "        if results:\n",
    "            print(\"\\n[검색 결과 Top-3]\")\n",
    "            for rank, r in enumerate(results, 1):\n",
    "                print(f\"{rank}위: {r['text']}\")\n",
    "                print(f\"   출처: {r['report_year']}년, (score={r['score']:.4f})\\n\")\n",
    "        else:\n",
    "            print(\"검색 결과 없음\")\n",
    "\n",
    "        print(\"\\n[정답]\")\n",
    "        print(a)\n",
    "\n",
    "        print(\"\\n[성능 지표]\")\n",
    "        print(\n",
    "            f\" Precision@3={metrics.get('Precision@3', 0):.2f},\"\n",
    "            f\" Recall@3={metrics.get('Recall@3', 0):.2f},\"\n",
    "            f\" F1@3={metrics.get('F1@3', 0):.2f},\"\n",
    "            f\" nDCG@3={metrics.get('nDCG@3', 0):.2f},\"\n",
    "            f\" MRR={metrics.get('MRR', 0):.2f}\"\n",
    "        )\n",
    "\n",
    "        all_metrics.append(metrics)\n",
    "\n",
    "    # 평균 성능 지표\n",
    "    df = pd.DataFrame(all_metrics)\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"=== 평균 성능 지표 ===\")\n",
    "    print(df.mean().round(3))\n",
    "\n",
    "    client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eba035-0b06-4606-86ca-99afa9140553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "💬 질문: 2014년 재무상태표에서 당기 유동자산의 하위계층 정보를 전부 줘. metadata에서 hierarchy / level을 꼭 참고해.\n",
      "\n",
      "🔍 검색 결과 (10개):\n",
      "====================================================================================================\n",
      "\n",
      "1. 스코어: 0.6022\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 유동자산는 62,054,773백만원입니다....\n",
      "   📊 메타데이터: account_id: 자산_유동자산, account_name: 유동자산, parent_id: 자산, level: 2, hierarchy: ['자산', '유동자산'], is_total: False, is_subtotal: False, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. 스코어: 0.6022\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 유동자산는 62,054,773백만원입니다....\n",
      "   📊 메타데이터: account_id: 자산_유동자산, account_name: 유동자산, parent_id: 자산, level: 2, hierarchy: ['자산', '유동자산'], is_total: False, is_subtotal: False, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. 스코어: 0.6022\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 유동자산는 62,054,773백만원입니다....\n",
      "   📊 메타데이터: account_id: 자산_유동자산, account_name: 유동자산, parent_id: 자산, level: 2, hierarchy: ['자산', '유동자산'], is_total: False, is_subtotal: False, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "4. 스코어: 0.5628\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 유동부채는 28,208,638백만원입니다....\n",
      "   📊 메타데이터: account_id: 부채_유동부채, account_name: 유동부채, parent_id: 부채, level: 2, hierarchy: ['부채', '유동부채'], is_total: False, is_subtotal: False, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "5. 스코어: 0.5628\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 유동부채는 28,208,638백만원입니다....\n",
      "   📊 메타데이터: account_id: 부채_유동부채, account_name: 유동부채, parent_id: 부채, level: 2, hierarchy: ['부채', '유동부채'], is_total: False, is_subtotal: False, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "6. 스코어: 0.5628\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 유동부채는 28,208,638백만원입니다....\n",
      "   📊 메타데이터: account_id: 부채_유동부채, account_name: 유동부채, parent_id: 부채, level: 2, hierarchy: ['부채', '유동부채'], is_total: False, is_subtotal: False, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "7. 스코어: 0.5589\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 유동성사채는 5,304백만원입니다. 주석: 6, 16...\n",
      "   📊 메타데이터: account_id: 부채_유동부채_유동성사채, account_name: 유동성사채, parent_id: 부채_유동부채, level: 3, hierarchy: ['유동부채', '유동성사채'], is_total: False, is_subtotal: True, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "8. 스코어: 0.5589\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 유동성사채는 5,304백만원입니다. 주석: 6, 16...\n",
      "   📊 메타데이터: account_id: 부채_유동부채_유동성사채, account_name: 유동성사채, parent_id: 부채_유동부채, level: 3, hierarchy: ['유동부채', '유동성사채'], is_total: False, is_subtotal: True, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "9. 스코어: 0.5589\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 유동성사채는 5,304백만원입니다. 주석: 6, 16...\n",
      "   📊 메타데이터: account_id: 부채_유동부채_유동성사채, account_name: 유동성사채, parent_id: 부채_유동부채, level: 3, hierarchy: ['유동부채', '유동성사채'], is_total: False, is_subtotal: True, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "10. 스코어: 0.5572\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 기타유동자산는 821,079백만원입니다....\n",
      "   📊 메타데이터: account_id: 자산_유동자산_기타유동자산, account_name: 기타유동자산, parent_id: 자산_유동자산, level: 3, hierarchy: ['유동자산', '기타유동자산'], is_total: False, is_subtotal: True, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 요약:\n",
      "   - 총 10개의 관련 문서를 찾았습니다.\n",
      "   - 관련 연도: 2014\n",
      "   - 발견된 계층 정보: 10개\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "# from llama_cpp import Llama  # 하단에서 import\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import re\n",
    "from qdrant_client.http import models as qmodels\n",
    "\n",
    "\n",
    "# ===== 임베딩 모델 로드 =====\n",
    "embed_model = SentenceTransformer(\"dragonkue/bge-m3-ko\")\n",
    "\n",
    "# ===== Qdrant 클라이언트 =====\n",
    "QDRANT_PATH = \"/Users/dan/Desktop/snu_project/git_제출용/data/vector_store/final-sjchunk/bge-ko-qdrant_db\"\n",
    "client = QdrantClient(path=QDRANT_PATH)\n",
    "\n",
    "collection_name = \"audit_chunks\"\n",
    "\n",
    "# ===== dense_search 함수 import =====\n",
    "# (예빈씨가 이전에 정의한 dense_search 그대로 사용한다고 가정)\n",
    "def extract_year_from_query(query: str):\n",
    "    \"\"\"질문에서 연도(4자리 숫자) 추출\"\"\"\n",
    "    match = re.search(r\"(20\\d{2}|19\\d{2})\", query)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def extract_numbers(text: str) -> str:\n",
    "    \"\"\"텍스트에서 숫자만 추출\"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    return \"\".join(re.findall(r\"\\d+\", text.replace(\",\", \"\")))\n",
    "    \n",
    "def dense_search(query: str, model, client, collection_name: str,\n",
    "                 top_k: int = 50, ground_truth=None):\n",
    "    \"\"\"\n",
    "    Qdrant query_points 기반 Dense Retriever 함수 + 성능지표 계산\n",
    "    \"\"\"\n",
    "    # 0. 질문에서 연도 추출\n",
    "    year = extract_year_from_query(query)\n",
    "    \n",
    "    # 1. 쿼리 임베딩 생성\n",
    "    qv = model.encode(query, normalize_embeddings=True).tolist()\n",
    "\n",
    "    # 2. Qdrant 검색 실행 (연도 필터 있으면 적용)\n",
    "    query_filter = None\n",
    "    if year:\n",
    "        query_filter = qmodels.Filter(\n",
    "            must=[\n",
    "                qmodels.FieldCondition(\n",
    "                    key=\"report_year\",\n",
    "                    match=qmodels.MatchValue(value=year)\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=qv,\n",
    "        limit=top_k,\n",
    "        with_payload=True,\n",
    "        query_filter=query_filter  # ✅ 필터 적용\n",
    "    )\n",
    "\n",
    "    # 3. 결과 정리 (payload 전체 반영)\n",
    "    output = []\n",
    "    for r in results.points:\n",
    "        payload = r.payload or {}\n",
    "        result_item = {\n",
    "            \"score\": r.score,\n",
    "            \"text\": payload.get(\"text\")\n",
    "        }\n",
    "        # metadata 안의 모든 키-값을 추가\n",
    "        if \"metadata\" in payload:\n",
    "            result_item.update(payload[\"metadata\"])\n",
    "        else:\n",
    "            # 혹시 metadata 키 없이 flat하게 들어온 경우\n",
    "            result_item.update(payload)\n",
    "        output.append(result_item)\n",
    "\n",
    "    # 4. 성능 지표 계산\n",
    "    metrics = {}\n",
    "    if ground_truth:\n",
    "        # 정답 숫자만 추출\n",
    "        normalized_gt = [extract_numbers(gt) for gt in ground_truth]\n",
    "\n",
    "        # 각 검색 결과가 정답과 매칭되는지 여부\n",
    "        used = set()\n",
    "        relevances = []\n",
    "        for r in output:\n",
    "            nums = extract_numbers(r[\"text\"])\n",
    "            hit = 0\n",
    "            for gt in normalized_gt:\n",
    "                if gt and gt in nums and gt not in used:\n",
    "                    hit = 1\n",
    "                    used.add(gt)\n",
    "                    break\n",
    "            relevances.append(hit)\n",
    "\n",
    "        # Precision@3\n",
    "        precision = sum(relevances) / top_k if top_k > 0 else 0.0\n",
    "        metrics[\"Precision@3\"] = precision\n",
    "\n",
    "        # Recall@3 (전체 정답 대비 비율)\n",
    "        recall = min(sum(relevances), len(normalized_gt)) / len(normalized_gt) if normalized_gt else 0.0\n",
    "        metrics[\"Recall@3\"] = recall\n",
    "\n",
    "        # F1@3\n",
    "        if precision + recall > 0:\n",
    "            metrics[\"F1@3\"] = 2 * (precision * recall) / (precision + recall)\n",
    "        else:\n",
    "            metrics[\"F1@3\"] = 0.0\n",
    "\n",
    "        # MRR\n",
    "        rr = 0.0\n",
    "        for rank, rel in enumerate(relevances, 1):\n",
    "            if rel == 1:\n",
    "                rr = 1.0 / rank\n",
    "                break\n",
    "        metrics[\"MRR\"] = rr\n",
    "\n",
    "        # nDCG@k\n",
    "        dcg = sum(rel / np.log2(idx + 2) for idx, rel in enumerate(relevances))\n",
    "        ideal_hits = min(len(normalized_gt), top_k)   # 최대 정답 수\n",
    "        idcg = sum(1.0 / np.log2(idx + 2) for idx in range(ideal_hits))\n",
    "        metrics[\"nDCG@3\"] = dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    return output, metrics\n",
    "    \n",
    "# ===== Zephyr 모델 로드 =====\n",
    "model_path = Path(\"/Users/dan/Desktop/snu_project/models/zephyr-7b-beta.Q4_K_M.gguf\").resolve()\n",
    "\n",
    "# from llama_cpp import Llama  # Cell 6에서 로드됨\n",
    "# llm = Llama(\n",
    "#     model_path=str(model_path),\n",
    "#     n_ctx=4096,\n",
    "#     n_threads=8,\n",
    "#     n_gpu_layers=35\n",
    "# )\n",
    "\n",
    "# ===== 간단한 검색 테스트 함수 =====\n",
    "def simple_search_test(query: str, model, client, collection_name: str, top_k: int = 10):\n",
    "    \"\"\"LLM 없이 검색 결과만 확인하는 함수\"\"\"\n",
    "    results, _ = dense_search(\n",
    "        query=query,\n",
    "        model=model,\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        top_k=top_k\n",
    "    )\n",
    "    \n",
    "    print(f\"🔍 검색 결과 ({len(results)}개):\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. 스코어: {r['score']:.4f}\")\n",
    "        print(f\"   연도: {r.get('report_year', 'N/A')}\")\n",
    "        print(f\"   텍스트: {r['text'][:200]}...\")\n",
    "        \n",
    "        # metadata 정보 출력\n",
    "        metadata_keys = ['account_id', 'account_name', 'parent_id', 'level', 'hierarchy', \n",
    "                        'is_total', 'is_subtotal', 'period_type', 'statement_type']\n",
    "        metadata_info = []\n",
    "        for key in metadata_keys:\n",
    "            if key in r:\n",
    "                metadata_info.append(f\"{key}: {r[key]}\")\n",
    "        if metadata_info:\n",
    "            print(f\"   📊 메타데이터: {', '.join(metadata_info)}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    return results\n",
    "\n",
    "# ===== RAG Pipeline (LLM 없이 검색만) =====\n",
    "def rag_pipeline_simple(query: str, model, client, collection_name: str, top_k: int = 10):\n",
    "    \"\"\"LLM 없이 검색 결과만 반환하는 간단한 RAG\"\"\"\n",
    "    print(f\"💬 질문: {query}\")\n",
    "    print()\n",
    "    \n",
    "    # 검색 수행\n",
    "    results = simple_search_test(query, model, client, collection_name, top_k)\n",
    "    \n",
    "    # 간단한 요약 정보\n",
    "    print(f\"\\n📋 요약:\")\n",
    "    print(f\"   - 총 {len(results)}개의 관련 문서를 찾았습니다.\")\n",
    "    \n",
    "    if results:\n",
    "        years = list(set([r.get('report_year', 'N/A') for r in results if r.get('report_year')]))\n",
    "        if years:\n",
    "            print(f\"   - 관련 연도: {', '.join(map(str, sorted(years)))}\")\n",
    "        \n",
    "        # 계층 정보가 있는 경우\n",
    "        hierarchies = [r.get('hierarchy', '') for r in results if r.get('hierarchy')]\n",
    "                 if hierarchies:\n",
    "             print(f\"   - 발견된 계층 정보: {len(hierarchies)}개\")\n",
    "     \n",
    "     return results\n",
    "\n",
    "# ===== RAG Pipeline =====\n",
    "def rag_pipeline(query: str, model, client, collection_name: str, top_k: int = 3):\n",
    "    # 1) Retriever 단계\n",
    "    results, _ = dense_search(\n",
    "        query=query,\n",
    "        model=model,\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        top_k=top_k\n",
    "    )\n",
    "\n",
    "    # 2) 검색 결과 합치기\n",
    "    context_text = \"\\n\".join([r[\"text\"] for r in results if r.get(\"text\")])\n",
    "\n",
    "    # 3) Reader 호출 (Zephyr LLM) - 튜닝된 프롬프트 적용\n",
    "    prompt = f\"\"\"<|system|>\n",
    "너는 재무보고서 전문가이자 데이터 구조화 전문가다. \n",
    "너의 임무는 검색된 문서에서 사용자가 요청한 항목을 \n",
    "metadata의 account_id, account_name, parent_id, is_total, is_subtotal, period_type,\n",
    "hierarchy, level 정보를 반드시 참고하여 계층 구조를 반영해 표로 정리하는 것이다.\n",
    "\n",
    "요구사항:\n",
    "1. 반드시 metadata의 account_id, account_name, parent_id, is_total, is_subtotal, period_type, hierarchy, level 정보를 모두 활용하라.\n",
    "2. account_id와 account_name으로 항목을 식별하고, parent_id를 사용하여 상위-하위 관계를 연결하라.\n",
    "3. is_total과 is_subtotal은 합계/소계 여부를 명확히 표시하라.\n",
    "4. period_type은 \"당기/전기/누적\" 등의 기간 구분을 반드시 표에 포함하라.\n",
    "5. level 값이 커질수록 하위 항목이므로 들여쓰기를 적용하거나, 표에서 level 열을 활용하라.\n",
    "6. 출력은 반드시 표 형식으로: \n",
    "   | account_id | account_name | parent_id | level | hierarchy | 값(백만원) | is_total | is_subtotal | period_type |\n",
    "7. 모든 항목을 빠짐없이 보여주고, 추측하지 말고 검색된 문서와 metadata만 근거로 작성하라.\n",
    "8. 만약 유동자산과 관련된 유동부채가 함께 제공된다면, 유동비율(Current Ratio = 유동자산 ÷ 유동부채)을 계산하여 표 맨 아래에 추가하라.\n",
    "9. 출처는 메타데이터에서 report_year를 사용해서 적어라.\n",
    "10. 절대로 account_name을 지어서 만들어내지 말라.\n",
    "</s>\n",
    "<|user|>\n",
    "다음은 검색된 문서다:\n",
    "{context_text}\n",
    "\n",
    "질문: {query}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "\n",
    "    response = llm(prompt, max_tokens=1024, stop=[\"</s>\"])\n",
    "    return response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "# ===== 실행 예시 =====\n",
    "if __name__ == \"__main__\":\n",
    "    questions = [\n",
    "        # \"2014년 재무상태표 상 당기 유동자산은 얼마인가?\",\n",
    "        # \"2014년 현금흐름표 상 당기 영업활동 현금흐름은 얼마인가?\",\n",
    "        # \"2015년 당기 비유동자산은 재무상태표에서 얼마인가?\",\n",
    "        # \"2015년 손익계산서 상 당기순이익은 얼마인가?\",\n",
    "        # \"2016년 재무상태표 상 당기 단기금융상품은 얼마인가요?\",\n",
    "        # \"2016년 포괄손익계산서 상 당기 총포괄이익은 얼마니?\",\n",
    "        # \"2016년 자본변동표 상 자기주식의 취득은 얼마인가?\",\n",
    "        # \"2017년 당기 매출채권은 재무상태표에 따르면 얼마냐?\",\n",
    "        # \"2017년 재무상태표상 전기 현금및현금성자산은 얼마입니까?\",\n",
    "        # \"2017년 재무상태표상 당기 매각예정분류자산은 얼마인가요?\",\n",
    "        # \"2018년 당기 미수금은 재무상태표에서 얼마인가?\",\n",
    "        # \"2018년 손익계산서상 매출총이익은 얼마인가요?\",\n",
    "        # \"2019년 재무상태표상 종속기업, 관계기업 및 공동기업 투자는 얼마인가요?\",\n",
    "        # \"2019년 현금흐름표 상 이익잉여금 배당은 얼마인가요?\",\n",
    "        # \"2019년 손익계산서상 기본주당이익은 얼마인가요?\",\n",
    "        # \"2020년 재무상태표 상 자산총계는?\",\n",
    "        # \"2020년 손익계산서 상 판매비와관리비는 얼마인가요?\",\n",
    "        # \"2021년 재무상태표상 당기 기타포괄손익-공정가치금융자산은 얼마인가요?\",\n",
    "        # \"2021년 재무상태표에서 당기 유동비율을 계산하면 얼마인가요?\",\n",
    "        # \"2021년 손익계산서 상 당기 금융비용은 얼마인가요?\",\n",
    "        # \"2022년 재무상태표상 당기 비유동부채는 얼마인가?\",\n",
    "        # \"2022년 손익계산서 상 당기 법인세비용은 얼마니?\",\n",
    "        # \"2022년 당기 현금흐름표 상 투자활동 현금흐름은 얼마인가?\",\n",
    "        # \"2023년 재무상태표 상 재고자산은 얼마인가?\",\n",
    "        # \"2023년 당기 영업이익은 얼마인가?\",\n",
    "        # \"2024년에는 재무상태표상 당기 무형자산이 얼마야?\",\n",
    "        # \"2024년 재무상태표 상 당기 우선주자본금은 얼마인가?\",\n",
    "        # \"2024년 손익계산서상 당기 법인세비용은 얼마야?\",\n",
    "        #\"손익계산서 상 매출액이 전년 대비 오른 연도를 전부 알려줘\",\n",
    "        #\"유동비율(유동자산/유동부채)을 2014년 재무상태표에서 값을 찾아서 계산해봐\"\n",
    "        \"2014년 재무상태표에서 당기 유동자산의 하위계층 정보를 전부 줘. metadata에서 hierarchy / level을 꼭 참고해.\"\n",
    "    ]\n",
    "\n",
    "    for q in questions:\n",
    "        # LLM RAG는 Cell 5에서 실행됩니다\n",
    "        print(\"✅ 모든 함수와 Zephyr 모델 로드 완료!\")\n",
    "        print(\"📝 Cell 5를 실행하여 LLM RAG 파이프라인을 테스트하세요!\")\n",
    "        print(\"=\" * 80)\n",
    "        print(\"질문:\", q)\n",
    "        print(\"답변:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104058bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== RAG Pipeline with LLM ==================\n",
    "def rag_pipeline(query: str, model, client, collection_name: str, top_k: int = 20):\n",
    "    \"\"\"실제 LLM을 사용하는 RAG 파이프라인\"\"\"\n",
    "    # 1) 검색 단계\n",
    "    results, _ = dense_search(\n",
    "        query=query,\n",
    "        model=model,\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        top_k=top_k,\n",
    "        fallback_min_hits=8\n",
    "    )\n",
    "    \n",
    "    # 2) 컨텍스트 구성 (메타데이터 포함)\n",
    "    context_parts = []\n",
    "    for i, r in enumerate(results, 1):\n",
    "        metadata_info = []\n",
    "        metadata_keys = ['account_id', 'account_name', 'parent_id', 'level', 'hierarchy', \n",
    "                        'is_total', 'is_subtotal', 'period_type', 'statement_type', 'report_year']\n",
    "        for key in metadata_keys:\n",
    "            if key in r:\n",
    "                metadata_info.append(f\"{key}: {r[key]}\")\n",
    "        \n",
    "        context_part = f\"문서 {i}:\\n\"\n",
    "        context_part += f\"텍스트: {r['text']}\\n\"\n",
    "        context_part += f\"메타데이터: {', '.join(metadata_info)}\\n\"\n",
    "        context_parts.append(context_part)\n",
    "    \n",
    "    context_text = \"\\n\".join(context_parts)\n",
    "    \n",
    "    # 3) LLM 프롬프트 구성\n",
    "    prompt = f\"\"\"<|system|>\n",
    "너는 재무보고서 전문가이자 데이터 구조화 전문가다.\n",
    "검색된 문서들의 metadata를 활용하여 사용자 질문에 대한 구조화된 표를 작성해라.\n",
    "\n",
    "**중요 규칙:**\n",
    "1. 반드시 metadata의 account_id, account_name, parent_id, level, hierarchy 정보를 모두 활용하라\n",
    "2. level 값이 클수록 하위 항목이므로 계층 구조를 반영하라\n",
    "3. 표 형식으로 출력: | account_id | account_name | parent_id | level | hierarchy | 값(백만원) | period_type |\n",
    "4. 모든 검색된 항목을 빠짐없이 포함하라\n",
    "5. 추측하지 말고 제공된 데이터만 사용하라\n",
    "6. hierarchy는 리스트 형태로 표시하라\n",
    "7. 값은 텍스트에서 추출한 숫자를 사용하라\n",
    "</s>\n",
    "<|user|>\n",
    "질문: {query}\n",
    "\n",
    "검색된 문서들:\n",
    "{context_text}\n",
    "\n",
    "위 정보를 바탕으로 구조화된 표를 작성해주세요.\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "    \n",
    "    # 4) LLM 실행\n",
    "    response = llm(prompt, max_tokens=2048, stop=[\"</s>\"], temperature=0.1)\n",
    "    return response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "# ================== LLM 테스트 실행 ==================\n",
    "# Cell 4에서 검색 함수들이 먼저 실행되었으므로, 이제 LLM RAG를 실행합니다\n",
    "print(\"🚀 LLM RAG 파이프라인 테스트 (Cell 4의 검색 결과를 LLM으로 구조화)\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "test_question = \"2014년 재무상태표에서 당기 비유동자산의 하위계층 정보를 전부 줘. metadata에서 hierarchy / level을 꼭 참고해.\"\n",
    "print(f\"💬 질문: {test_question}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "try:\n",
    "    # LLM을 사용한 구조화된 답변 생성\n",
    "    answer = rag_pipeline(test_question, embed_model, client, collection_name, top_k=30)\n",
    "    \n",
    "    print(\"🤖 LLM 답변:\")\n",
    "    print(answer)\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 오류 발생: {e}\")\n",
    "    print(\"📝 Cell 4를 먼저 실행했는지 확인하세요!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad2e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== 🚀 독립 실행형 LLM RAG 파이프라인 ==================\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models as qmodels\n",
    "from llama_cpp import Llama\n",
    "\n",
    "print(\"🚀 독립 실행형 LLM RAG 파이프라인\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# ===== 설정 =====\n",
    "QDRANT_PATH = \"/Users/dan/Desktop/snu_project/git_제출용/data/vector_store/final-sjchunk/bge-ko-qdrant_db\"\n",
    "MODEL_PATH = \"/Users/dan/Desktop/snu_project/models/zephyr-7b-beta.Q4_K_M.gguf\"\n",
    "collection_name = \"audit_chunks\"\n",
    "\n",
    "# ===== 모델 로드 =====\n",
    "print(\"📦 모델 로드 중...\")\n",
    "embed_model = SentenceTransformer(\"dragonkue/bge-m3-ko\")\n",
    "client = QdrantClient(path=QDRANT_PATH)\n",
    "llm = Llama(model_path=MODEL_PATH, n_ctx=4096, n_threads=8, n_gpu_layers=35)\n",
    "print(\"   ✅ 모델 로드 완료\")\n",
    "\n",
    "# ===== 유틸 함수 =====\n",
    "def extract_year_from_query(query: str):\n",
    "    m = re.search(r\"(20\\d{2}|19\\d{2})\", query)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def detect_statement_type(query: str) -> str:\n",
    "    q = query.replace(\" \", \"\")\n",
    "    if \"재무상태표\" in q or \"대차대조표\" in q: return \"balance\"\n",
    "    if \"손익계산서\" in q or \"포괄손익\" in q: return \"income\"\n",
    "    if \"현금흐름표\" in q: return \"cashflow\"\n",
    "    if \"자본변동표\" in q: return \"equity_changes\"\n",
    "    return \"balance\"\n",
    "\n",
    "def build_filter(year=None, statement_type=None, period_type=None, parent_id=None, min_level=None):\n",
    "    must = []\n",
    "    if year: must.append(qmodels.FieldCondition(key=\"report_year\", match=qmodels.MatchValue(value=year)))\n",
    "    if statement_type: must.append(qmodels.FieldCondition(key=\"statement_type\", match=qmodels.MatchValue(value=statement_type)))\n",
    "    if period_type: must.append(qmodels.FieldCondition(key=\"period_type\", match=qmodels.MatchValue(value=period_type)))\n",
    "    if parent_id: must.append(qmodels.FieldCondition(key=\"parent_id\", match=qmodels.MatchValue(value=parent_id)))\n",
    "    if min_level: must.append(qmodels.FieldCondition(key=\"level\", range=qmodels.Range(gte=min_level)))\n",
    "    must.append(qmodels.FieldCondition(key=\"is_total\", match=qmodels.MatchValue(value=False)))\n",
    "    return qmodels.Filter(must=must) if must else None\n",
    "\n",
    "# ===== 검색 함수 =====\n",
    "def simple_search(query: str, top_k: int = 20):\n",
    "    year = extract_year_from_query(query)\n",
    "    statement_type = detect_statement_type(query)\n",
    "    period_type = \"current\"\n",
    "    \n",
    "    # 비유동자산 검색을 위한 필터\n",
    "    query_filter = build_filter(\n",
    "        year=year,\n",
    "        statement_type=statement_type,\n",
    "        period_type=period_type,\n",
    "        min_level=3  # 하위 항목들\n",
    "    )\n",
    "    \n",
    "    qv = embed_model.encode(\"query: \" + query, normalize_embeddings=True).tolist()\n",
    "    \n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=qv,\n",
    "        limit=top_k,\n",
    "        with_payload=True,\n",
    "        query_filter=query_filter\n",
    "    )\n",
    "    \n",
    "    output = []\n",
    "    seen_ids = set()\n",
    "    for r in results.points:\n",
    "        payload = r.payload or {}\n",
    "        text = payload.get(\"text\")\n",
    "        if not text: continue\n",
    "        \n",
    "        meta = payload.get(\"metadata\", {})\n",
    "        if not meta: meta = {k: v for k, v in payload.items() if k != \"text\"}\n",
    "        \n",
    "        account_id = meta.get(\"account_id\")\n",
    "        if account_id and account_id in seen_ids: continue\n",
    "        if account_id: seen_ids.add(account_id)\n",
    "        \n",
    "        # 비유동자산 관련 필터링\n",
    "        hierarchy = meta.get(\"hierarchy\", [])\n",
    "        if isinstance(hierarchy, list) and \"비유동자산\" in hierarchy:\n",
    "            item = {\"score\": r.score, \"text\": text}\n",
    "            item.update(meta)\n",
    "            output.append(item)\n",
    "    \n",
    "    output.sort(key=lambda x: (x.get(\"level\", 999), str(x.get(\"account_name\", \"\"))))\n",
    "    return output\n",
    "\n",
    "# ===== RAG 파이프라인 =====\n",
    "def rag_pipeline(query: str, top_k: int = 20):\n",
    "    # 1) 검색\n",
    "    results = simple_search(query, top_k)\n",
    "    \n",
    "    # 2) 컨텍스트 구성\n",
    "    context_parts = []\n",
    "    for i, r in enumerate(results, 1):\n",
    "        metadata_keys = ['account_id', 'account_name', 'parent_id', 'level', 'hierarchy', \n",
    "                        'is_total', 'is_subtotal', 'period_type', 'statement_type', 'report_year']\n",
    "        metadata_info = [f\"{key}: {r[key]}\" for key in metadata_keys if key in r]\n",
    "        \n",
    "        context_part = f\"문서 {i}:\\n텍스트: {r['text']}\\n메타데이터: {', '.join(metadata_info)}\\n\"\n",
    "        context_parts.append(context_part)\n",
    "    \n",
    "    context_text = \"\\n\".join(context_parts)\n",
    "    \n",
    "    # 3) LLM 프롬프트\n",
    "    prompt = f\"\"\"<|system|>\n",
    "너는 재무보고서 전문가다. 검색된 문서들의 metadata를 활용하여 구조화된 표를 작성해라.\n",
    "\n",
    "**규칙:**\n",
    "1. metadata의 account_id, account_name, parent_id, level, hierarchy 정보를 모두 활용\n",
    "2. level 값이 클수록 하위 항목\n",
    "3. 표 형식: | account_id | account_name | parent_id | level | hierarchy | 값(백만원) | period_type |\n",
    "4. 모든 검색된 항목을 포함\n",
    "5. 추측하지 말고 제공된 데이터만 사용\n",
    "6. 값은 텍스트에서 추출한 숫자 사용\n",
    "</s>\n",
    "<|user|>\n",
    "질문: {query}\n",
    "\n",
    "검색된 문서들:\n",
    "{context_text}\n",
    "\n",
    "위 정보를 바탕으로 구조화된 표를 작성해주세요.\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "    \n",
    "    # 4) LLM 실행\n",
    "    response = llm(prompt, max_tokens=2048, stop=[\"</s>\"], temperature=0.1)\n",
    "    return response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "# ===== 실행 =====\n",
    "test_question = \"2014년 재무상태표에서 당기 비유동자산의 하위계층 정보를 전부 줘. metadata에서 hierarchy / level을 꼭 참고해.\"\n",
    "print(f\"💬 질문: {test_question}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "try:\n",
    "    # 1) 검색\n",
    "    print(\"🔍 1단계: 검색 실행 중...\")\n",
    "    search_results = simple_search(test_question, top_k=20)\n",
    "    print(f\"   ✅ {len(search_results)}개 문서 검색 완료\")\n",
    "    \n",
    "    # 2) LLM 답변 생성\n",
    "    print(\"🤖 2단계: LLM 답변 생성 중...\")\n",
    "    answer = rag_pipeline(test_question, top_k=20)\n",
    "    \n",
    "    print(\"🎯 최종 답변:\")\n",
    "    print(\"=\" * 100)\n",
    "    print(answer)\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 오류 발생: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e435868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== 🎯 최종 실행 안내 ==================\n",
    "print(\"🎯 독립 실행형 RAG 시스템\")\n",
    "print(\"=\" * 50)\n",
    "print(\"📝 Cell 6만 실행하시면 모든 기능이 작동합니다!\")\n",
    "print(\"   - 모델 로드\")\n",
    "print(\"   - 검색 실행\") \n",
    "print(\"   - LLM 답변 생성\")\n",
    "print(\"=\" * 50)\n",
    "print(\"⚡ 다른 셀들은 무시하고 Cell 6만 실행하세요!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0037927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f8f9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ff6ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "💬 질문: 2014년 재무상태표에서 당기 유동자산의 하위계층 정보를 전부 줘. metadata에서 hierarchy / level을 꼭 참고해.\n",
      "\n",
      "🔍 검색 결과 (1개):\n",
      "====================================================================================================\n",
      "\n",
      "1. 스코어: 0.5557\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 기타유동자산는 821,079백만원입니다....\n",
      "   📊 메타데이터: account_id: 자산_유동자산_기타유동자산, account_name: 기타유동자산, parent_id: 자산_유동자산, level: 3, hierarchy: ['유동자산', '기타유동자산'], is_total: False, is_subtotal: True, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 요약:\n",
      "   - 총 1개의 관련 문서를 찾았습니다.\n",
      "   - 관련 연도: 2014\n",
      "   - 발견된 계층 정보: 1개\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "# from llama_cpp import Llama  # 임시로 주석 처리 (모듈이 설치되어 있지 않음)\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import re\n",
    "from qdrant_client.http import models as qmodels\n",
    "\n",
    "# ===== 임베딩 모델 로드 =====\n",
    "embed_model = SentenceTransformer(\"dragonkue/bge-m3-ko\")\n",
    "\n",
    "# ===== Qdrant 클라이언트 =====\n",
    "QDRANT_PATH = \"/Users/dan/Desktop/snu_project/git_제출용/data/vector_store/final-sjchunk/bge-ko-qdrant_db\"\n",
    "client = QdrantClient(path=QDRANT_PATH)\n",
    "\n",
    "collection_name = \"audit_chunks\"\n",
    "\n",
    "\n",
    "# =============== 유틸 ===============\n",
    "def extract_year_from_query(query: str):\n",
    "    \"\"\"질문에서 연도(4자리 숫자) 추출\"\"\"\n",
    "    match = re.search(r\"(20\\d{2}|19\\d{2})\", query)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def extract_numbers(text: str) -> str:\n",
    "    \"\"\"텍스트에서 숫자만 추출\"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    return \"\".join(re.findall(r\"\\d+\", text.replace(\",\", \"\")))\n",
    "\n",
    "\n",
    "# =============== (신규) 필터 빌더 ===============  ### ADDED\n",
    "def build_filter(\n",
    "    year: int = None,\n",
    "    statement_type: str = None,     # e.g., \"balance\"\n",
    "    period_type: str = None,        # e.g., \"current\" or \"previous\"\n",
    "    must_have_hierarchy: str = None,# e.g., \"유동자산\"\n",
    "    min_level: int = None,          # e.g., 3\n",
    "    exclude_totals: bool = True,\n",
    "    exclude_subtotals: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Qdrant 서버 측 필터를 조립합니다.\n",
    "    - hierarchy는 리스트 필드라고 가정하고 '유동자산' 포함 여부를 MatchAny로 체크합니다.\n",
    "    \"\"\"\n",
    "    must = []\n",
    "\n",
    "    if year is not None:\n",
    "        must.append(qmodels.FieldCondition(\n",
    "            key=\"report_year\",\n",
    "            match=qmodels.MatchValue(value=year)\n",
    "        ))\n",
    "\n",
    "    if statement_type:\n",
    "        must.append(qmodels.FieldCondition(\n",
    "            key=\"statement_type\",\n",
    "            match=qmodels.MatchValue(value=statement_type)\n",
    "        ))\n",
    "\n",
    "    if period_type:\n",
    "        must.append(qmodels.FieldCondition(\n",
    "            key=\"period_type\",\n",
    "            match=qmodels.MatchValue(value=period_type)\n",
    "        ))\n",
    "\n",
    "    if must_have_hierarchy:\n",
    "        # hierarchy가 [\"자산\",\"유동자산\",\"현금및...\"] 처럼 리스트라고 가정\n",
    "        must.append(qmodels.FieldCondition(\n",
    "            key=\"hierarchy\",\n",
    "            match=qmodels.MatchAny(any=[must_have_hierarchy])\n",
    "        ))\n",
    "\n",
    "    if min_level is not None:\n",
    "        must.append(qmodels.FieldCondition(\n",
    "            key=\"level\",\n",
    "            range=qmodels.Range(gte=min_level)\n",
    "        ))\n",
    "\n",
    "    if exclude_totals:\n",
    "        must.append(qmodels.FieldCondition(\n",
    "            key=\"is_total\",\n",
    "            match=qmodels.MatchValue(value=False)\n",
    "        ))\n",
    "\n",
    "    if exclude_subtotals:\n",
    "        must.append(qmodels.FieldCondition(\n",
    "            key=\"is_subtotal\",\n",
    "            match=qmodels.MatchValue(value=False)\n",
    "        ))\n",
    "\n",
    "    return qmodels.Filter(must=must) if must else None\n",
    "\n",
    "\n",
    "# =============== dense_search ===============  ### CHANGED (핵심 수정)\n",
    "def dense_search(query: str, model, client, collection_name: str,\n",
    "                 top_k: int = 50, ground_truth=None,\n",
    "                 score_threshold: float = None,\n",
    "                 strict_children_of: str = None):\n",
    "    \"\"\"\n",
    "    Qdrant query_points 기반 Dense Retriever + 성능지표 계산\n",
    "    변경 사항:\n",
    "    - BGE 계열 권장: 쿼리에 \"query: \" 프리픽스 적용\n",
    "    - 서버 필터 강화: balance/current/연도/유동자산 포함/level>=3/토탈 제외\n",
    "    - 결과 중복 제거(account_id)\n",
    "    - strict_children_of(예: '유동자산') 재검증\n",
    "    - 결과 정렬(level, account_name)\n",
    "    - 필요 시 score 하한선 적용\n",
    "    \"\"\"\n",
    "    # 0) 연도 추출\n",
    "    year = extract_year_from_query(query)\n",
    "\n",
    "    # 1) 쿼리 임베딩 (BGE는 질의 프리픽스가 미세하게 도움됨)\n",
    "    qv = model.encode(\"query: \" + query, normalize_embeddings=True).tolist()  # ### CHANGED\n",
    "\n",
    "    # 2) 서버 필터 구성\n",
    "    query_filter = build_filter(\n",
    "        year=year,\n",
    "        statement_type=\"balance\",           # 재무상태표 강제\n",
    "        period_type=\"current\",              # 당기값 강제\n",
    "        must_have_hierarchy=strict_children_of or \"유동자산\",\n",
    "        min_level=3,                        # 하위계층만\n",
    "        exclude_totals=True,                # 합계 제외\n",
    "        exclude_subtotals=False             # 필요 시 True로\n",
    "    )\n",
    "\n",
    "    # 3) 검색 실행\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=qv,\n",
    "        limit=top_k,\n",
    "        with_payload=True,\n",
    "        query_filter=query_filter\n",
    "    )\n",
    "\n",
    "    # 4) 결과 정리 + 중복 제거(account_id)\n",
    "    seen_ids = set()\n",
    "    output = []\n",
    "    for r in results.points:\n",
    "        payload = r.payload or {}\n",
    "        text = payload.get(\"text\")\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # 메타 평탄화\n",
    "        meta = {}\n",
    "        if \"metadata\" in payload and isinstance(payload[\"metadata\"], dict):\n",
    "            meta.update(payload[\"metadata\"])\n",
    "        else:\n",
    "            meta.update({k: v for k, v in payload.items() if k != \"text\"})\n",
    "\n",
    "        # account_id 기준 중복 제거\n",
    "        account_id = meta.get(\"account_id\")\n",
    "        if account_id and account_id in seen_ids:\n",
    "            continue\n",
    "        if account_id:\n",
    "            seen_ids.add(account_id)\n",
    "\n",
    "        # 스코어 컷\n",
    "        if score_threshold is not None and r.score < score_threshold:\n",
    "            continue\n",
    "\n",
    "        # 엄격 재검증: hierarchy에 특정 노드가 반드시 포함되어야 함\n",
    "        if strict_children_of:\n",
    "            hier = meta.get(\"hierarchy\", [])\n",
    "            if isinstance(hier, list) and strict_children_of not in hier:\n",
    "                continue\n",
    "\n",
    "        result_item = {\"score\": r.score, \"text\": text}\n",
    "        result_item.update(meta)\n",
    "        output.append(result_item)\n",
    "\n",
    "    # 5) 가독 정렬: level 오름차순 → account_name\n",
    "    output.sort(key=lambda x: (x.get(\"level\", 999), str(x.get(\"account_name\", \"\"))))\n",
    "\n",
    "    # 6) 성능 지표 (옵션)\n",
    "    metrics = {}\n",
    "    if ground_truth:\n",
    "        normalized_gt = [extract_numbers(gt) for gt in ground_truth]\n",
    "        used = set()\n",
    "        relevances = []\n",
    "        for r in output[:top_k]:\n",
    "            nums = extract_numbers(r[\"text\"])\n",
    "            hit = 0\n",
    "            for gt in normalized_gt:\n",
    "                if gt and gt in nums and gt not in used:\n",
    "                    hit = 1\n",
    "                    used.add(gt)\n",
    "                    break\n",
    "            relevances.append(hit)\n",
    "\n",
    "        precision = sum(relevances) / top_k if top_k > 0 else 0.0\n",
    "        recall = min(sum(relevances), len(normalized_gt)) / len(normalized_gt) if normalized_gt else 0.0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0.0\n",
    "        rr = next((1.0 / (i+1) for i, rel in enumerate(relevances) if rel == 1), 0.0)\n",
    "        dcg = sum(rel / np.log2(i + 2) for i, rel in enumerate(relevances))\n",
    "        ideal_hits = min(len(normalized_gt), top_k)\n",
    "        idcg = sum(1.0 / np.log2(i + 2) for i in range(ideal_hits))\n",
    "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "        metrics = {\"Precision@3\": precision, \"Recall@3\": recall, \"F1@3\": f1, \"MRR\": rr, \"nDCG@3\": ndcg}\n",
    "\n",
    "    return output, metrics\n",
    "\n",
    "\n",
    "# =============== 간단 검색 출력 ===============  ### CHANGED (새 파라미터 반영)\n",
    "def simple_search_test(query: str, model, client, collection_name: str, top_k: int = 10,\n",
    "                       score_threshold: float = None, strict_children_of: str = None):\n",
    "    \"\"\"LLM 없이 검색 결과만 확인하는 함수\"\"\"\n",
    "    results, _ = dense_search(\n",
    "        query=query,\n",
    "        model=model,\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        top_k=top_k,\n",
    "        score_threshold=score_threshold,        # ### CHANGED\n",
    "        strict_children_of=strict_children_of   # ### CHANGED\n",
    "    )\n",
    "\n",
    "    print(f\"🔍 검색 결과 ({len(results)}개):\")\n",
    "    print(\"=\" * 100)\n",
    "\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. 스코어: {r['score']:.4f}\")\n",
    "        print(f\"   연도: {r.get('report_year', 'N/A')}\")\n",
    "        print(f\"   텍스트: {r['text'][:200]}...\")\n",
    "\n",
    "        metadata_keys = ['account_id', 'account_name', 'parent_id', 'level', 'hierarchy',\n",
    "                         'is_total', 'is_subtotal', 'period_type', 'statement_type']\n",
    "        metadata_info = []\n",
    "        for key in metadata_keys:\n",
    "            if key in r:\n",
    "                metadata_info.append(f\"{key}: {r[key]}\")\n",
    "        if metadata_info:\n",
    "            print(f\"   📊 메타데이터: {', '.join(metadata_info)}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# =============== RAG Pipeline (LLM 없이 검색만) ===============  ### CHANGED\n",
    "def rag_pipeline_simple(query: str, model, client, collection_name: str, top_k: int = 10,\n",
    "                        score_threshold: float = None, strict_children_of: str = None):\n",
    "    \"\"\"LLM 없이 검색 결과만 반환하는 간단한 RAG\"\"\"\n",
    "    print(f\"💬 질문: {query}\\n\")\n",
    "    results = simple_search_test(\n",
    "        query, model, client, collection_name, top_k=top_k,\n",
    "        score_threshold=score_threshold, strict_children_of=strict_children_of\n",
    "    )\n",
    "    print(f\"\\n📋 요약:\")\n",
    "    print(f\"   - 총 {len(results)}개의 관련 문서를 찾았습니다.\")\n",
    "    if results:\n",
    "        years = list({r.get('report_year') for r in results if r.get('report_year')})\n",
    "        if years:\n",
    "            print(f\"   - 관련 연도: {', '.join(map(str, sorted(years)))}\")\n",
    "        hierarchies = [r.get('hierarchy', []) for r in results if r.get('hierarchy')]\n",
    "        if hierarchies:\n",
    "            print(f\"   - 발견된 계층 정보: {len(hierarchies)}개\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# ===== Zephyr 모델 로드 (임시로 주석 처리) =====\n",
    "# model_path = Path(\"/Users/bag-yebin/Desktop/흠/자연어처리/samsun-audit-rag-qa/models/zephyr-7b-beta.Q4_K_M.gguf\").resolve()\n",
    "# llm = Llama(\n",
    "#     model_path=str(model_path),\n",
    "#     n_ctx=4096,\n",
    "#     n_threads=8,\n",
    "#     n_gpu_layers=35\n",
    "# )\n",
    "\n",
    "\n",
    "# =============== 실행 예시 ===============\n",
    "if __name__ == \"__main__\":\n",
    "    questions = [\n",
    "        \"2014년 재무상태표에서 당기 유동자산의 하위계층 정보를 전부 줘. metadata에서 hierarchy / level을 꼭 참고해.\"\n",
    "    ]\n",
    "\n",
    "    for q in questions:\n",
    "        print(\"=\" * 100)\n",
    "        # strict_children_of=\"유동자산\" 을 안전망으로 활용\n",
    "        results = rag_pipeline_simple(\n",
    "            q, embed_model, client, collection_name,\n",
    "            top_k=50,\n",
    "            score_threshold=0.55,           # 필요 시 조절\n",
    "            strict_children_of=\"유동자산\"   # '유동자산' subtree만\n",
    "        )\n",
    "        print(\"\\n\" + \"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa2aa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_load_from_file_impl: using device Metal (Apple M2 Pro) - 7888 MiB free\n",
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from /Users/dan/Desktop/snu_project/models/zephyr-7b-beta.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = huggingfaceh4_zephyr-7b-beta\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 4.07 GiB (4.83 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: printing all EOG tokens:\n",
      "load:   - 2 ('</s>')\n",
      "load: special tokens cache size = 3\n",
      "load: token to piece cache size = 0.1637 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 10000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.24 B\n",
      "print_info: general.name     = huggingfaceh4_zephyr-7b-beta\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32000\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: PAD token        = 2 '</s>'\n",
      "print_info: LF token         = 13 '<0x0A>'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  29 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  30 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  31 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  32 assigned to device Metal, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q4_K) (and 0 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "ggml_backend_metal_log_allocated_size: allocated buffer, size =  4095.08 MiB, ( 7129.45 / 10922.67)\n",
      "load_tensors: offloading 32 repeating layers to GPU\n",
      "load_tensors: offloading output layer to GPU\n",
      "load_tensors: offloaded 33/33 layers to GPU\n",
      "load_tensors: Metal_Mapped model buffer size =  4095.07 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =    70.31 MiB\n",
      "...............................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 4096\n",
      "llama_context: n_ctx_per_seq = 4096\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 10000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2 Pro\n",
      "ggml_metal_init: picking default device: Apple M2 Pro\n",
      "ggml_metal_load_library: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M2 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8  (1008)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has residency sets    = true\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_metal_init: loaded kernel_add                                    0x3484ffda0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_2                             0x347c65ca0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_3                             0x343a5c350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_4                             0x39505b4b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_5                             0x395059b80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_6                             0x39505a390 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_7                             0x343a2e0b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_8                             0x3a0f4fca0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4                             0x3a0f48570 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_2                      0x347dc91e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_3                      0x39dc9b0a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_4                      0x39dc9b840 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_5                      0x337d9dc60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_6                      0x39505de90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_7                      0x3a0f44e60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_8                      0x349780a90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                    0x337ddec20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row_c4                             0x39dc9baa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                    0x39dc9bd30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row_c4                             0x347d22830 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                    0x3438bb8d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row_c4                             0x39dc9bf90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_id                                 0x3438b1530 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                             0x3424171a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                             0x342352ae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                             0x34827d2b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                             0x39a2a83a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                                  0x106b0a6f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                                0x101305100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                                  0x3421f1f10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                   0x102a0dfa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                   0x106b09730 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                                0x3438c0f70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                   0x343856670 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                                 0x347a97720 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_erf                               0x102a0eb30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_erf_4                             0x39505e0f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                             0x10130b880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                           0x102a0f0d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                   0x102a0f330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                                 0x3a0f50220 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_elu                                    0x10130c9c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_abs                                    0x3438a3300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sgn                                    0x3a0f514d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_step                                   0x3480745f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_hardswish                              0x39dc9c1f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_hardsigmoid                            0x10130b3e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_exp                                    0x39505ecf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                           0x39dc9cbe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                         0x106104950 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                           0x10610cd90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                         0x10130c0f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                          0x10130cfc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                        0x106b0bc30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                           0x10130e6f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                           0x10610da60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                          0x10610e6d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                          0x39dc9ce70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                          0x3377c9640 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                          0x3423e52b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                          0x3377a33d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_mxfp4                         0x344d71530 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                          0x39dc9d0d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                          0x3486be330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                          0x3422aeb10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                          0x39dc9d330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                          0x34b8f4670 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                       0x39dc9d590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                        0x3455b8460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                       0x39dc9d7f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                         0x39dc9da50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                         0x39dc9dec0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                         0x3438830d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                         0x342205ac0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                        0x3427dff90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                        0x39dc9e120 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                           0x34672b7f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_f32                           0x3455b79f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_f16                           0x39a2a9840 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_set_rows_q8_0                          0x3a0f57c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q4_0                          0x3a0f54460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q4_1                          0x10610de40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q5_0                          0x3460c8a90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q5_1                          0x343888d20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_iq4_nl                        0x343894b60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                               0x102a10940 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm_mul                           0x334e445e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm_mul_add                       0x10130db10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_l2_norm                                0x106b0b310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                             0x348036310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                   0x3460f5170 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                           0x3a0f52460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                           0x3479eeb80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32_group                     0x34793a5c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv6_f32                          0x3427e0880 | th_max =  384 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv7_f32                          0x39a2a90c0 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                         0x39505e5d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32_c4                      0x39dc9e380 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                         0x345fa48c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_c4                      0x3a0f526c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                    0x347e95d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                      0x39dc9e5e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                         0x3427e0ae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                        0x3a0f60750 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                        0x39a2a9320 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                        0x3463180b0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                        0x3463a6960 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                        0x34bdbc640 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_mxfp4_f32                       0x39505e9e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_2                0x39a2a9dc0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_3                0x39a2aa020 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_4                0x39a2aa540 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_5                0x334e803a0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_2               0x3427e0d40 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_3               0x34bee9020 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_4               0x346359bf0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_5               0x334e84e10 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_2               0x39505f4b0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_3               0x34bd20b80 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_4               0x34646cd40 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_5               0x3464fbbd0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_2               0x34649da70 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_3               0x34baf21c0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_4               0x346553420 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_5               0x39a2aab80 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_2               0x39a2aade0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_3               0x334e26480 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_4               0x3466783e0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_5               0x346657390 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_2               0x3427e0fd0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_3               0x39a2ab0d0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_4               0x34ba62140 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_5               0x39505f710 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_2              0x39dc9e840 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_3              0x3a0f609b0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_4              0x3a0f60c10 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_5              0x34622e620 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_2               0x3a0f60ea0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_3               0x3a0f61100 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_4               0x3427e1260 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_5               0x39dc9ead0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_2               0x3950608f0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_3               0x395060e30 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_4               0x39a2abf70 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_5               0x344a603d0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_2               0x3a0f61390 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_3               0x334e11d00 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_4               0x3435b4240 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_5               0x334e928e0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_2             0x334e4deb0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_3             0x334e27920 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_4             0x334eb9180 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_5             0x346296880 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                        0x334e7b9e0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                        0x3427e14c0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                        0x39dc9ed60 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                        0x39a2ac540 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                        0x39dc9efc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                     0x3427e1780 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                      0x3427e19e0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                     0x327593c80 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                       0x3275fd2e0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                       0x34367a260 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                       0x34369e1e0 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                       0x343668740 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                      0x348f44810 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                      0x39a2ad5f0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                      0x3427e1c40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                      0x3a0f61620 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                     0x3a0f61880 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                     0x3436519b0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                     0x343607a30 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                     0x3427e1ea0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                     0x3487d4880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_mxfp4_f32                    0x3a0f61ae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                     0x3a0f61d40 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                     0x343670a50 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                     0x3a0f61fa0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                     0x3352abc70 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                     0x33523d290 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32                  0x3427e2100 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                   0x3374d0340 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32                  0x3275a5b20 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                    0x3427e2360 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                    0x3427e25c0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                    0x3a0f62200 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                    0x3a0f62460 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                   0x39a2addc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                   0x3a0f626c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                         0x3950615b0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                         0x39a2ac8c0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                        0x3275cce00 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                        0x3a0f62920 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_0_f32                        0x3a0f62b80 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_1_f32                        0x39dc9f220 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                        0x39a2acfe0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_mxfp4_f32                       0x335b1a9f0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_mxfp4_f32                       0x3427e2820 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                        0x39dc9f480 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                        0x335bafcd0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                        0x335baaba0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                        0x3427e2a80 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                        0x3427e2ce0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xxs_f32                     0x33524bd60 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xs_f32                      0x39dc9f6e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_xxs_f32                     0x39dc9f940 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_s_f32                       0x395062690 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_s_f32                       0x335267400 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_s_f32                       0x395062dd0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_m_f32                       0x395063030 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_nl_f32                      0x39dc9fba0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_xs_f32                      0x3375e6110 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_map0_f16                     0x39a2af0c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_map1_f32                     0x39dc9fe00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f32_f16                      0x39a2af840 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f16_f16                      0x39dca0060 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_0_f16                     0x3352e9b00 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_1_f16                     0x39a2aff50 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_0_f16                     0x39dca02c0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_1_f16                     0x3352f4fd0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q8_0_f16                     0x3352be420 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_mxfp4_f16                    0x3a0f62de0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q2_K_f16                     0x3a0f63040 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q3_K_f16                     0x395063760 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_K_f16                     0x3a0f632a0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_K_f16                     0x348bbb230 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q6_K_f16                     0x3a0f63500 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xxs_f16                  0x335bcd990 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xs_f16                   0x3363b8a70 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_xxs_f16                  0x3a0f63760 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_s_f16                    0x3a0f639c0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_s_f16                    0x3a0f63c20 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_s_f16                    0x3352702f0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_m_f16                    0x3363390b0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_nl_f16                   0x395063290 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_xs_f16                   0x39dca0520 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                          0x3a0f63e80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                          0x3427e2f40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_multi_f32                         0x3427e31d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_multi_f16                         0x3434b3b80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_vision_f32                        0x343b0d3e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_vision_f16                        0x395075900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                          0x3a0f640e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                          0x3a0f64340 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                             0x33636e080 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                             0x34340e070 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                         0x39dca0780 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                         0x3427e3460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f32_f32              0x348518f20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f16_f32              0x39dca09e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                            0x39dca0c40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                                0x337bf6c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_reflect_1d_f32                     0x3a0f64630 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32                 0x3a0f64890 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                             0x337bab760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                    0x3a0f64af0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                   0x39a2ae910 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                         0x395076e10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h64                 0x395077440 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h80                 0x395077c10 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h96                 0x3950781f0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h112                0x3427e36c0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h128                0x336daa140 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h192                0x3427e3920 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk192_hv128         0x343b697b0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h256                0x3363f5e50 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk576_hv512         0x33630d360 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h64                0x336382f00 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h80                0x39a2b0750 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h96                0x3427e3bd0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h112               0x3427e3e70 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h128               0x343b80f30 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h192               0x395078450 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk192_hv128        0x3363c1910 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h256               0x395076750 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk576_hv512        0x106b0c790 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h64                0x10610ed20 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h80                0x10130ef50 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h96                0x10610f470 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h112               0x336d559d0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h128               0x3363b2d50 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h192               0x347544e80 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk192_hv128        0x3454972b0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h256               0x3427e40d0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk576_hv512        0x102a11080 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h64                0x3427e4330 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h80                0x39dca0ed0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h96                0x39dca1160 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h112               0x106b0c9f0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h128               0x3a0f64d50 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h192               0x106b0d0a0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk192_hv128        0x3454d9e20 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h256               0x10130f6d0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk576_hv512        0x10130f930 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h64                0x106b0d930 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h80                0x3427e4590 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h96                0x102a11810 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h112               0x106b0ea50 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h128               0x3a0f64fb0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h192               0x101310920 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk192_hv128        0x3a0f65270 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h256               0x106110310 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk576_hv512        0x343b47380 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h64                0x395079230 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h80                0x3427e47f0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h96                0x3475875d0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h112               0x3427e4ab0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h128               0x3475410f0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h192               0x39a2b1090 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk192_hv128        0x336ed01f0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h256               0x336e217e0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk576_hv512        0x343b601b0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h64             0x344eea2d0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h64            0x3a0f654d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h64            0x33586ee70 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h64            0x3358080f0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h64            0x3427e4d40 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h64            0x344e76810 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h96             0x344e790b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h96            0x3373f7000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h96            0x33587fef0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h96            0x343bd0990 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h96            0x39a2b1820 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h96            0x343bd4650 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128            0x335818e10 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128           0x395079a10 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128           0x3358ee850 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128           0x3358426e0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128           0x106b0f260 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128           0x33585c920 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h192            0x3358f9b60 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h192           0x3a0f65730 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h192           0x3439a8b80 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h192           0x3a0f65990 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h192           0x33730a550 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h192           0x3427e4fd0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk192_hv128      0x3427e5260 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk192_hv128      0x3a0f65bf0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk192_hv128      0x3a0f65f40 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk192_hv128      0x3439c7f60 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk192_hv128      0x3427e54c0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk192_hv128      0x39507a1e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256            0x343920170 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256           0x3427e5720 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256           0x3a0f661a0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256           0x3439ed540 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256           0x39dca13c0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256           0x3439d7840 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk576_hv512      0x3427e5980 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk576_hv512      0x3427e5be0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk576_hv512      0x344fa2140 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk576_hv512      0x33620f420 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk576_hv512      0x3362517f0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk576_hv512      0x3427e5f00 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_f32                                0x3427e6160 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_i32                                0x33626c310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                            0x344f209c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                            0x3362ba610 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                            0x39507ae80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                            0x39507b5f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                           0x33620b2a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                           0x34391cd10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                           0x336273660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                           0x33764d550 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                           0x336275860 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                         0x3427e63c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f32                           0x3376c6880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f16                           0x337612880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f32                           0x3427e6620 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f16                           0x39507c2f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f32                           0x335704710 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f16                           0x3376adf80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f32                           0x336bf9de0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f16                           0x335740150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f32                           0x335707c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f16                           0x34393fa20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                                 0x3357ac5f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                    0x39a2b0c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                   0x3a0f66430 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                    0x3427e6b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                    0x343915b10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_neg                                    0x39507bd70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_reglu                                  0x336b90110 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu                                  0x33576c630 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_swiglu                                 0x3357a6870 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_swiglu_oai                             0x3427e6d60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu_erf                              0x39507c630 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu_quick                            0x3439e1580 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                               0x3357de300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mean                                   0x33617e220 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argmax                                 0x345ef9300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                        0x3361b56c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                        0x345e7de90 | th_max = 1024 | th_width =   32\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.12 MiB\n",
      "create_memory: n_ctx = 4096 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = Metal\n",
      "llama_kv_cache_unified: layer   1: dev = Metal\n",
      "llama_kv_cache_unified: layer   2: dev = Metal\n",
      "llama_kv_cache_unified: layer   3: dev = Metal\n",
      "llama_kv_cache_unified: layer   4: dev = Metal\n",
      "llama_kv_cache_unified: layer   5: dev = Metal\n",
      "llama_kv_cache_unified: layer   6: dev = Metal\n",
      "llama_kv_cache_unified: layer   7: dev = Metal\n",
      "llama_kv_cache_unified: layer   8: dev = Metal\n",
      "llama_kv_cache_unified: layer   9: dev = Metal\n",
      "llama_kv_cache_unified: layer  10: dev = Metal\n",
      "llama_kv_cache_unified: layer  11: dev = Metal\n",
      "llama_kv_cache_unified: layer  12: dev = Metal\n",
      "llama_kv_cache_unified: layer  13: dev = Metal\n",
      "llama_kv_cache_unified: layer  14: dev = Metal\n",
      "llama_kv_cache_unified: layer  15: dev = Metal\n",
      "llama_kv_cache_unified: layer  16: dev = Metal\n",
      "llama_kv_cache_unified: layer  17: dev = Metal\n",
      "llama_kv_cache_unified: layer  18: dev = Metal\n",
      "llama_kv_cache_unified: layer  19: dev = Metal\n",
      "llama_kv_cache_unified: layer  20: dev = Metal\n",
      "llama_kv_cache_unified: layer  21: dev = Metal\n",
      "llama_kv_cache_unified: layer  22: dev = Metal\n",
      "llama_kv_cache_unified: layer  23: dev = Metal\n",
      "llama_kv_cache_unified: layer  24: dev = Metal\n",
      "llama_kv_cache_unified: layer  25: dev = Metal\n",
      "llama_kv_cache_unified: layer  26: dev = Metal\n",
      "llama_kv_cache_unified: layer  27: dev = Metal\n",
      "llama_kv_cache_unified: layer  28: dev = Metal\n",
      "llama_kv_cache_unified: layer  29: dev = Metal\n",
      "llama_kv_cache_unified: layer  30: dev = Metal\n",
      "llama_kv_cache_unified: layer  31: dev = Metal\n",
      "llama_kv_cache_unified:      Metal KV buffer size =   512.00 MiB\n",
      "llama_kv_cache_unified: size =  512.00 MiB (  4096 cells,  32 layers,  1/1 seqs), K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 3\n",
      "llama_context: max_nodes = 2328\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:      Metal compute buffer size =   300.01 MiB\n",
      "llama_context:        CPU compute buffer size =    20.01 MiB\n",
      "llama_context: graph nodes  = 1126\n",
      "llama_context: graph splits = 2\n",
      "Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | DOTPROD = 1 | ACCELERATE = 1 | REPACK = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.padding_token_id': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '10000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'huggingfaceh4_zephyr-7b-beta'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "💬 질문: 2014년 재무상태표에서 당기 비유동자산의 하위계층 정보를 전부 줘. metadata에서 hierarchy / level을 꼭 참고해.\n",
      "\n",
      "🔍 검색 결과 (7개):\n",
      "====================================================================================================\n",
      "\n",
      "1. 스코어: 0.5709\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 기타비유동자산는 1,694,436백만원입니다....\n",
      "   📊 메타데이터: account_id: 자산_비유동자산_기타비유동자산, account_name: 기타비유동자산, parent_id: 자산_비유동자산, level: 3, hierarchy: ['비유동자산', '기타비유동자산'], is_total: False, is_subtotal: True, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. 스코어: 0.5290\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 무형자산는 3,051,564백만원입니다. 주석: 14...\n",
      "   📊 메타데이터: account_id: 자산_비유동자산_무형자산, account_name: 무형자산, parent_id: 자산_비유동자산, level: 3, hierarchy: ['비유동자산', '무형자산'], is_total: False, is_subtotal: True, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. 스코어: 0.4806\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 순확정급여자산는 135,951백만원입니다. 주석: 17...\n",
      "   📊 메타데이터: account_id: 자산_비유동자산_순확정급여자산, account_name: 순확정급여자산, parent_id: 자산_비유동자산, level: 3, hierarchy: ['비유동자산', '순확정급여자산'], is_total: False, is_subtotal: True, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "4. 스코어: 0.5072\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 유형자산는 43,744,259백만원입니다. 주석: 13...\n",
      "   📊 메타데이터: account_id: 자산_비유동자산_유형자산, account_name: 유형자산, parent_id: 자산_비유동자산, level: 3, hierarchy: ['비유동자산', '유형자산'], is_total: False, is_subtotal: True, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "5. 스코어: 0.4657\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 장기매도가능금융자산는 7,106,234백만원입니다. 주석: 6, 9...\n",
      "   📊 메타데이터: account_id: 자산_비유동자산_장기매도가능금융자산, account_name: 장기매도가능금융자산, parent_id: 자산_비유동자산, level: 3, hierarchy: ['비유동자산', '장기매도가능금융자산'], is_total: False, is_subtotal: True, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "6. 스코어: 0.4131\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 장기선급비용는 4,415,935백만원입니다....\n",
      "   📊 메타데이터: account_id: 자산_비유동자산_장기선급비용, account_name: 장기선급비용, parent_id: 자산_비유동자산, level: 3, hierarchy: ['비유동자산', '장기선급비용'], is_total: False, is_subtotal: True, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "7. 스코어: 0.4869\n",
      "   연도: 2014\n",
      "   텍스트: 재무상태표에서 2014년 (당기) 종속기업,관계기업및공동기업투자는 41,857,431백만원입니다. 주석: 12...\n",
      "   📊 메타데이터: account_id: 자산_비유동자산_종속기업,관계기업및공동기업투자, account_name: 종속기업,관계기업및공동기업투자, parent_id: 자산_비유동자산, level: 3, hierarchy: ['비유동자산', '종속기업,관계기업및공동기업투자'], is_total: False, is_subtotal: True, period_type: current, statement_type: balance\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 요약:\n",
      "   - 총 7개의 관련 문서를 찾았습니다.\n",
      "   - 관련 연도: 2014\n",
      "   - 발견된 계층 정보: 7개\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "# from llama_cpp import Llama  # 임시로 주석 처리 (모듈이 설치되어 있지 않음)\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import re\n",
    "from qdrant_client.http import models as qmodels\n",
    "\n",
    "# ===== 임베딩 모델 로드 =====\n",
    "embed_model = SentenceTransformer(\"dragonkue/bge-m3-ko\")\n",
    "\n",
    "# ===== Qdrant 클라이언트 =====\n",
    "QDRANT_PATH = \"/Users/dan/Desktop/snu_project/git_제출용/data/vector_store/final-sjchunk/bge-ko-qdrant_db\"\n",
    "client = QdrantClient(path=QDRANT_PATH)\n",
    "\n",
    "collection_name = \"audit_chunks\"\n",
    "\n",
    "# ================== 유틸 ==================\n",
    "KOREAN_SPACE_RE = re.compile(r\"(?:[가-힣]\\s)+(?:[가-힣])\")\n",
    "def collapse_ko_spaced(s: str) -> str:\n",
    "    \"\"\"'유  동  자  산' -> '유동자산'\"\"\"\n",
    "    if not s:\n",
    "        return s\n",
    "    return s.replace(\" \", \"\") if KOREAN_SPACE_RE.fullmatch(s) else s\n",
    "\n",
    "def extract_year_from_query(query: str):\n",
    "    m = re.search(r\"(20\\d{2}|19\\d{2})\", query)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def extract_numbers(text: str) -> str:\n",
    "    if text is None: return \"\"\n",
    "    return \"\".join(re.findall(r\"\\d+\", text.replace(\",\", \"\")))\n",
    "\n",
    "def detect_statement_type(query: str) -> str:\n",
    "    q = query.replace(\" \", \"\")\n",
    "    if \"재무상태표\" in q or \"대차대조표\" in q: return \"balance\"\n",
    "    if \"손익계산서\" in q or \"포괄손익\" in q: return \"income\"\n",
    "    if \"현금흐름표\" in q: return \"cashflow\"\n",
    "    if \"자본변동표\" in q: return \"equity_changes\"\n",
    "    # 기본값(질문에 없으면 재무상태표로 가정)\n",
    "    return \"balance\"\n",
    "\n",
    "# ================== Qdrant Filter 빌더 ==================\n",
    "def build_filter(\n",
    "    year: int = None,\n",
    "    statement_type: str = None,\n",
    "    period_type: str = None,\n",
    "    must_have_hierarchy: str = None,  # 리스트 포함 체크\n",
    "    parent_id: str = None,\n",
    "    min_level: int = None,\n",
    "    exclude_totals: bool = True,\n",
    "    exclude_subtotals: bool = False,\n",
    "):\n",
    "    must = []\n",
    "    if year is not None:\n",
    "        must.append(qmodels.FieldCondition(key=\"report_year\", match=qmodels.MatchValue(value=year)))\n",
    "    if statement_type:\n",
    "        must.append(qmodels.FieldCondition(key=\"statement_type\", match=qmodels.MatchValue(value=statement_type)))\n",
    "    if period_type:\n",
    "        must.append(qmodels.FieldCondition(key=\"period_type\", match=qmodels.MatchValue(value=period_type)))\n",
    "    if must_have_hierarchy:\n",
    "        must.append(qmodels.FieldCondition(key=\"hierarchy\", match=qmodels.MatchAny(any=[must_have_hierarchy])))\n",
    "    if parent_id:\n",
    "        must.append(qmodels.FieldCondition(key=\"parent_id\", match=qmodels.MatchValue(value=parent_id)))\n",
    "    if min_level is not None:\n",
    "        must.append(qmodels.FieldCondition(key=\"level\", range=qmodels.Range(gte=min_level)))\n",
    "    if exclude_totals:\n",
    "        must.append(qmodels.FieldCondition(key=\"is_total\", match=qmodels.MatchValue(value=False)))\n",
    "    if exclude_subtotals:\n",
    "        must.append(qmodels.FieldCondition(key=\"is_subtotal\", match=qmodels.MatchValue(value=False)))\n",
    "    return qmodels.Filter(must=must) if must else None\n",
    "\n",
    "# ================== Parent 자동 탐색 ==================\n",
    "def resolve_parent_node(\n",
    "    query: str,\n",
    "    client: QdrantClient,\n",
    "    collection_name: str,\n",
    "    year: int,\n",
    "    statement_type: str = \"balance\",\n",
    "    period_type: str = \"current\",\n",
    "    level: int = 2,\n",
    "    top_k: int = 10,\n",
    "):\n",
    "    \"\"\"\n",
    "    질의에서 '부모 노드'(예: 유동자산, 비유동자산, 유동부채 등)를 자동으로 찾아 반환.\n",
    "    - 방법: 쿼리 임베딩 + 서버 필터(year/statement/current/level=2)로 상위 후보를 받고,\n",
    "            후보의 account_name/hierarchy 말단이 질의 문자열에 등장하는지 우선 매칭.\n",
    "    - 반환: dict(account_id, account_name, hierarchy, level, report_year, ...)\n",
    "    \"\"\"\n",
    "    # 1) 필터: 해당 연도, 표 종류, 당기, level=2 (부모 레벨)\n",
    "    filt = build_filter(\n",
    "        year=year,\n",
    "        statement_type=statement_type,\n",
    "        period_type=period_type,\n",
    "        min_level=level,\n",
    "        exclude_totals=True,\n",
    "        exclude_subtotals=False,\n",
    "    )\n",
    "    # 2) 질의 임베딩\n",
    "    qv = embed_model.encode(\"query: \" + query, normalize_embeddings=True).tolist()\n",
    "    # 3) 검색\n",
    "    res = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=qv,\n",
    "        limit=top_k,\n",
    "        with_payload=True,\n",
    "        query_filter=filt\n",
    "    )\n",
    "\n",
    "    # 4) 후보 중 '질문에 이름이 직접 등장'하는 것을 우선 선택\n",
    "    q_norm = collapse_ko_spaced(query.replace(\" \", \"\"))\n",
    "    best = None\n",
    "    for p in res.points:\n",
    "        payload = p.payload or {}\n",
    "        meta = payload.get(\"metadata\", payload)\n",
    "        name = collapse_ko_spaced(str(meta.get(\"account_name\", \"\")))\n",
    "        # hierarchy의 말단 노드명도 검사\n",
    "        last_h = \"\"\n",
    "        hier = meta.get(\"hierarchy\", [])\n",
    "        if isinstance(hier, list) and len(hier) > 0:\n",
    "            last_h = collapse_ko_spaced(str(hier[-1]))\n",
    "        # 직접 문자열 매칭\n",
    "        hit = False\n",
    "        if name and name in q_norm:\n",
    "            hit = True\n",
    "        elif last_h and last_h in q_norm:\n",
    "            hit = True\n",
    "        # '유동 자산'처럼 띄어쓰기 포함 질의를 대비해 축약 매칭도 검사 (이미 q_norm에서 공백 제거)\n",
    "        if hit:\n",
    "            best = meta\n",
    "            break\n",
    "\n",
    "    # 5) 매칭이 없다면 스코어 1순위로\n",
    "    if not best and res.points:\n",
    "        best_payload = res.points[0].payload or {}\n",
    "        best = best_payload.get(\"metadata\", best_payload)\n",
    "\n",
    "    return best  # 실패 시 None\n",
    "\n",
    "# ================== 자식 전량 회수(scroll) ==================\n",
    "def scroll_children_by_parent(\n",
    "    client: QdrantClient,\n",
    "    collection_name: str,\n",
    "    year: int,\n",
    "    parent_id: str,\n",
    "    statement_type: str = \"balance\",\n",
    "    period_type: str = \"current\",\n",
    "    min_level: int = 3,\n",
    "    exclude_totals: bool = True,\n",
    "    exclude_subtotals: bool = False,\n",
    "    limit: int = 256\n",
    "):\n",
    "    filt = build_filter(\n",
    "        year=year,\n",
    "        statement_type=statement_type,\n",
    "        period_type=period_type,\n",
    "        parent_id=parent_id,\n",
    "        min_level=min_level,\n",
    "        exclude_totals=exclude_totals,\n",
    "        exclude_subtotals=exclude_subtotals\n",
    "    )\n",
    "    out = []\n",
    "    next_offset = None\n",
    "    while True:\n",
    "        points, next_offset = client.scroll(\n",
    "            collection_name=collection_name,\n",
    "            scroll_filter=filt,\n",
    "            with_payload=True,\n",
    "            with_vectors=False,\n",
    "            limit=limit,\n",
    "            offset=next_offset\n",
    "        )\n",
    "        for p in points:\n",
    "            payload = p.payload or {}\n",
    "            text = payload.get(\"text\")\n",
    "            if not text:\n",
    "                continue\n",
    "            meta = payload.get(\"metadata\", {})\n",
    "            if not meta:\n",
    "                meta = {k: v for k, v in payload.items() if k != \"text\"}\n",
    "            item = {\"score\": None, \"text\": text}\n",
    "            item.update(meta)\n",
    "            out.append(item)\n",
    "        if not next_offset:\n",
    "            break\n",
    "    out.sort(key=lambda x: (x.get(\"level\", 999), str(x.get(\"account_name\", \"\"))))\n",
    "    return out\n",
    "\n",
    "# ================== Dense Search (자동 parent 사용) ==================\n",
    "def dense_search(query: str, model, client, collection_name: str,\n",
    "                 top_k: int = 50, ground_truth=None,\n",
    "                 score_threshold: float = None,\n",
    "                 strict_children_of: str = None,\n",
    "                 fallback_min_hits: int = 6):\n",
    "    \"\"\"\n",
    "    1) 질의로부터 연도/표종류/부모노드 자동 추정\n",
    "    2) 부모 account_id를 parent_id_hint로 사용하여 자식 검색\n",
    "    3) 부족하면 scroll로 전량 보강\n",
    "    \"\"\"\n",
    "    # 0) 연도/표종류 추론\n",
    "    year = extract_year_from_query(query)\n",
    "    statement_type = detect_statement_type(query)\n",
    "    period_type = \"current\"  # 질문이 '당기' 중심이므로 기본값 current\n",
    "\n",
    "    # 연도는 반드시 필요. 없다면 필터 약화(=전 연도) 대신 결과 품질 위해 None 허용 but fallback에서 year 필요\n",
    "    # → year 없으면 우선 dense만 수행하고, fallback은 생략하거나 가장 최근 연도 찾기 로직 추가 가능\n",
    "    # 여기서는 year 없으면 fallback 생략\n",
    "    # 1) 부모 노드 자동 탐색\n",
    "    parent_meta = None\n",
    "    if year is not None:\n",
    "        parent_meta = resolve_parent_node(\n",
    "            query=query,\n",
    "            client=client,\n",
    "            collection_name=collection_name,\n",
    "            year=year,\n",
    "            statement_type=statement_type,\n",
    "            period_type=period_type,\n",
    "            level=2,\n",
    "            top_k=10\n",
    "        )\n",
    "\n",
    "    # 2) 쿼리 임베딩\n",
    "    qv = model.encode(\"query: \" + query, normalize_embeddings=True).tolist()\n",
    "\n",
    "    # 3) 서버 필터 구성 (부모를 찾았으면 parent_id 강제)\n",
    "    query_filter = build_filter(\n",
    "        year=year,\n",
    "        statement_type=statement_type,\n",
    "        period_type=period_type,\n",
    "        parent_id=parent_meta.get(\"account_id\") if parent_meta else None,\n",
    "        min_level=3,\n",
    "        exclude_totals=True,\n",
    "        exclude_subtotals=False\n",
    "    )\n",
    "\n",
    "    # 4) 검색 실행\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=qv,\n",
    "        limit=top_k,\n",
    "        with_payload=True,\n",
    "        query_filter=query_filter\n",
    "    )\n",
    "\n",
    "    # 5) 결과 정리 + 중복 제거\n",
    "    seen_ids = set()\n",
    "    output = []\n",
    "    for r in results.points:\n",
    "        payload = r.payload or {}\n",
    "        text = payload.get(\"text\")\n",
    "        if not text:\n",
    "            continue\n",
    "        meta = payload.get(\"metadata\", {})\n",
    "        if not meta:\n",
    "            meta = {k: v for k, v in payload.items() if k != \"text\"}\n",
    "\n",
    "        account_id = meta.get(\"account_id\")\n",
    "        if account_id and account_id in seen_ids:\n",
    "            continue\n",
    "        if account_id:\n",
    "            seen_ids.add(account_id)\n",
    "\n",
    "        if score_threshold is not None and r.score < score_threshold:\n",
    "            continue\n",
    "\n",
    "        if strict_children_of:\n",
    "            hier = meta.get(\"hierarchy\", [])\n",
    "            if isinstance(hier, list) and strict_children_of not in hier:\n",
    "                continue\n",
    "\n",
    "        item = {\"score\": r.score, \"text\": text}\n",
    "        item.update(meta)\n",
    "        output.append(item)\n",
    "\n",
    "    # 6) 가독 정렬\n",
    "    output.sort(key=lambda x: (x.get(\"level\", 999), str(x.get(\"account_name\", \"\"))))\n",
    "\n",
    "    # 7) Fallback: 결과가 부족할 때 parent_id로 전체 회수\n",
    "    if year is not None and parent_meta and len(output) < fallback_min_hits:\n",
    "        fallback_items = scroll_children_by_parent(\n",
    "            client=client,\n",
    "            collection_name=collection_name,\n",
    "            year=year,\n",
    "            parent_id=parent_meta[\"account_id\"],\n",
    "            statement_type=statement_type,\n",
    "            period_type=period_type,\n",
    "            min_level=3,\n",
    "            exclude_totals=True,\n",
    "            exclude_subtotals=False\n",
    "        )\n",
    "        # 병합(중복 제거)\n",
    "        by_id = {x.get(\"account_id\"): x for x in output if x.get(\"account_id\")}\n",
    "        for it in fallback_items:\n",
    "            aid = it.get(\"account_id\")\n",
    "            if aid and aid not in by_id:\n",
    "                by_id[aid] = it\n",
    "        output = list(by_id.values())\n",
    "        output.sort(key=lambda x: (x.get(\"level\", 999), str(x.get(\"account_name\", \"\"))))\n",
    "\n",
    "    # 8) 메트릭(옵션)\n",
    "    metrics = {}\n",
    "    if ground_truth:\n",
    "        normalized_gt = [extract_numbers(gt) for gt in ground_truth]\n",
    "        used = set()\n",
    "        relevances = []\n",
    "        for r in output[:top_k]:\n",
    "            nums = extract_numbers(r[\"text\"])\n",
    "            hit = 0\n",
    "            for gt in normalized_gt:\n",
    "                if gt and gt in nums and gt not in used:\n",
    "                    hit = 1\n",
    "                    used.add(gt)\n",
    "                    break\n",
    "            relevances.append(hit)\n",
    "\n",
    "        precision = sum(relevances) / top_k if top_k > 0 else 0.0\n",
    "        recall = min(sum(relevances), len(normalized_gt)) / len(normalized_gt) if normalized_gt else 0.0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0.0\n",
    "        rr = next((1.0 / (i+1) for i, rel in enumerate(relevances) if rel == 1), 0.0)\n",
    "        dcg = sum(rel / np.log2(i + 2) for i, rel in enumerate(relevances))\n",
    "        ideal_hits = min(len(normalized_gt), top_k)\n",
    "        idcg = sum(1.0 / np.log2(i + 2) for i in range(ideal_hits))\n",
    "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    "        metrics = {\"Precision@3\": precision, \"Recall@3\": recall, \"F1@3\": f1, \"MRR\": rr, \"nDCG@3\": ndcg}\n",
    "\n",
    "    return output, metrics\n",
    "\n",
    "# ================== 출력 헬퍼 ==================\n",
    "def simple_search_test(query: str, model, client, collection_name: str, top_k: int = 10,\n",
    "                       score_threshold: float = None, strict_children_of: str = None,\n",
    "                       fallback_min_hits: int = 6):\n",
    "    results, _ = dense_search(\n",
    "        query=query,\n",
    "        model=model,\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        top_k=top_k,\n",
    "        score_threshold=score_threshold,\n",
    "        strict_children_of=strict_children_of,\n",
    "        fallback_min_hits=fallback_min_hits\n",
    "    )\n",
    "    print(f\"🔍 검색 결과 ({len(results)}개):\")\n",
    "    print(\"=\" * 100)\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. 스코어: {r.get('score', 0) if r.get('score') is not None else float('nan'):.4f}\")\n",
    "        print(f\"   연도: {r.get('report_year', 'N/A')}\")\n",
    "        print(f\"   텍스트: {r['text'][:200]}...\")\n",
    "        metadata_keys = ['account_id', 'account_name', 'parent_id', 'level', 'hierarchy',\n",
    "                         'is_total', 'is_subtotal', 'period_type', 'statement_type']\n",
    "        metadata_info = []\n",
    "        for key in metadata_keys:\n",
    "            if key in r:\n",
    "                metadata_info.append(f\"{key}: {r[key]}\")\n",
    "        if metadata_info:\n",
    "            print(f\"   📊 메타데이터: {', '.join(metadata_info)}\")\n",
    "        print(\"-\" * 80)\n",
    "    return results\n",
    "\n",
    "def rag_pipeline_simple(query: str, model, client, collection_name: str, top_k: int = 10,\n",
    "                        score_threshold: float = None, strict_children_of: str = None,\n",
    "                        fallback_min_hits: int = 6):\n",
    "    print(f\"💬 질문: {query}\\n\")\n",
    "    results = simple_search_test(\n",
    "        query, model, client, collection_name, top_k=top_k,\n",
    "        score_threshold=score_threshold, strict_children_of=strict_children_of,\n",
    "        fallback_min_hits=fallback_min_hits\n",
    "    )\n",
    "    print(f\"\\n📋 요약:\")\n",
    "    print(f\"   - 총 {len(results)}개의 관련 문서를 찾았습니다.\")\n",
    "    if results:\n",
    "        years = list({r.get('report_year') for r in results if r.get('report_year')})\n",
    "        if years:\n",
    "            print(f\"   - 관련 연도: {', '.join(map(str, sorted(years)))}\")\n",
    "        hierarchies = [r.get('hierarchy', []) for r in results if r.get('hierarchy')]\n",
    "        if hierarchies:\n",
    "            print(f\"   - 발견된 계층 정보: {len(hierarchies)}개\")\n",
    "    return results\n",
    "\n",
    "# ===== Zephyr 모델 로드 =====\n",
    "model_path = Path(\"/Users/dan/Desktop/snu_project/models/zephyr-7b-beta.Q4_K_M.gguf\").resolve()\n",
    "\n",
    "from llama_cpp import Llama\n",
    "llm = Llama(\n",
    "    model_path=str(model_path),\n",
    "    n_ctx=4096,\n",
    "    n_threads=8,\n",
    "    n_gpu_layers=35  # Apple Silicon의 경우 Metal GPU 사용\n",
    ")\n",
    "\n",
    "# ================== 실행 예시 ==================\n",
    "if __name__ == \"__main__\":\n",
    "    questions = [\n",
    "        \"2014년 재무상태표에서 당기 비유동자산의 하위계층 정보를 전부 줘. metadata에서 hierarchy / level을 꼭 참고해.\"\n",
    "    ]\n",
    "    for q in questions:\n",
    "        print(\"=\" * 100)\n",
    "        results = rag_pipeline_simple(\n",
    "            q, embed_model, client, collection_name,\n",
    "            top_k=50,\n",
    "            score_threshold=0.0,      # 컷 없이 다 모으고 부족하면 fallback\n",
    "            strict_children_of=None,  # parent 자동 해석을 쓰므로 굳이 필요 없음\n",
    "            fallback_min_hits=8\n",
    "        )\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a4fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
