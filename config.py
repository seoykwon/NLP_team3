"""
NLP Team3 - ë²¡í„° DB ì„¤ì • íŒŒì¼
íŒ€ì›ë³„ë¡œ ì´ íŒŒì¼ë§Œ ìˆ˜ì •í•˜ë©´ ë©ë‹ˆë‹¤.
"""

import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (ìë™ ê°ì§€)
PROJECT_ROOT = Path(__file__).parent

# ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •
DATA_PATHS = {
    'annotation': {
        2014: PROJECT_ROOT / "ì•„ì¹´ì´ë¸Œ" / "ê°ì‚¬ë³´ê³ ì„œ_2014_parsed.json",
        2015: PROJECT_ROOT / "ì•„ì¹´ì´ë¸Œ" / "ê°ì‚¬ë³´ê³ ì„œ_2015_parsed.json", 
        2016: PROJECT_ROOT / "ì•„ì¹´ì´ë¸Œ" / "ê°ì‚¬ë³´ê³ ì„œ_2016_parsed.json",
        2017: PROJECT_ROOT / "ì•„ì¹´ì´ë¸Œ" / "ê°ì‚¬ë³´ê³ ì„œ_2017_parsed.json",
        2018: PROJECT_ROOT / "ì•„ì¹´ì´ë¸Œ" / "ê°ì‚¬ë³´ê³ ì„œ_2018_parsed.json",
        2019: PROJECT_ROOT / "ì•„ì¹´ì´ë¸Œ" / "ê°ì‚¬ë³´ê³ ì„œ_2019_parsed.json",
        2020: PROJECT_ROOT / "ì•„ì¹´ì´ë¸Œ" / "ê°ì‚¬ë³´ê³ ì„œ_2020_parsed.json",
        2021: PROJECT_ROOT / "ì•„ì¹´ì´ë¸Œ" / "ê°ì‚¬ë³´ê³ ì„œ_2021_parsed.json",
        2022: PROJECT_ROOT / "ì•„ì¹´ì´ë¸Œ" / "ê°ì‚¬ë³´ê³ ì„œ_2022_parsed.json",
        2023: PROJECT_ROOT / "ì•„ì¹´ì´ë¸Œ" / "ê°ì‚¬ë³´ê³ ì„œ_2023_parsed.json",
        2024: PROJECT_ROOT / "ì•„ì¹´ì´ë¸Œ" / "ê°ì‚¬ë³´ê³ ì„œ_2024_parsed.json"
    },
    'financial_table': {
        2014: PROJECT_ROOT / "table_parsing" / "ê°ì‚¬ë³´ê³ ì„œ_2014_parsed.json",
        2015: PROJECT_ROOT / "table_parsing" / "ê°ì‚¬ë³´ê³ ì„œ_2015_parsed.json",
        2016: PROJECT_ROOT / "table_parsing" / "ê°ì‚¬ë³´ê³ ì„œ_2016_parsed.json", 
        2017: PROJECT_ROOT / "table_parsing" / "ê°ì‚¬ë³´ê³ ì„œ_2017_parsed.json",
        2018: PROJECT_ROOT / "table_parsing" / "ê°ì‚¬ë³´ê³ ì„œ_2018_parsed.json",
        2019: PROJECT_ROOT / "table_parsing" / "ê°ì‚¬ë³´ê³ ì„œ_2019_parsed.json",
        2020: PROJECT_ROOT / "table_parsing" / "ê°ì‚¬ë³´ê³ ì„œ_2020_parsed.json",
        2021: PROJECT_ROOT / "table_parsing" / "ê°ì‚¬ë³´ê³ ì„œ_2021_parsed.json",
        2022: PROJECT_ROOT / "table_parsing" / "ê°ì‚¬ë³´ê³ ì„œ_2022_parsed.json",
        2023: PROJECT_ROOT / "table_parsing" / "ê°ì‚¬ë³´ê³ ì„œ_2023_parsed.json",
        2024: PROJECT_ROOT / "table_parsing" / "ê°ì‚¬ë³´ê³ ì„œ_2024_parsed.json"
    },
    'accounting_standard': {
        2024: PROJECT_ROOT / "kifrs_combined_2.json"
    }
}

# ChromaDB ì„¤ì •
CHROMA_DB_PATH = PROJECT_ROOT / "vector_db"

# ì„ë² ë”© ëª¨ë¸ ì„¤ì •
EMBEDDING_MODEL = "jhgan/ko-sroberta-multitask"

# ë°°ì¹˜ í¬ê¸° ì„¤ì • (ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥)
DEFAULT_BATCH_SIZE = 25

# íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í•¨ìˆ˜
def check_data_files():
    """í•„ìš”í•œ ë°ì´í„° íŒŒì¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
    missing_files = []
    
    for doc_type, year_files in DATA_PATHS.items():
        for year, file_path in year_files.items():
            if not file_path.exists():
                missing_files.append(f"{doc_type} - {year}: {file_path}")
    
    return missing_files

# ë¬¸ìì—´ ê²½ë¡œë¡œ ë³€í™˜ (í•˜ìœ„ í˜¸í™˜ì„±)
def get_string_paths():
    """ë¬¸ìì—´ í˜•íƒœì˜ íŒŒì¼ ê²½ë¡œ ë°˜í™˜ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ìš©)"""
    string_paths = {}
    for doc_type, year_files in DATA_PATHS.items():
        string_paths[doc_type] = {}
        for year, file_path in year_files.items():
            string_paths[doc_type][year] = str(file_path)
    return string_paths

if __name__ == "__main__":
    # ì„¤ì • í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
    print("ğŸ” NLP Team3 ë²¡í„°DB ì„¤ì • í™•ì¸")
    print(f"í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}")
    print(f"ChromaDB ê²½ë¡œ: {CHROMA_DB_PATH}")
    
    missing = check_data_files()
    if missing:
        print(f"\nâš ï¸ ëˆ„ë½ëœ íŒŒì¼ë“¤ ({len(missing)}ê°œ):")
        for file in missing:
            print(f"  - {file}")
    else:
        print("\nâœ… ëª¨ë“  ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤!")
