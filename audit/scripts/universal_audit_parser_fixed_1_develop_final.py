#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import re
import html
import json
import os
import glob
import hashlib
from bs4 import BeautifulSoup, NavigableString
from typing import List, Dict, Any, Optional
from datetime import datetime

class UniversalAuditParser:
    """2014-2024ë…„ ëª¨ë“  ê°ì‚¬ë³´ê³ ì„œ í˜•ì‹ì„ í†µí•© ì²˜ë¦¬í•˜ëŠ” ë²”ìš© íŒŒì„œ (ì£¼ì„ êµ¬ì¡° ìœ ì§€ + í…Œì´ë¸” ì²˜ë¦¬ ê°œì„ )"""
    
    def __init__(self):
        self.main_notes = []
        self.note_boundaries = []
        self.parsed_chunks = []
        self.financial_statements = []  # ì¬ë¬´ì œí‘œ ì„¹ì…˜ë“¤
        self.file_year = None
        self.file_format = None
        self.table_counter = 0  # í‘œ ë²ˆí˜¸ ì¹´ìš´í„°
        self.collected_tables = []  # ìˆ˜ì§‘ëœ í‘œë“¤
        self.chunk_counter = 0  # RAG ì²­í¬ ì¹´ìš´í„°
        
        # ì¬ë¬´ì œí‘œ í•­ëª© ë§¤í•‘ (rag_optimized_parserì—ì„œ ê°€ì ¸ì˜´)
        self.financial_items = {
            'ìì‚°': ['ìœ ë™ìì‚°', 'ë¹„ìœ ë™ìì‚°', 'í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°', 'ë‹¨ê¸°ê¸ˆìœµìƒí’ˆ', 'ë§¤ì¶œì±„ê¶Œ', 'ì¬ê³ ìì‚°', 'ìœ í˜•ìì‚°', 'ë¬´í˜•ìì‚°'],
            'ë¶€ì±„': ['ìœ ë™ë¶€ì±„', 'ë¹„ìœ ë™ë¶€ì±„', 'ë§¤ì…ì±„ë¬´', 'ë‹¨ê¸°ì°¨ì…ê¸ˆ', 'ì¥ê¸°ì°¨ì…ê¸ˆ', 'ì¶©ë‹¹ë¶€ì±„'],
            'ìë³¸': ['ìë³¸ê¸ˆ', 'ìë³¸ì‰ì—¬ê¸ˆ', 'ì´ìµì‰ì—¬ê¸ˆ', 'ê¸°íƒ€ìë³¸í•­ëª©'],
            'ì†ìµ': ['ë§¤ì¶œì•¡', 'ë§¤ì¶œì›ê°€', 'ë§¤ì¶œì´ì´ìµ', 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ'],
            'í˜„ê¸ˆíë¦„': ['ì˜ì—…í™œë™í˜„ê¸ˆíë¦„', 'íˆ¬ìí™œë™í˜„ê¸ˆíë¦„', 'ì¬ë¬´í™œë™í˜„ê¸ˆíë¦„']
        }
        
        # ë‹¨ìœ„ ì •ê·œí™” ë° ìŠ¤ì¼€ì¼ íŒ©í„°
        self.unit_mapping = {
            'ë°±ë§Œì›': 'ë°±ë§Œì›',
            'ì²œì›': 'ì²œì›', 
            'ì›': 'ì›',
            'ë°±ë§Œ': 'ë°±ë§Œì›',
            'ì²œ': 'ì²œì›'
        }
        
        # ë‹¨ìœ„ë³„ ìŠ¤ì¼€ì¼ íŒ©í„° (ì› ê¸°ì¤€)
        self.scale_factors = {
            'ë°±ë§Œì›': 1000000,
            'ì²œì›': 1000,
            'ì›': 1,
            'ë°±ë§Œ': 1000000,
            'ì²œ': 1000
        }

    def generate_chunk_id(self, content: str) -> str:
        """ì²­í¬ ID ìƒì„± (rag_optimized_parser ë°©ì‹)"""
        self.chunk_counter += 1
        content_hash = hashlib.md5(content.encode()).hexdigest()[:8]
        return f"chunk_{self.chunk_counter:04d}_{content_hash}"
    
    def generate_doc_id(self, company: str, year: int, note_num: str, table_num: int = None, subsection: str = None) -> str:
        """RAGìš© ë¬¸ì„œ ID ìƒì„±"""
        # íšŒì‚¬ëª… ì •ê·œí™”
        company_clean = re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', company)
        
        # ì—°ë„ë¥¼ 2ìë¦¬ë¡œ ë³€í™˜ (2015 -> 15)
        year_short = str(year)[-2:] if year else "00"
        
        # ê¸°ë³¸ ID êµ¬ì„±
        doc_id_parts = [company_clean.lower(), year_short, f"note{note_num}"]
        
        # í…Œì´ë¸” ë²ˆí˜¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if table_num is not None:
            doc_id_parts.append(f"table{table_num}")
        
        # í•˜ìœ„ì„¹ì…˜ì´ ìˆìœ¼ë©´ ì¶”ê°€ (í•´ì‹œ ì²˜ë¦¬)
        if subsection:
            subsection_hash = hashlib.md5(subsection.encode()).hexdigest()[:6]
            doc_id_parts.append(f"sub{subsection_hash}")
        
        return "_".join(doc_id_parts)

    def find_input_files(self, base_path="/Users/dan/Desktop/snu_project/data/raw"):
        """raw í´ë”ì˜ ëª¨ë“  í•˜ìœ„ í´ë”ì—ì„œ ê°ì‚¬ë³´ê³ ì„œ HTML íŒŒì¼ ì°¾ê¸°"""
        html_files = []
        search_patterns = [
            os.path.join(base_path, "**", "*ê°ì‚¬ë³´ê³ ì„œ*.htm*"),
            os.path.join(base_path, "**", "*audit*.htm*"),
            os.path.join(base_path, "**", "*.htm"),
            os.path.join(base_path, "**", "*.html")
        ]
        
        for pattern in search_patterns:
            html_files.extend(glob.glob(pattern, recursive=True))
        
        # ì¤‘ë³µ ì œê±° ë° ê°ì‚¬ë³´ê³ ì„œ íŒŒì¼ë§Œ í•„í„°ë§
        html_files = list(set(html_files))
        audit_files = [f for f in html_files if any(keyword in os.path.basename(f).lower() 
                      for keyword in ['ê°ì‚¬ë³´ê³ ì„œ', 'audit', '201', '202'])]
        
        print(f"ğŸ“ ë°œê²¬ëœ ê°ì‚¬ë³´ê³ ì„œ íŒŒì¼: {len(audit_files)}ê°œ")
        for file in sorted(audit_files):
            print(f"   - {file}")
        
        return sorted(audit_files)

    def detect_file_format(self, soup, file_path):
        """íŒŒì¼ í˜•ì‹ì„ ìë™ ê°ì§€"""
        file_name = os.path.basename(file_path)
        
        # ì—°ë„ ì¶”ì¶œ
        year_match = re.search(r'(20\d{2})', file_name)
        self.file_year = int(year_match.group(1)) if year_match else None
        
        # êµ¬ì¡°ì  íŠ¹ì§• ë¶„ì„
        spans = soup.find_all('span')
        empty_spans = len([s for s in spans if not s.get_text(strip=True)])
        total_spans = len(spans)
        
        # ì£¼ì„ íŒ¨í„´ ìˆ˜ í™•ì¸
        p_elements = soup.find_all(['p', 'P'])
        note_patterns = len([p for p in p_elements if re.match(r'^\d{1,2}\.\s*', p.get_text(strip=True))])
        
        # í˜•ì‹ ë¶„ë¥˜
        if self.file_year and self.file_year <= 2016:
            if empty_spans > 200:
                self.file_format = "legacy_complex"  # 2014-2016ë…„ ë³µì¡í•œ SPAN êµ¬ì¡°
            else:
                self.file_format = "legacy_simple"   # 2014-2016ë…„ ë‹¨ìˆœ êµ¬ì¡°
        elif self.file_year and self.file_year <= 2020:
            if empty_spans > 500:
                self.file_format = "modern_complex"  # 2017-2020ë…„ ë³µì¡í•œ SPAN êµ¬ì¡°
            else:
                self.file_format = "modern_simple"   # 2017-2020ë…„ ë‹¨ìˆœ êµ¬ì¡°
        else:
            if total_spans < 100:
                self.file_format = "latest_clean"    # 2021-2024ë…„ ê¹”ë”í•œ êµ¬ì¡°
            else:
                self.file_format = "latest_mixed"    # 2021-2024ë…„ í˜¼í•© êµ¬ì¡°
        
        print(f"ğŸ” íŒŒì¼ í˜•ì‹ ê°ì§€: {self.file_year}ë…„ - {self.file_format}")
        print(f"   SPAN ìš”ì†Œ: {total_spans}ê°œ (ë¹ˆ SPAN: {empty_spans}ê°œ)")
        print(f"   ì£¼ì„ íŒ¨í„´: {note_patterns}ê°œ")

    def extract_document_metadata(self, soup: BeautifulSoup, filename: str) -> Dict[str, Any]:
        """ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (RAG ìµœì í™”)"""
        text = soup.get_text()
        
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        year_match = re.search(r'(20\d{2})', filename)
        
        # íšŒì‚¬ëª… ì¶”ì¶œ (ë” ì •í™•í•œ íŒ¨í„´)
        company_patterns = [
            r'([ê°€-í£]+(?:ì£¼ì‹íšŒì‚¬|ãˆœ))\s*(?:ê°ì‚¬ë³´ê³ ì„œ|ì—°ê²°ê°ì‚¬ë³´ê³ ì„œ)',
            r'íšŒì‚¬ëª…\s*[:\ï¼š]?\s*([ê°€-í£]+(?:ì£¼ì‹íšŒì‚¬|ãˆœ))',
            r'([ê°€-í£]+(?:ì£¼ì‹íšŒì‚¬|ãˆœ))\s*ì œ\s*\d+\s*ê¸°',
            r'([ê°€-í£]+(?:ì£¼ì‹íšŒì‚¬|ãˆœ))'
        ]
        
        company_name = None
        for pattern in company_patterns:
            company_match = re.search(pattern, text)
            if company_match:
                company_name = company_match.group(1).strip()
                break
        
        # ë³´ê³ ì„œ ìœ í˜• íŒë³„
        report_type = "ê°ì‚¬ë³´ê³ ì„œ"
        if "ì—°ê²°" in text:
            report_type = "ì—°ê²°ê°ì‚¬ë³´ê³ ì„œ"
        
        # íšŒê³„ê¸°ê°„ ì¶”ì¶œ (ë” ì •í™•í•œ íŒ¨í„´)
        period_patterns = [
            r'ì œ\s*(\d+)\s*ê¸°\s*\((20\d{2})\.(\d{2})\.(\d{2})\s*~\s*(20\d{2})\.(\d{2})\.(\d{2})\)',
            r'ì œ\s*(\d+)\s*ê¸°\s*ê°ì‚¬ë³´ê³ ì„œ',
            r'ì œ\s*(\d+)\s*ê¸°'
        ]
        
        current_period = None
        fiscal_year_start = None
        fiscal_year_end = None
        
        for pattern in period_patterns:
            period_match = re.search(pattern, text)
            if period_match:
                current_period = int(period_match.group(1))
                if len(period_match.groups()) >= 6:  # ë‚ ì§œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
                    fiscal_year_start = f"{period_match.group(2)}-{period_match.group(3).zfill(2)}-{period_match.group(4).zfill(2)}"
                    fiscal_year_end = f"{period_match.group(5)}-{period_match.group(6).zfill(2)}-{period_match.group(7).zfill(2)}"
                break
        
        # ê¸°ë³¸ ë‹¨ìœ„ ì¶”ì¶œ
        unit_patterns = [
            r'\(ë‹¨ìœ„\s*[:\ï¼š]?\s*([^)]+)\)',
            r'ë‹¨ìœ„\s*[:\ï¼š]\s*([ê°€-í£]+ì›?)'
        ]
        
        default_unit = None
        for pattern in unit_patterns:
            unit_match = re.search(pattern, text)
            if unit_match:
                unit = unit_match.group(1).strip()
                default_unit = self.unit_mapping.get(unit, unit)
                break
        
        # ì—°ë„ ì¶”ì¶œ ê°œì„  (íŒŒì¼ ì—°ë„ ìš°ì„ )
        final_year = None
        if year_match:
            final_year = int(year_match.group(1))
        elif self.file_year:
            final_year = self.file_year
        
        return {
            'filename': filename,
            'company': company_name or "Unknown",
            'report_year': final_year,
            'period_label': f"ì œ {current_period} ê¸°" if current_period else None,
            'fiscal_year_start': fiscal_year_start,
            'fiscal_year_end': fiscal_year_end,
            'report_type': report_type,
            'default_unit': default_unit,
            'parsing_timestamp': datetime.now().isoformat(),
            'source_path': filename
        }

    def classify_financial_item(self, item_name: str) -> str:
        """ì¬ë¬´í•­ëª© ë¶„ë¥˜ (rag_optimized_parser ë°©ì‹)"""
        item_name = item_name.lower()
        
        for category, items in self.financial_items.items():
            for item in items:
                if item.lower() in item_name:
                    return category
        
        return 'ê¸°íƒ€'

    def normalize_amount(self, amount_str: str, unit: str = None, scale_factor: int = 1) -> Dict[str, Any]:
        """ê¸ˆì•¡ ì •ê·œí™” (ë‹¨ìœ„ ë³€í™˜ í¬í•¨)"""
        if not amount_str or amount_str.strip() in ['-', '', 'â€•', 'â€”']:
            return {
                'value': None, 
                'display': amount_str,
                'normalized_value': None,
                'unit': unit,
                'scale_factor': scale_factor
            }
        
        # ê´„í˜¸ ì²˜ë¦¬ (ìŒìˆ˜)
        is_negative = False
        clean_amount = amount_str.strip()
        if clean_amount.startswith('(') and clean_amount.endswith(')'):
            is_negative = True
            clean_amount = clean_amount[1:-1]
        
        # ì½¤ë§ˆ, ê³µë°± ì œê±° í›„ ìˆ«ì ì¶”ì¶œ
        clean_amount = re.sub(r'[,\s]', '', clean_amount)
        
        # ìˆ«ì ì¶”ì¶œ (ì†Œìˆ˜ì  í¬í•¨)
        number_match = re.search(r'(\d+(?:\.\d+)?)', clean_amount)
        if number_match:
            value = float(number_match.group(1))
            if is_negative:
                value = -value
            
            # ë‹¨ìœ„ì— ë”°ë¥¸ ìŠ¤ì¼€ì¼ íŒ©í„° ì ìš©
            normalized_value = value
            if scale_factor != 1:
                normalized_value = value * scale_factor
            
            return {
                'value': value,  # ì›ë³¸ ê°’
                'display': amount_str,
                'normalized_value': normalized_value,  # ì› ë‹¨ìœ„ë¡œ ì •ê·œí™”ëœ ê°’
                'is_negative': is_negative,
                'unit': unit,
                'scale_factor': scale_factor
            }
        
        return {
            'value': None, 
            'display': amount_str,
            'normalized_value': None,
            'unit': unit,
            'scale_factor': scale_factor
        }

    def parse_file(self, file_path):
        print(f"ğŸš€ ë²”ìš© ê°ì‚¬ë³´ê³ ì„œ íŒŒì„œë¡œ {file_path} íŒŒì‹± ì‹œì‘...")
        
        # ë‹¤ì¤‘ ì¸ì½”ë”© ì‹œë„
        content = self.read_with_encoding(file_path)
        if not content:
            raise ValueError(f"íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        soup = BeautifulSoup(content, "html.parser")
        
        # íŒŒì¼ í˜•ì‹ ìë™ ê°ì§€
        self.detect_file_format(soup, file_path)
        
        # ìƒˆë¡œ ì¶”ê°€: ì¬ë¬´ì œí‘œ ì„¹ì…˜ íŒŒì‹±
        self.parse_financial_statements(soup)
        
        # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì£¼ì„ êµ¬ì¡° íŒŒì‹± (Phase 1-3)
        elements = self.phase1_preprocess_html(soup)
        self.phase2_find_main_note_boundaries(elements)
        processed_elements = self.phase3_process_continuation_patterns(elements)
        
        # Phase 4ì—ì„œ ê°œì„ ëœ í…Œì´ë¸” ì²˜ë¦¬ ì ìš©
        self.phase4_extract_content_with_enhanced_tables(processed_elements, soup)
        
        return self.parsed_chunks

    def read_with_encoding(self, file_path):
        """ë‹¤ì¤‘ ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ ì½ê¸°"""
        encodings = ['cp949', 'euc-kr', 'utf-8', 'latin1', 'iso-8859-1']
        
        for encoding in encodings:
            try:
                with open(file_path, "r", encoding=encoding) as f:
                    content = f.read()
                print(f"âœ… {encoding} ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ ì½ê¸° ì„±ê³µ")
                return content
            except (UnicodeDecodeError, UnicodeError):
                continue
        
        print(f"âŒ ëª¨ë“  ì¸ì½”ë”© ì‹œë„ ì‹¤íŒ¨")
        return None

    def parse_financial_statements(self, soup):
        """ì£¼ì„ ì „ ì¬ë¬´ì œí‘œ ì„¹ì…˜ íŒŒì‹±"""
        print("ğŸ“Š ì¬ë¬´ì œí‘œ ì„¹ì…˜ íŒŒì‹± ì‹œì‘...")
        
        # ì£¼ì„ ì‹œì‘ì  ì°¾ê¸°
        p_elements = soup.find_all(["p", "P"])
        notes_start_idx = None
        for i, element in enumerate(p_elements):
            text = self._merge_spans_adaptively(element)
            if re.search(r"1\.\s*ì¼ë°˜ì \s*ì‚¬í•­", text):
                notes_start_idx = i
                break
        
        if notes_start_idx is None:
            print("   âŒ ì£¼ì„ ì‹œì‘ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"   ğŸ“ ì£¼ì„ ì‹œì‘ì : P[{notes_start_idx}]")
        
        # ê°„ë‹¨í•œ ë°©ì‹: ì²˜ìŒ 20ê°œ TABLE í´ë˜ìŠ¤ í…Œì´ë¸”ì—ì„œ ì¬ë¬´ì œí‘œ ì°¾ê¸°
        all_tables = soup.find_all('table')
        
        # ì¬ë¬´ì œí‘œ í…Œì´ë¸” íŒ¨í„´ ì •ì˜ (CENTER ì •ë ¬ ì œëª© ê¸°ë°˜)
        statement_patterns = {
            "ì¬ë¬´ìƒíƒœí‘œ": [
                r"ì¬\s*ë¬´\s*ìƒ\s*íƒœ\s*í‘œ",
                r"ëŒ€\s*ì°¨\s*ëŒ€\s*ì¡°\s*í‘œ"
            ],
            "ì†ìµê³„ì‚°ì„œ": [
                r"ì†\s*ìµ\s*ê³„\s*ì‚°\s*ì„œ"
            ],
            "í¬ê´„ì†ìµê³„ì‚°ì„œ": [
                r"í¬\s*ê´„\s*ì†\s*ìµ\s*ê³„\s*ì‚°\s*ì„œ"
            ],
            "ìë³¸ë³€ë™í‘œ": [
                r"ì\s*ë³¸\s*ë³€\s*ë™\s*í‘œ"
            ],
            "í˜„ê¸ˆíë¦„í‘œ": [
                r"í˜„\s*ê¸ˆ\s*í\s*ë¦„\s*í‘œ"
            ]
        }
        
        # ì¬ë¬´ì œí‘œ í—¤ë”ì™€ ë°ì´í„° í…Œì´ë¸”ì„ ìˆœì„œëŒ€ë¡œ ì°¾ê¸°
        for table_idx, table in enumerate(all_tables[:30]):  # ì²˜ìŒ 30ê°œ í™•ì¸
            # CENTER ì •ë ¬ëœ ì…€ì—ì„œ ì œëª© ì°¾ê¸°
            center_cells = table.find_all('td', {'align': 'CENTER'})
            statement_title = None
            statement_unit = None
            
            for cell in center_cells:
                cell_text = cell.get_text(strip=True)
                
                # ì¬ë¬´ì œí‘œ ì œëª© í™•ì¸ (í¬ê´„ì†ìµê³„ì‚°ì„œ ìš°ì„  ì²˜ë¦¬)
                if re.search(r'í¬\s*ê´„\s*ì†\s*ìµ\s*ê³„\s*ì‚°\s*ì„œ', cell_text):
                    statement_title = "í¬ê´„ì†ìµê³„ì‚°ì„œ"
                    print(f"   ğŸ“‹ í¬ê´„ì†ìµê³„ì‚°ì„œ í—¤ë” ë°œê²¬: Table[{table_idx}] - {cell_text}")
                else:
                    for statement_name, patterns in statement_patterns.items():
                        if any(re.search(pattern, cell_text) for pattern in patterns):
                            statement_title = statement_name
                            print(f"   ğŸ“‹ {statement_name} í—¤ë” ë°œê²¬: Table[{table_idx}] - {cell_text}")
                            break
                
                # ë‹¨ìœ„ ì •ë³´ ì¶”ì¶œ
                unit_match = re.search(r'\(ë‹¨ìœ„\s*[:ï¼š]?\s*([^)]+)\)', cell_text)
                if unit_match:
                    statement_unit = self.unit_mapping.get(unit_match.group(1).strip(), unit_match.group(1).strip())
                    print(f"      ğŸ“ ë‹¨ìœ„ ì •ë³´: {unit_match.group(1).strip()} -> {statement_unit}")
            
            if statement_title:
                # í—¤ë” í…Œì´ë¸” ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ì‹¤ì œ ë°ì´í„° í…Œì´ë¸” ì°¾ê¸°
                data_table = None
                for next_idx in range(table_idx + 1, min(table_idx + 5, len(all_tables))):  # ë‹¤ìŒ 4ê°œ í…Œì´ë¸” í™•ì¸
                    next_table = all_tables[next_idx]
                    next_table_text = next_table.get_text()
                    
                    # ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” í…Œì´ë¸”ì¸ì§€ í™•ì¸ (ê³¼ëª©, ì£¼ì„ ì»¬ëŸ¼ì´ ìˆê³  ìˆ«ì ë°ì´í„°ê°€ ë§ì€)
                    # ê³µë°±ì´ ë§ì€ "ê³¼                      ëª©" í˜•íƒœë„ ì¸ì‹
                    has_subject = re.search(r'ê³¼\s*ëª©', next_table_text) is not None
                    has_note = 'ì£¼ì„' in next_table_text
                    number_count = len(re.findall(r'\d{1,3}(?:,\d{3})*', next_table_text))
                    
                    if (has_subject and has_note and number_count > 10):  # ìˆ«ìê°€ 10ê°œ ì´ìƒ
                        data_table = next_table
                        data_table_idx = next_idx
                        print(f"      ğŸ“Š {statement_title} ë°ì´í„° í…Œì´ë¸” ë°œê²¬: Table[{data_table_idx}]")
                        break
                
                if data_table:
                    try:
                        # ì‹¤ì œ ë°ì´í„° í…Œì´ë¸” ì²˜ë¦¬
                        matrix = self.table_to_matrix(data_table)
                        if matrix and len(matrix) > 3:  # ìœ íš¨í•œ ë§¤íŠ¸ë¦­ìŠ¤ì¸ì§€ í™•ì¸
                            table_metadata = self.extract_table_metadata(data_table, matrix)
                            table_metadata['statement_type'] = statement_title
                            table_metadata['table_number'] = data_table_idx + 1
                            table_metadata['table_title'] = statement_title
                            if statement_unit:
                                table_metadata['unit'] = statement_unit
                                table_metadata['scale_factor'] = self.scale_factors.get(statement_unit, 1)
                            
                            statement_chunk = {
                                "statement_type": statement_title,
                                "title": statement_title,
                                "table_number": data_table_idx + 1,
                                "matrix": matrix,
                                "metadata": table_metadata
                            }
                            
                            # ê¸°ì¡´ ì¬ë¬´ì œí‘œê°€ ìˆëŠ”ì§€ í™•ì¸
                            existing = next((s for s in self.financial_statements if s["statement_type"] == statement_title), None)
                            if existing:
                                existing.setdefault("tables", []).append(statement_chunk)
                                existing["table_count"] = len(existing["tables"])
                            else:
                                new_statement = {
                                    "statement_type": statement_title,
                                    "title": statement_title,
                                    "tables": [statement_chunk],
                                    "table_count": 1
                                }
                                self.financial_statements.append(new_statement)
                            
                            print(f"      âœ… {statement_title} ë°ì´í„° í…Œì´ë¸” ìˆ˜ì§‘ ì™„ë£Œ (í–‰: {len(matrix)}, ì—´: {len(matrix[0]) if matrix else 0})")
                    except Exception as e:
                        print(f"      âŒ {statement_title} ë°ì´í„° í…Œì´ë¸” ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        print(f"âœ… ì¬ë¬´ì œí‘œ íŒŒì‹± ì™„ë£Œ: {len(self.financial_statements)}ê°œ ì¬ë¬´ì œí‘œ ë°œê²¬")

    def _get_table_position_in_document(self, table, p_elements, notes_start_idx):
        """í…Œì´ë¸”ì˜ ë¬¸ì„œ ë‚´ ìœ„ì¹˜ í™•ì¸"""
        try:
            # í…Œì´ë¸” ì•ì˜ í…ìŠ¤íŠ¸ ìš”ì†Œë“¤ í™•ì¸
            prev_element = table.previous_sibling
            while prev_element:
                if hasattr(prev_element, 'name') and prev_element.name in ['p', 'P']:
                    # p_elementsì—ì„œ í•´ë‹¹ ìš”ì†Œì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
                    for i, p in enumerate(p_elements):
                        if p == prev_element:
                            return i
                prev_element = prev_element.previous_sibling
            return 0
        except:
            return None

    def _find_and_parse_statement(self, p_elements, statement_name, patterns, soup):
        """íŠ¹ì • ì¬ë¬´ì œí‘œ ì°¾ê¸° ë° íŒŒì‹±"""
        for i, element in enumerate(p_elements):
            text = self._merge_spans_adaptively(element)
            
            # íŒ¨í„´ ë§¤ì¹­
            for pattern in patterns:
                if re.search(pattern, text):
                    print(f"   ğŸ“‹ {statement_name} ë°œê²¬: P[{i}] - {text[:50]}...")
                    
                    # í•´ë‹¹ ì¬ë¬´ì œí‘œì˜ í…Œì´ë¸”ë“¤ ì°¾ê¸°
                    statement_tables = self._extract_statement_tables(i, p_elements, soup, statement_name)
                    
                    if statement_tables:
                        statement_chunk = {
                            "statement_type": statement_name,
                            "title": statement_name,
                            "start_index": i,
                            "tables": statement_tables,
                            "table_count": len(statement_tables)
                        }
                        self.financial_statements.append(statement_chunk)
                        print(f"      ğŸ“Š {statement_name} í…Œì´ë¸” {len(statement_tables)}ê°œ ìˆ˜ì§‘")
                    
                    return  # ì²« ë²ˆì§¸ ë§¤ì¹­ì—ì„œ ì¤‘ë‹¨

    def _extract_statement_tables(self, start_idx, p_elements, soup, statement_name):
        """ì¬ë¬´ì œí‘œì˜ í…Œì´ë¸”ë“¤ ì¶”ì¶œ"""
        statement_tables = []
        
        # ì‹œì‘ì ë¶€í„° ë‹¤ìŒ ì¬ë¬´ì œí‘œë‚˜ ì£¼ì„ê¹Œì§€ ê²€ìƒ‰
        end_idx = len(p_elements)
        for i in range(start_idx + 1, len(p_elements)):
            text = self._merge_spans_adaptively(p_elements[i])
            
            # ë‹¤ë¥¸ ì¬ë¬´ì œí‘œë‚˜ ì£¼ì„ ì‹œì‘ì ì´ë©´ ì¤‘ë‹¨
            if (re.search(r"ì¬\s*ë¬´\s*ìƒ\s*íƒœ\s*í‘œ|ì†\s*ìµ\s*ê³„\s*ì‚°\s*ì„œ|ì\s*ë³¸\s*ë³€\s*ë™\s*í‘œ|í˜„\s*ê¸ˆ\s*í\s*ë¦„\s*í‘œ", text) or
                re.search(r"1\.\s*ì¼ë°˜ì \s*ì‚¬í•­", text)):
                end_idx = i
                break
        
        print(f"      ğŸ” {statement_name} í…Œì´ë¸” ê²€ìƒ‰ ë²”ìœ„: P[{start_idx}] ~ P[{end_idx-1}]")
        
        # í•´ë‹¹ ë²”ìœ„ì˜ í…Œì´ë¸”ë“¤ ìˆ˜ì§‘
        for i in range(start_idx, end_idx):
            element = p_elements[i]
            
            # í…Œì´ë¸” ë§ˆì»¤ í™•ì¸
            text = self._merge_spans_adaptively_with_markers(element)
            marker_matches = re.findall(r'í‘œ (\d+)', text)
            
            for table_num in marker_matches:
                # ìˆ˜ì§‘ëœ í…Œì´ë¸”ì—ì„œ ì°¾ê¸°
                for collected_num, table_element, table_info in self.collected_tables:
                    if collected_num == int(table_num):
                        try:
                            # í…Œì´ë¸” ì²˜ë¦¬
                            matrix = self.table_to_matrix(table_element)
                            if matrix and self.is_data_table(matrix, table_element):
                                # í…Œì´ë¸” ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                                table_metadata = self.extract_table_metadata(table_element, matrix)
                                table_metadata['table_number'] = int(table_num)
                                
                                # nb í´ë˜ìŠ¤ì—ì„œ ì¶”ì¶œí•œ ì •ë³´ ì ìš©
                                if table_info.get('extracted_unit') and not table_metadata.get('unit'):
                                    table_metadata['unit'] = table_info['extracted_unit']
                                    table_metadata['scale_factor'] = self.scale_factors.get(table_info['extracted_unit'], 1)
                                
                                # ì¬ë¬´ì œí‘œ ì œëª© ì ìš©
                                if table_info.get('statement_title'):
                                    table_metadata['statement_type'] = table_info['statement_title']
                                    table_metadata['table_title'] = table_info['statement_title']
                                else:
                                    table_metadata['statement_type'] = statement_name
                                
                                # ê¸°ê°„ ì •ë³´ ì ìš©
                                if table_info.get('period_info'):
                                    period = table_info['period_info']
                                    table_metadata['year'] = period['year']
                                    table_metadata['period'] = period['period']
                                
                                statement_table = {
                                    "table_number": int(table_num),
                                    "matrix": matrix,
                                    "metadata": table_metadata
                                }
                                statement_tables.append(statement_table)
                                print(f"         âœ… í‘œ {table_num} ìˆ˜ì§‘ ì™„ë£Œ")
                        except Exception as e:
                            print(f"         âŒ í‘œ {table_num} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        break
        
        return statement_tables

    def phase1_preprocess_html(self, soup):
        print("ğŸ“‹ Phase 1: HTML ì „ì²˜ë¦¬ ë° í‘œ ìœ„ì¹˜ ë§ˆì»¤ ì‚½ì… ì‹œì‘...")
        
        # 1ë‹¨ê³„: ë°ì´í„° í…Œì´ë¸” ë¶„ë¥˜ ë° ë§ˆì»¤ ì‚½ì…
        all_tables = soup.find_all('table')
        self._insert_table_markers(soup, all_tables)
        
        # 2ë‹¨ê³„: p ìš”ì†Œ ì²˜ë¦¬
        p_elements = soup.find_all(["p", "P"])
        processed_elements = []
        start_found = False
        
        for i, element in enumerate(p_elements):
            merged_text = self._merge_spans_adaptively_with_markers(element)

            if not start_found:
                # ë‹¤ì–‘í•œ ì‹œì‘ íŒ¨í„´ ì¸ì‹
                start_patterns = [
                    r"1\. *ì¼ë°˜ì  *ì‚¬í•­",
                    r"1\. *íšŒì‚¬ì˜ *ê°œìš”",
                    r"1\. *ê¸°ì—…ì˜ *ê°œìš”",
                    r"ì£¼ì„.*ì¬ë¬´ì œí‘œ"
                ]
                
                if any(re.search(pattern, merged_text, re.IGNORECASE) for pattern in start_patterns):
                    start_found = True
                    print(f"âœ… ì£¼ì„ ì„¹ì…˜ ì‹œì‘ì  ë°œê²¬: P[{i}] - {merged_text[:50]}...")
                else:
                    continue
            
            if merged_text:
                processed_elements.append({
                    "element": element,
                    "text": merged_text,
                    "index": len(processed_elements),
                    "original_index": i,
                })
        
        print(f"âœ… Phase 1 ì™„ë£Œ: {len(processed_elements)}ê°œ ìš”ì†Œ ì²˜ë¦¬ë¨, {len(self.collected_tables)}ê°œ í‘œ ìˆ˜ì§‘ë¨")
        return processed_elements

    def _merge_spans_adaptively(self, element):
        """í˜•ì‹ì— ë”°ë¼ ì ì‘ì ìœ¼ë¡œ SPAN ë³‘í•©"""
        if not element:
            return ""
        
        # ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = element.get_text(separator=' ', strip=True)
        text = html.unescape(text)
        
        # í˜•ì‹ë³„ íŠ¹ë³„ ì²˜ë¦¬
        if self.file_format in ["legacy_complex", "modern_complex"]:
            # ë³µì¡í•œ SPAN êµ¬ì¡°: ë¹ˆ SPAN ì œê±° í›„ ë³‘í•©
            spans = element.find_all('span')
            if spans:
                span_texts = []
                for span in spans:
                    span_text = span.get_text(strip=True)
                    if span_text:  # ë¹ˆ SPAN ì œì™¸
                        span_texts.append(span_text)
                if span_texts:
                    text = ' '.join(span_texts)
        
        # ê³µí†µ ì •ë¦¬
        text = re.sub(r"\s+", " ", text)
        text = text.replace("\xa0", " ")
        return text.strip()
    
    def _merge_spans_adaptively_with_markers(self, element):
        """í˜•ì‹ì— ë”°ë¼ ì ì‘ì ìœ¼ë¡œ SPAN ë³‘í•©í•˜ë˜, í‘œ ë§ˆì»¤ í¬í•¨"""
        if not element:
            return ""
        
        # í‘œ ë§ˆì»¤ ë¨¼ì € í™•ì¸
        table_marker_match = re.search(r'\[TABLE_MARKER_(\d+)\]', element.get_text())
        if table_marker_match:
            table_num = table_marker_match.group(1)
            return f"í‘œ {table_num}"
        
        # ì¼ë°˜ í…ìŠ¤íŠ¸ ì²˜ë¦¬
        return self._merge_spans_adaptively(element)

    def phase2_find_main_note_boundaries(self, elements):
        print("ğŸ“‹ Phase 2: ë©”ì¸ ì£¼ì„ ê²½ê³„ ì •ì˜ ì‹œì‘...")
        main_notes = []
        
        # ì—°ë„ë³„ ë§ì¶¤ íŒ¨í„´
        if self.file_year and self.file_year <= 2016:
            # 2014-2016ë…„: ë³µì¡í•œ íŒ¨í„´ (ì¼œë¡  ì—†ëŠ” ê²½ìš°ë„ ì²˜ë¦¬)
            note_patterns = [
                r"^(\d{1,2})\.\s*(.+?)\s*[:ï¼š]\s*$",  # ì¼œë¡ ì´ ìˆê³  ë’¤ì— ê³µë°±
                r"^(\d{1,2})\.\s*(.+?)[:ï¼š]$",  # ì¼œë¡ ì´ ìˆì§€ë§Œ ë’¤ì— ê³µë°± ì—†ìŒ
                r"^(\d{1,2})\.\s*(.+?)(?:\s*,\s*ê³„ì†.*)?$",  # ê³„ì† í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš°
                r"^(\d{1,2})\.\s*(.+?)\s*$"  # ì¼œë¡ ì´ ì—†ëŠ” ê²½ìš°
            ]
        else:
            # 2017ë…„ ì´í›„: ë‹¨ìˆœí•œ íŒ¨í„´
            note_patterns = [
                r"^(\d{1,2})\.\s*(.+?)(?:\s*[:ï¼š].*)?$"
            ]
        
        # Note 12 íŠ¹ë³„ ì²˜ë¦¬ íŒ¨í„´ (ëª¨ë“  ì—°ë„)
        note12_patterns = [
            r"(\d{1,2})\.\s*ì¢…ì†ê¸°ì—….*ê´€ê³„ê¸°ì—….*ê³µë™ê¸°ì—….*íˆ¬ì",
            r"(\d{1,2})\.\s*ì¢…ì†ê¸°ì—…,?\s*ê´€ê³„ê¸°ì—…\s*ë°\s*ê³µë™ê¸°ì—…\s*íˆ¬ì",
            r"(\d{1,2})\.\s*ê´€ê³„ê¸°ì—….*íˆ¬ì",
            r"(\d{1,2})\.\s*íˆ¬ì.*ì¢…ì†ê¸°ì—…"
        ]
        
        # Note 1 íŠ¹ë³„ ì²˜ë¦¬ íŒ¨í„´ (ì¼ë°˜ì  ì‚¬í•­)
        note1_patterns = [
            r"(1)\.\s*ì¼ë°˜ì \s*ì‚¬í•­",
            r"(1)\.ì¼ë°˜ì ì‚¬í•­"
        ]
        
        # Note 5 íŠ¹ë³„ ì²˜ë¦¬ íŒ¨í„´ (ì‚¬ìš©ì œí•œê¸ˆìœµìƒí’ˆ)
        note5_patterns = [
            r"(5)\.\s*ì‚¬ìš©ì œí•œê¸ˆìœµìƒí’ˆ",
            r"(5)\.ì‚¬ìš©ì œí•œê¸ˆìœµìƒí’ˆ"
        ]
        
        # Note 4 íŠ¹ë³„ ì²˜ë¦¬ íŒ¨í„´ (í˜„ê¸ˆê´€ë ¨)
        note4_patterns = [
            r"(\d{1,2})\.\s*í˜„ê¸ˆ.*í˜„ê¸ˆì„±ìì‚°",
            r"(\d{1,2})\.\s*í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°",
            r"(\d{1,2})\.í˜„ê¸ˆ.*í˜„ê¸ˆì„±ìì‚°",  # ê³µë°± ì—†ëŠ” ê²½ìš°
            r"(\d{1,2})\.í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°"   # ê³µë°± ì—†ëŠ” ê²½ìš°
        ]
        
        # Note 15, 17, 18 íŠ¹ë³„ ì²˜ë¦¬ íŒ¨í„´ (ì¶©ë‹¹ë¶€ì±„)
        note15_patterns = [
            r"(15)\.\s*ì¶©ë‹¹ë¶€ì±„",
            r"(15)\.ì¶©ë‹¹ë¶€ì±„"
        ]
        
        note17_patterns = [
            r"(17)\.\s*ì¶©ë‹¹ë¶€ì±„", 
            r"(17)\.ì¶©ë‹¹ë¶€ì±„"
        ]
        
        note18_patterns = [
            r"(18)\.\s*ì¶©ë‹¹ë¶€ì±„",
            r"(18)\.ì¶©ë‹¹ë¶€ì±„"
        ]

        for elem in elements:
            text = elem["text"]
            
            # spanìœ¼ë¡œ ë¶„ë¦¬ëœ ì£¼ì„ ë²ˆí˜¸ì™€ ì œëª© ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
            raw_element_text = elem["element"].get_text(separator="", strip=True)
            combined_text = elem["element"].get_text(separator=" ", strip=True)
            
            # Note 1 íŠ¹ë³„ ì²˜ë¦¬ (ì¼ë°˜ì  ì‚¬í•­)
            for note1_pattern in note1_patterns:
                # ê¸°ë³¸ í…ìŠ¤íŠ¸, raw í…ìŠ¤íŠ¸, combined í…ìŠ¤íŠ¸ ëª¨ë‘ í™•ì¸
                for check_text in [text, raw_element_text, combined_text]:
                    match = re.search(note1_pattern, check_text, re.IGNORECASE)
                    if match:
                        note_number = int(match.group(1))
                        if note_number == 1:
                            if not any(note["number"] == 1 for note in main_notes):
                                main_notes.append({
                                    "number": 1,
                                    "title": "ì¼ë°˜ì  ì‚¬í•­",
                                    "start_index": elem["index"],
                                })
                                print(f"âœ… Note 1 íŠ¹ë³„ íŒ¨í„´ìœ¼ë¡œ ë°œê²¬: {check_text[:50]}...")
                            break
                else:
                    continue
                break
            
            # Note 5 íŠ¹ë³„ ì²˜ë¦¬ (ì‚¬ìš©ì œí•œê¸ˆìœµìƒí’ˆ)
            for note5_pattern in note5_patterns:
                # ê¸°ë³¸ í…ìŠ¤íŠ¸, raw í…ìŠ¤íŠ¸, combined í…ìŠ¤íŠ¸ ëª¨ë‘ í™•ì¸
                for check_text in [text, raw_element_text, combined_text]:
                    match = re.search(note5_pattern, check_text, re.IGNORECASE)
                    if match:
                        note_number = int(match.group(1))
                        if note_number == 5:
                            if not any(note["number"] == 5 for note in main_notes):
                                main_notes.append({
                                    "number": 5,
                                    "title": "ì‚¬ìš©ì œí•œê¸ˆìœµìƒí’ˆ",
                                    "start_index": elem["index"],
                                })
                                print(f"âœ… Note 5 íŠ¹ë³„ íŒ¨í„´ìœ¼ë¡œ ë°œê²¬: {check_text[:50]}...")
                            break
                else:
                    continue
                break
            
            # Note 12 íŠ¹ë³„ ì²˜ë¦¬
            for note12_pattern in note12_patterns:
                match = re.search(note12_pattern, text, re.IGNORECASE)
                if match:
                    note_number = int(match.group(1))
                    if note_number == 12:
                        if not any(note["number"] == 12 for note in main_notes):
                            main_notes.append({
                                "number": 12,
                                "title": "ì¢…ì†ê¸°ì—…, ê´€ê³„ê¸°ì—… ë° ê³µë™ê¸°ì—… íˆ¬ì",
                                "start_index": elem["index"],
                            })
                            print(f"âœ… Note 12 íŠ¹ë³„ íŒ¨í„´ìœ¼ë¡œ ë°œê²¬: {text[:50]}...")
                        continue
            
            # Note 4 íŠ¹ë³„ ì²˜ë¦¬ (í˜„ê¸ˆê´€ë ¨)
            for note4_pattern in note4_patterns:
                # ê¸°ë³¸ í…ìŠ¤íŠ¸, raw í…ìŠ¤íŠ¸, combined í…ìŠ¤íŠ¸ ëª¨ë‘ í™•ì¸
                for check_text in [text, raw_element_text, combined_text]:
                    match = re.search(note4_pattern, check_text, re.IGNORECASE)
                    if match:
                        note_number = int(match.group(1))
                        if note_number == 4:
                            if not any(note["number"] == 4 for note in main_notes):
                                main_notes.append({
                                    "number": 4,
                                    "title": "í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°",
                                    "start_index": elem["index"],
                                })
                                print(f"âœ… Note 4 íŠ¹ë³„ íŒ¨í„´ìœ¼ë¡œ ë°œê²¬: {check_text[:50]}...")
                            break
                else:
                    continue
                break
            
            # Note 15 íŠ¹ë³„ ì²˜ë¦¬ (ì¶©ë‹¹ë¶€ì±„)
            for note15_pattern in note15_patterns:
                # ê¸°ë³¸ í…ìŠ¤íŠ¸, raw í…ìŠ¤íŠ¸, combined í…ìŠ¤íŠ¸ ëª¨ë‘ í™•ì¸
                for check_text in [text, raw_element_text, combined_text]:
                    match = re.search(note15_pattern, check_text, re.IGNORECASE)
                    if match:
                        note_number = int(match.group(1))
                        if note_number == 15:
                            if not any(note["number"] == 15 for note in main_notes):
                                main_notes.append({
                                    "number": 15,
                                    "title": "ì¶©ë‹¹ë¶€ì±„",
                                    "start_index": elem["index"],
                                })
                                print(f"âœ… Note 15 íŠ¹ë³„ íŒ¨í„´ìœ¼ë¡œ ë°œê²¬: {check_text[:50]}...")
                            break
                else:
                    continue
                break
            
            # Note 17 íŠ¹ë³„ ì²˜ë¦¬ (ì¶©ë‹¹ë¶€ì±„)
            for note17_pattern in note17_patterns:
                # ê¸°ë³¸ í…ìŠ¤íŠ¸, raw í…ìŠ¤íŠ¸, combined í…ìŠ¤íŠ¸ ëª¨ë‘ í™•ì¸
                for check_text in [text, raw_element_text, combined_text]:
                    match = re.search(note17_pattern, check_text, re.IGNORECASE)
                    if match:
                        note_number = int(match.group(1))
                        if note_number == 17:
                            if not any(note["number"] == 17 for note in main_notes):
                                main_notes.append({
                                    "number": 17,
                                    "title": "ì¶©ë‹¹ë¶€ì±„",
                                    "start_index": elem["index"],
                                })
                                print(f"âœ… Note 17 íŠ¹ë³„ íŒ¨í„´ìœ¼ë¡œ ë°œê²¬: {check_text[:50]}...")
                            break
                else:
                    continue
                break
            
            # Note 18 íŠ¹ë³„ ì²˜ë¦¬ (ì¶©ë‹¹ë¶€ì±„)
            for note18_pattern in note18_patterns:
                # ê¸°ë³¸ í…ìŠ¤íŠ¸, raw í…ìŠ¤íŠ¸, combined í…ìŠ¤íŠ¸ ëª¨ë‘ í™•ì¸
                for check_text in [text, raw_element_text, combined_text]:
                    match = re.search(note18_pattern, check_text, re.IGNORECASE)
                    if match:
                        note_number = int(match.group(1))
                        if note_number == 18:
                            if not any(note["number"] == 18 for note in main_notes):
                                main_notes.append({
                                    "number": 18,
                                    "title": "ì¶©ë‹¹ë¶€ì±„",
                                    "start_index": elem["index"],
                                })
                                print(f"âœ… Note 18 íŠ¹ë³„ íŒ¨í„´ìœ¼ë¡œ ë°œê²¬: {check_text[:50]}...")
                            break
                else:
                    continue
                break
            
            # ì¼ë°˜ íŒ¨í„´ ì²˜ë¦¬
            for pattern in note_patterns:
                match = re.match(pattern, text)
                if match:
                    note_number = int(match.group(1))
                    title_part = match.group(2).strip()
                    
                    if 1 <= note_number <= 40:
                        # ì œì™¸ íŒ¨í„´ (ì²« ë²ˆì§¸ ì£¼ì„ì´ë©´ "ê³„ì†" í‚¤ì›Œë“œ ë¬´ì‹œ)
                        if any(keyword in title_part.lower() for keyword in ["ê³„ì†", "continued"]):
                            if not any(note["number"] == note_number for note in main_notes):
                                continue  # ì²« ë²ˆì§¸ ë°œê²¬ì´ë©´ "ê³„ì†" ë¬´ì‹œ
                        
                        # ì¤‘ë³µ ì²´í¬
                        if not any(note["number"] == note_number for note in main_notes):
                            main_notes.append({
                                "number": note_number,
                                "title": title_part,
                                "start_index": elem["index"],
                            })
                            print(f"âœ… Note {note_number} ë°œê²¬: {title_part}")
                        break
        
        # ì •ë ¬ ë° ê²½ê³„ ì„¤ì •
        main_notes.sort(key=lambda x: x["number"])
        self.main_notes = main_notes
        
        # ê²½ê³„ ì„¤ì •
        note_boundaries = []
        for i, note in enumerate(main_notes):
            end_index = main_notes[i + 1]["start_index"] - 1 if i + 1 < len(main_notes) else len(elements) - 1
            note_boundaries.append({
                "number": note["number"],
                "title": note["title"],
                "start_index": note["start_index"],
                "end_index": end_index
            })
        
        self.note_boundaries = note_boundaries
        print(f"âœ… Phase 2 ì™„ë£Œ: {len(main_notes)}ê°œ ì£¼ì„ ê²½ê³„ ì„¤ì •ë¨")

    def phase3_process_continuation_patterns(self, elements):
        print("ğŸ“‹ Phase 3: ê³„ì† íŒ¨í„´ ì²˜ë¦¬ ì‹œì‘...")
        
        processed_elements = []
        for elem in elements:
            # ê³„ì† íŒ¨í„´ ì œê±°
            text = elem["text"]
            text = re.sub(r"\s*,?\s*ê³„ì†\s*$", "", text)
            text = re.sub(r"\s*,?\s*continued\s*$", "", text, re.IGNORECASE)
            
            elem["text"] = text.strip()
            
            # ë¹ˆ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
            if elem["text"]:
                processed_elements.append(elem)
        
        print(f"âœ… Phase 3 ì™„ë£Œ: ê³„ì† íŒ¨í„´ ì²˜ë¦¬ í›„ {len(processed_elements)}ê°œ ìš”ì†Œ ë‚¨ìŒ")
        return processed_elements

    def phase4_extract_content_with_enhanced_tables(self, elements, soup):
        """ê°œì„ ëœ í…Œì´ë¸” ì²˜ë¦¬ê°€ ì ìš©ëœ Phase 4"""
        print("ğŸ“‹ Phase 4: ë‚´ìš© ì¶”ì¶œ ë° ê°œì„ ëœ í…Œì´ë¸” ë¶„ì„ ì‹œì‘...")
        chunks = []
        
        # ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        doc_metadata = self.extract_document_metadata(soup, "temp_filename")
        
        print(f"   ìˆ˜ì§‘ëœ í…Œì´ë¸”: {len(self.collected_tables)}ê°œ")
        
        for boundary in self.note_boundaries:
            note_elements = [elem for elem in elements if boundary["start_index"] <= elem["index"] <= boundary["end_index"]]
            content_parts = [elem["text"] for elem in note_elements]
            
            # í•´ë‹¹ ì£¼ì„ì˜ í…Œì´ë¸” ì°¾ê¸° (ë§ˆì»¤ ê¸°ë°˜)
            note_tables = self._find_tables_by_markers(content_parts)
            
            # ê°œì„ ëœ í…Œì´ë¸” ì²˜ë¦¬: RAG ìµœì í™” ë°©ì‹ ì ìš©
            enhanced_table_data = self._process_tables_with_rag_optimization(note_tables, doc_metadata, boundary)
            
            # ì²­í¬ ìƒì„± (ê¸°ì¡´ êµ¬ì¡° ìœ ì§€)
            chunk = {
                "note_number": str(boundary["number"]),
                "title": boundary["title"],
                "content": "\\n\\n".join(content_parts),
                "content_length": sum(len(part) for part in content_parts),
                "tables": {
                    "count": len(note_tables),
                    "markers_in_content": [f"í‘œ {t['table_number']}" for t in note_tables],
                    "enhanced_data": enhanced_table_data  # ê°œì„ ëœ í…Œì´ë¸” ë°ì´í„° ì¶”ê°€
                },
                "metadata": {
                    "file_year": self.file_year,
                    "file_format": self.file_format,
                    **doc_metadata  # ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                }
            }
            chunks.append(chunk)
        
        print(f"âœ… Phase 4 ì™„ë£Œ: {len(chunks)}ê°œ ì£¼ì„ ì²­í¬ ìƒì„±ë¨")
        self.parsed_chunks = chunks

    def _process_tables_with_rag_optimization(self, note_tables, doc_metadata, boundary):
        """RAG ìµœì í™” ë°©ì‹ìœ¼ë¡œ í…Œì´ë¸” ì²˜ë¦¬"""
        enhanced_tables = []
        
        for table_info in note_tables:
            table_element = table_info.get('table_element')
            if not table_element:
                continue
                
            try:
                # í…Œì´ë¸”ì„ ë§¤íŠ¸ë¦­ìŠ¤ë¡œ ë³€í™˜ (ê°œì„ ëœ ë°©ì‹)
                matrix = self.table_to_matrix(table_element)
                
                if not matrix or not self.is_data_table(matrix, table_element):
                    continue
                
                # í…Œì´ë¸” ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                table_metadata = self.extract_table_metadata(table_element, matrix)
                table_metadata['table_number'] = table_info.get('table_number')
                table_metadata['note_number'] = boundary["number"]
                table_metadata['note_title'] = boundary["title"]
                
                # nb í´ë˜ìŠ¤ì—ì„œ ì¶”ì¶œí•œ ë‹¨ìœ„ ì •ë³´ ì ìš©
                if table_info.get('extracted_unit') and not table_metadata.get('unit'):
                    table_metadata['unit'] = table_info['extracted_unit']
                    table_metadata['scale_factor'] = self.scale_factors.get(table_info['extracted_unit'], 1)
                
                # í…Œì´ë¸” ìš”ì•½ ì²­í¬ ìƒì„±
                summary_chunk = self.create_table_summary_chunk(matrix, table_metadata, doc_metadata)
                
                # ì¬ë¬´ ë°ì´í„° ì²­í¬ë“¤ ìƒì„±
                data_chunks = self.create_financial_data_chunks(matrix, table_metadata, doc_metadata)
                
                enhanced_table = {
                    "table_number": table_info.get('table_number'),
                    "summary_chunk": summary_chunk,
                    "data_chunks": data_chunks,
                    "matrix_rows": len(matrix),
                    "matrix_cols": len(matrix[0]) if matrix else 0
                }
                
                enhanced_tables.append(enhanced_table)
                
            except Exception as e:
                print(f"    í…Œì´ë¸” {table_info.get('table_number', '?')} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        return enhanced_tables

    def _insert_table_markers(self, soup, all_tables):
        """í…Œì´ë¸” ìœ„ì¹˜ì— ë§ˆì»¤ë¥¼ ì‚½ì…í•˜ê³  í…Œì´ë¸”ì„ ìˆ˜ì§‘"""
        self.table_counter = 0
        self.collected_tables = []
        self.unit_info = {}  # ë‹¨ìœ„ ì •ë³´ ì €ì¥
        
        for table in all_tables:
            table_class = table.get('class', [])
            if isinstance(table_class, list):
                table_class = ' '.join(table_class)
            
            # nb í´ë˜ìŠ¤ì—ì„œ ì œëª©, ê¸°ê°„, ë‹¨ìœ„ ì •ë³´ ì¶”ì¶œ
            if 'nb' in table_class.lower():
                # ëª¨ë“  CENTER ì •ë ¬ëœ ì…€ í™•ì¸
                center_cells = table.find_all('td', {'align': 'CENTER'})
                statement_title = None  # ë³€ìˆ˜ ì´ˆê¸°í™”
                period_info = None  # ë³€ìˆ˜ ì´ˆê¸°í™”
                
                for cell in center_cells:
                    cell_text = cell.get_text(strip=True)
                    
                    # ì¬ë¬´ì œí‘œ ì œëª© í™•ì¸
                    if re.search(r'í¬\s*ê´„\s*ì†\s*ìµ\s*ê³„\s*ì‚°\s*ì„œ', cell_text):
                        statement_title = "í¬ê´„ì†ìµê³„ì‚°ì„œ"
                        print(f"   ğŸ“‹ í¬ê´„ì†ìµê³„ì‚°ì„œ í—¤ë” ë°œê²¬ (nb): {cell_text}")
                    elif re.search(r'ì¬\s*ë¬´\s*ìƒ\s*íƒœ\s*í‘œ', cell_text):
                        statement_title = "ì¬ë¬´ìƒíƒœí‘œ"
                        print(f"   ğŸ“‹ ì¬ë¬´ìƒíƒœí‘œ í—¤ë” ë°œê²¬ (nb): {cell_text}")
                    elif re.search(r'ì†\s*ìµ\s*ê³„\s*ì‚°\s*ì„œ', cell_text):
                        statement_title = "ì†ìµê³„ì‚°ì„œ"
                        print(f"   ğŸ“‹ ì†ìµê³„ì‚°ì„œ í—¤ë” ë°œê²¬ (nb): {cell_text}")
                    elif re.search(r'ì\s*ë³¸\s*ë³€\s*ë™\s*í‘œ', cell_text):
                        statement_title = "ìë³¸ë³€ë™í‘œ"
                        print(f"   ğŸ“‹ ìë³¸ë³€ë™í‘œ í—¤ë” ë°œê²¬ (nb): {cell_text}")
                    elif re.search(r'í˜„\s*ê¸ˆ\s*í\s*ë¦„\s*í‘œ', cell_text):
                        statement_title = "í˜„ê¸ˆíë¦„í‘œ"
                        print(f"   ğŸ“‹ í˜„ê¸ˆíë¦„í‘œ í—¤ë” ë°œê²¬ (nb): {cell_text}")
                    
                    # ê¸°ê°„ ì •ë³´ ì¶”ì¶œ
                    period_match = re.search(r'ì œ\s*(\d+)\s*ê¸°\s*[:ï¼š]?\s*(20\d{2})ë…„\s*\d+ì›”\s*\d+ì¼', cell_text)
                    if period_match:
                        period_info = {
                            'year': int(period_match.group(2)),
                            'period': int(period_match.group(1))
                        }
                        print(f"   ğŸ“… ê¸°ê°„ ì •ë³´ ë°œê²¬: {period_info['year']}ë…„ (ì œ{period_info['period']}ê¸°)")
                
                # ë‹¨ìœ„ ì •ë³´ ì¶”ì¶œ (ë§ˆì§€ë§‰ ì…€, RIGHT ì •ë ¬)
                right_cells = table.find_all('td', {'align': 'RIGHT'})
                for cell in right_cells:
                    cell_text = cell.get_text(strip=True)
                    unit_patterns = [
                        r'\(ë‹¨ìœ„\s*[:ï¼š]?\s*([^)]+)\)',
                        r'ë‹¨ìœ„\s*[:ï¼š]\s*([ê°€-í£ì›ë°±ë§Œì²œ]+)',
                        r'(ë°±ë§Œì›|ì²œì›|ì›)',
                    ]
                    
                    for pattern in unit_patterns:
                        unit_match = re.search(pattern, cell_text)
                        if unit_match:
                            unit = unit_match.group(1).strip()
                            # ë‹¤ìŒ ë°ì´í„° í…Œì´ë¸”ì— ì ìš©í•  ë‹¨ìœ„ë¡œ ì €ì¥
                            self.unit_info['next_table_unit'] = self.unit_mapping.get(unit, unit)
                            print(f"   ğŸ“ ë‹¨ìœ„ ì •ë³´ ë°œê²¬: {unit} -> {self.unit_info['next_table_unit']}")
                            break
                
                # ì¶”ì¶œëœ ì •ë³´ë¥¼ ë‹¤ìŒ ë°ì´í„° í…Œì´ë¸”ì— ì ìš©í•˜ê¸° ìœ„í•´ ì €ì¥
                if statement_title:
                    self.unit_info['next_table_title'] = statement_title
                    print(f"   ğŸ“‹ ë‹¤ìŒ í…Œì´ë¸” ì œëª© ì„¤ì •: {statement_title}")
                
                # ê¸°ê°„ ì •ë³´ë„ ì €ì¥
                if period_info:
                    self.unit_info['next_table_period'] = period_info
                    print(f"   ğŸ“… ë‹¤ìŒ í…Œì´ë¸” ê¸°ê°„ ì„¤ì •: {period_info['year']}ë…„ (ì œ{period_info['period']}ê¸°)")
                
                table.decompose()
                continue
            
            # ë°ì´í„° í…Œì´ë¸”ì¸ì§€ íŒë‹¨
            if self._is_collectible_table(table):
                self.table_counter += 1
                table_num = self.table_counter
                
                # ì €ì¥ëœ ì •ë³´ ì ìš©
                table_unit = self.unit_info.get('next_table_unit')
                table_title = self.unit_info.get('next_table_title')
                table_period = self.unit_info.get('next_table_period')
                
                # í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘ (ì›ë³¸ í…Œì´ë¸” ìš”ì†Œ í¬í•¨)
                table_info = {
                    'table_number': table_num,
                    'table_element': table,  # ì›ë³¸ í…Œì´ë¸” ìš”ì†Œ ì €ì¥
                    'table_class': table.get('class', []),
                    'extracted_unit': table_unit,  # ì¶”ì¶œëœ ë‹¨ìœ„ ì •ë³´ ì¶”ê°€
                    'statement_title': table_title,  # ì¬ë¬´ì œí‘œ ì œëª© ì¶”ê°€
                    'period_info': table_period  # ê¸°ê°„ ì •ë³´ ì¶”ê°€
                }
                
                # ì •ë³´ ì‚¬ìš© í›„ ì´ˆê¸°í™”
                self.unit_info = {}
                self.collected_tables.append((table_num, table, table_info))
                
                # ë§ˆì»¤ ì‚½ì…
                marker = soup.new_tag("p")
                marker.string = f"[TABLE_MARKER_{table_num}]"
                table.insert_before(marker)
                
                # ì›ë³¸ í…Œì´ë¸”ì€ ì œê±°í•˜ì§€ ì•Šê³  ìˆ¨ê¹€ ì²˜ë¦¬
                table['style'] = 'display: none;'
                
                # ë‹¨ìœ„ ì •ë³´ ì´ˆê¸°í™” (í•œ ë²ˆ ì‚¬ìš© í›„ ë¦¬ì…‹)
                if 'next_table_unit' in self.unit_info:
                    del self.unit_info['next_table_unit']
    
    def _is_collectible_table(self, table):
        """ìˆ˜ì§‘ ê°€ëŠ¥í•œ í…Œì´ë¸”ì¸ì§€ íŒë‹¨"""
        table_class = table.get('class', [])
        if isinstance(table_class, list):
            table_class = ' '.join(table_class)
        
        # TABLE í´ë˜ìŠ¤ ìˆìœ¼ë©´ ìˆ˜ì§‘
        if 'table' in table_class.lower():
            return True
        
        # êµ¬ì¡° ê¸°ë°˜ íŒë³„
        has_thead = table.find('thead') is not None
        row_count = len(table.find_all('tr'))
        
        if has_thead or row_count >= 2:
            # ë‚´ìš© ê¸°ë°˜ íŒë³„
            table_text = table.get_text(strip=True)
            if any(keyword in table_text for keyword in ['ë‹¨ìœ„:', 'êµ¬ë¶„', 'ê³¼ëª©', 'ë‹¹ê¸°', 'ì „ê¸°']):
                return True
        
        return False

    def _find_tables_by_markers(self, content_parts):
        """ì½˜í…ì¸ ì—ì„œ í‘œ ë§ˆì»¤ë¥¼ ì°¾ì•„ í…Œì´ë¸” ì •ë³´ ë°˜í™˜"""
        note_tables = []
        
        for content in content_parts:
            # í‘œ ë§ˆì»¤ ì°¾ê¸°
            marker_matches = re.findall(r'í‘œ (\d+)', content)
            
            for table_num in marker_matches:
                # ìˆ˜ì§‘ëœ í…Œì´ë¸”ì—ì„œ ì°¾ê¸°
                for collected_num, table_element, table_info in self.collected_tables:
                    if collected_num == int(table_num):
                        note_tables.append(table_info)
                        break
        
        return note_tables

    def clean_text(self, text):
        """í…ìŠ¤íŠ¸ ì •ë¦¬ (ê°œì„ ëœ ë²„ì „ - ì˜ë¯¸ì—†ëŠ” íŒ¨í„´ ì œê±°)"""
        if not text:
            return ""
        
        # ê¸°ë³¸ ì •ë¦¬
        text = text.replace('\xa0', ' ')
        text = re.sub(r'\s+', ' ', text).strip()
        
        # ì˜ë¯¸ì—†ëŠ” íŒ¨í„´ ì œê±°
        text = re.sub(r'\\n\\n', '\n', text)  # \\n\\n -> \n
        text = re.sub(r'\\n', ' ', text)      # \\n -> ê³µë°±
        
        # ê³„ì† íŒ¨í„´ë“¤ ì œê±° (ë‹¤ì–‘í•œ í˜•íƒœ)
        continue_patterns = [
            r'\s*,?\s*ê³„ì†\s*[;ï¼š:]\s*',     # ê³„ì†;, ê³„ì†:
            r'\s*,?\s*ê³„ì†\s*$',            # ë¬¸ì¥ ëì˜ ê³„ì†
            r'\s*;\s*$',                    # ë¬¸ì¥ ëì˜ ì„¸ë¯¸ì½œë¡ 
            r'\s*ï¼š\s*$',                   # ë¬¸ì¥ ëì˜ ì „ê° ì½œë¡ 
            r'\s*:\s*$',                    # ë¬¸ì¥ ëì˜ ë°˜ê° ì½œë¡ 
        ]
        
        for pattern in continue_patterns:
            text = re.sub(pattern, '', text)
        
        # ì¤‘ë³µëœ ê³µë°± ì •ë¦¬
        text = re.sub(r'\s+', ' ', text).strip()
        
        # í•œê¸€ ê¸€ì ì‚¬ì´ ê³µë°± ì œê±° (ë” ë„“ì€ ë²”ìœ„)
        # "ìœ  ë™ ì ì‚°", "ë¹„ ìœ  ë™ ë¶€ ì±„" ë“± ì²˜ë¦¬
        if re.search(r'[ê°€-í£]\s+[ê°€-í£]', text):
            # í•œê¸€ ì‚¬ì´ì˜ ê³µë°± ì œê±°
            text = re.sub(r'([ê°€-í£])\s+([ê°€-í£])', r'\1\2', text)
            # ì—¬ëŸ¬ ë²ˆ ì ìš©í•˜ì—¬ ëª¨ë“  ê³µë°± ì œê±°
            while re.search(r'[ê°€-í£]\s+[ê°€-í£]', text):
                text = re.sub(r'([ê°€-í£])\s+([ê°€-í£])', r'\1\2', text)
        
        return text
    
    def is_numeric_like(self, s):
        """ìˆ«ì í˜•íƒœì¸ì§€ í™•ì¸ (ë…¸íŠ¸ë¶ ì½”ë“œ ê¸°ë°˜)"""
        if s is None: 
            return False
        x = str(s).strip()
        if x == "" or x in {"-", "â€“", "â€”"}: 
            return False
        x = x.replace(",", "")
        if x.startswith("(") and x.endswith(")"): 
            x = x[1:-1]
        return bool(re.fullmatch(r"-?\d+(?:\.\d+)?", x))
    
    def build_header(self, matrix, max_header_rows=4):
        """í—¤ë” êµ¬ì¡° ë¶„ì„ (ë…¸íŠ¸ë¶ ì½”ë“œ ê¸°ë°˜)"""
        if not matrix:
            return [], 0, matrix
        
        header_rows = 0
        for i, row in enumerate(matrix[:max_header_rows]):
            nonempty = [x for x in row if str(x or "").strip()]
            numish = sum(1 for x in row if self.is_numeric_like(x) or x in {"-", "â€“", "â€”"})
            if nonempty and numish/len(nonempty) >= 0.6:
                break
            header_rows += 1
        
        if header_rows == 0:
            header_rows = 1
        
        header_grid = matrix[:header_rows]
        body = matrix[header_rows:] if header_rows < len(matrix) else []
        
        if not body:
            body = matrix
            header_grid = []
        
        # ì»¬ëŸ¼ëª… ìƒì„± (ê°œì„ ëœ ë¡œì§)
        ncols = max(len(r) for r in (header_grid or body)) if (header_grid or body) else 0
        cols = []
        
        for j in range(ncols):
            parts = []
            for i in range(len(header_grid)):
                if j < len(header_grid[i]):
                    s = self.clean_text(str(header_grid[i][j] or ""))
                    if s and not self.is_numeric_like(s):  # ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš°ë§Œ
                        parts.append(s)
            
            # ì»¬ëŸ¼ëª… ì¡°í•©
            if parts:
                name = " ".join(parts).strip()
            else:
                name = ""
            
            cols.append(name)
        
        # ì»¬ëŸ¼ëª… í›„ì²˜ë¦¬ (ì¬ë¬´ì œí‘œ íŠ¹í™”)
        processed_cols = []
        for j, c in enumerate(cols):
            if c == "" or self.is_numeric_like(c) or c in {"-","â€“","â€”"}:
                # ë¹ˆ ì»¬ëŸ¼ëª…ì¼ ë•Œ ì¬ë¬´ì œí‘œ íŒ¨í„´ì— ë§ê²Œ ì¶”ì •
                if j == 0:
                    processed_cols.append("í•­ëª©")
                elif j == 1:
                    processed_cols.append("ì£¼ì„")
                else:
                    # í—¤ë” ê·¸ë¦¬ë“œì—ì„œ í•´ë‹¹ ìœ„ì¹˜ì˜ ëª¨ë“  ê°’ í™•ì¸
                    found_meaningful_name = False
                    for header_row in header_grid:
                        if j < len(header_row) and header_row[j]:
                            cell_text = str(header_row[j]).strip()
                            
                            # ë‹¹ê¸°/ì „ê¸° íŒ¨í„´ í™•ì¸
                            if "ë‹¹" in cell_text and ("46" in cell_text or "2014" in cell_text):
                                processed_cols.append("ë‹¹ê¸°")
                                found_meaningful_name = True
                                break
                            elif "ì „" in cell_text and ("45" in cell_text or "2013" in cell_text):
                                processed_cols.append("ì „ê¸°")
                                found_meaningful_name = True
                                break
                            elif re.search(r'20\d{2}', cell_text):  # ì—°ë„ê°€ ìˆìœ¼ë©´
                                if "2014" in cell_text or "46" in cell_text:
                                    processed_cols.append("ë‹¹ê¸°")
                                elif "2013" in cell_text or "45" in cell_text:
                                    processed_cols.append("ì „ê¸°")
                                else:
                                    processed_cols.append(f"ê¸°ê°„{j}")
                                found_meaningful_name = True
                                break
                    
                    if not found_meaningful_name:
                        # colspanìœ¼ë¡œ ì¸í•œ ë¹ˆ ì»¬ëŸ¼ì¼ ê°€ëŠ¥ì„± - ì›ë³¸ í—¤ë”ëª… ì‚¬ìš©
                        if j >= 2:
                            # ë‹¹ê¸° ê´€ë ¨ ì»¬ëŸ¼ë“¤ (ì œ 46ê¸°ëŠ” colspan=2ì´ë¯€ë¡œ 2,3ë²ˆ ì»¬ëŸ¼ ëª¨ë‘ "ì œ 46 (ë‹¹) ê¸°")
                            if j in [2, 3]:
                                processed_cols.append("ì œ 46 (ë‹¹) ê¸°")
                            elif j in [4, 5]:
                                processed_cols.append("ì œ 45 (ì „) ê¸°")
                            else:
                                processed_cols.append(f"ì»¬ëŸ¼{j}")
                        else:
                            processed_cols.append(f"ì»¬ëŸ¼{j}")
            else:
                processed_cols.append(c)
        
        # ì¤‘ë³µ ì»¬ëŸ¼ëª… ì²˜ë¦¬í•˜ì§€ ì•Šê³  ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        return processed_cols, len(header_grid), body
    
    def table_to_matrix(self, table):
        """í…Œì´ë¸”ì„ ë§¤íŠ¸ë¦­ìŠ¤ë¡œ ë³€í™˜ (rag_optimized_parser ë°©ì‹)"""
        rows = table.find_all("tr")
        grid = []
        max_cols = 0

        def next_free_idx(row):
            i = 0
            while i < len(row) and row[i] is not None:
                i += 1
            return i

        for r, tr in enumerate(rows):
            if r >= len(grid):
                grid.append([])
            if len(grid[r]) < max_cols:
                grid[r].extend([None] * (max_cols - len(grid[r])))

            cells = tr.find_all(["th", "td"], recursive=False)
            for cell in cells:
                if len(grid[r]) < max_cols:
                    grid[r].extend([None] * (max_cols - len(grid[r])))
                c_idx = next_free_idx(grid[r])
                
                # í…ìŠ¤íŠ¸ ì¶”ì¶œ ê°œì„ 
                txt = ""
                for content in cell.contents:
                    if isinstance(content, NavigableString):
                        txt += str(content)
                    elif content.name == "br":
                        txt += " "
                    else:
                        txt += content.get_text(" ", strip=True)
                
                txt = self.clean_text(txt)
                
                # rowspan/colspan ì²˜ë¦¬ ê°œì„ 
                rs = int(cell.get("rowspan", "1") or "1")
                cs = int(cell.get("colspan", "1") or "1")

                # colspanì´ ìˆëŠ” ê²½ìš° ì›ë³¸ ê°’ ë³´ì¡´
                original_value = txt if cs > 1 else None

                needed_cols = c_idx + cs
                if needed_cols > max_cols:
                    for rr in range(len(grid)):
                        grid[rr].extend([None] * (needed_cols - len(grid[rr])))
                    max_cols = needed_cols

                for rr in range(r, r + rs):
                    while rr >= len(grid):
                        grid.append([None] * max_cols)
                    for cc in range(c_idx, c_idx + cs):
                        if rr == r and cc == c_idx:
                            grid[rr][cc] = txt
                        else:
                            if grid[rr][cc] is None:
                                # colspan ë¶„í•  ì‹œ ì›ë³¸ ê°’ ì‚¬ìš©
                                if original_value and rr == r:
                                    grid[rr][cc] = original_value
                                else:
                                    grid[rr][cc] = ""

        # ë¹ˆ ì»¬ëŸ¼ ì œê±°
        keep = []
        for j in range(max_cols):
            col_vals = [grid[i][j] if j < len(grid[i]) else None for i in range(len(grid))]
            if any(v not in (None, "") for v in col_vals):
                keep.append(j)
        
        mat = [[row[j] for j in keep] for row in grid]
        mat = [row for row in mat if any(v not in (None, "") for v in row)]
        
        # ì¤‘ë³µëœ í—¤ë” í–‰ ì œê±°
        if len(mat) > 1:
            unique_rows = []
            seen = set()
            for row in mat:
                row_str = "|".join(str(x or "") for x in row)
                if row_str not in seen:
                    unique_rows.append(row)
                    seen.add(row_str)
            mat = unique_rows
        
        return mat
    
    def _process_structured_table(self, thead, tbody):
        """thead/tbodyê°€ êµ¬ë¶„ëœ í…Œì´ë¸” ì²˜ë¦¬"""
        # 1ë‹¨ê³„: thead ì²˜ë¦¬ (í—¤ë”ë§Œ)
        header_matrix = self._convert_to_matrix(thead.find_all("tr"))
        
        # 2ë‹¨ê³„: tbody ì²˜ë¦¬ (ë°ì´í„°ë§Œ)  
        data_matrix = self._convert_to_matrix(tbody.find_all("tr"))
        
        # 3ë‹¨ê³„: í—¤ë” ê²°í•© (thead ë‚´ì—ì„œë§Œ)
        if len(header_matrix) > 1:
            # ë³µì¡í•œ í—¤ë” êµ¬ì¡° ì²˜ë¦¬
            combined_header = self._combine_thead_headers(header_matrix)
        else:
            combined_header = header_matrix[0] if header_matrix else []
        
        # 4ë‹¨ê³„: ìµœì¢… ë§¤íŠ¸ë¦­ìŠ¤ êµ¬ì„±
        final_matrix = [combined_header] if combined_header else []
        final_matrix.extend(data_matrix)
        
        return final_matrix
    
    def _process_unstructured_table(self, table):
        """thead/tbodyê°€ ì—†ëŠ” í…Œì´ë¸” ì²˜ë¦¬ (ê¸°ì¡´ ë°©ì‹)"""
        rows = table.find_all("tr")
        matrix = self._convert_to_matrix(rows)
        
        # ë³µì¡í•œ í—¤ë” ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)
        if len(matrix) >= 2:
            matrix = self.process_complex_headers(matrix)
        
        return matrix
    
    def _convert_to_matrix(self, rows):
        """tr ë¦¬ìŠ¤íŠ¸ë¥¼ ë§¤íŠ¸ë¦­ìŠ¤ë¡œ ë³€í™˜"""
        grid = []
        max_cols = 0

        def next_free_idx(row):
            i = 0
            while i < len(row) and row[i] is not None:
                i += 1
            return i

        # ê¸°ë³¸ ê·¸ë¦¬ë“œ ìƒì„±
        for r, tr in enumerate(rows):
            if r >= len(grid):
                grid.append([])
            
            # í˜„ì¬ í–‰ì„ max_colsê¹Œì§€ í™•ì¥
            while len(grid[r]) < max_cols:
                grid[r].append(None)

            cells = tr.find_all(["th", "td"], recursive=False)
            for cell in cells:
                # í˜„ì¬ í–‰ì—ì„œ ë‹¤ìŒ ë¹ˆ ìœ„ì¹˜ ì°¾ê¸°
                c_idx = next_free_idx(grid[r])
                txt = self.clean_text(cell.get_text(" ", strip=True))
                rs = int(cell.get("rowspan", "1") or "1")
                cs = int(cell.get("colspan", "1") or "1")

                # í•„ìš”í•œ ì»¬ëŸ¼ ìˆ˜ ê³„ì‚°
                needed_cols = c_idx + cs
                if needed_cols > max_cols:
                    # ëª¨ë“  í–‰ì„ ìƒˆë¡œìš´ ì»¬ëŸ¼ ìˆ˜ì— ë§ê²Œ í™•ì¥
                    for rr in range(len(grid)):
                        while len(grid[rr]) < needed_cols:
                            grid[rr].append(None)
                    max_cols = needed_cols

                # rowspanê³¼ colspanì— ë”°ë¼ ì…€ ì±„ìš°ê¸°
                for rr in range(r, r + rs):
                    # í•„ìš”í•œ í–‰ì´ ì—†ìœ¼ë©´ ìƒì„±
                    while rr >= len(grid):
                        grid.append([None] * max_cols)
                    
                    # í˜„ì¬ í–‰ì„ max_colsê¹Œì§€ í™•ì¥
                    while len(grid[rr]) < max_cols:
                        grid[rr].append(None)
                    
                    for cc in range(c_idx, c_idx + cs):
                        if rr == r and cc == c_idx:
                            # ì›ë³¸ ì…€ ìœ„ì¹˜ì—ëŠ” ì‹¤ì œ í…ìŠ¤íŠ¸
                            grid[rr][cc] = txt
                        else:
                            # ë³‘í•©ëœ ì…€ ìœ„ì¹˜ì—ëŠ” ë¹ˆ ë¬¸ìì—´ (Noneì´ ì•„ë‹Œ)
                            if grid[rr][cc] is None:
                                grid[rr][cc] = ""

        # ë¹ˆ ì»¬ëŸ¼ ì œê±°
        keep = []
        for j in range(max_cols):
            col_vals = [grid[i][j] if j < len(grid[i]) else None for i in range(len(grid))]
            if any(v not in (None, "") for v in col_vals):
                keep.append(j)
        
        # ìœ íš¨í•œ ì»¬ëŸ¼ë§Œ ìœ ì§€
        mat = []
        for row in grid:
            new_row = [row[j] if j < len(row) else "" for j in keep]
            if any(v not in (None, "") for v in new_row):
                mat.append(new_row)
        
        return mat
    
    def _combine_thead_headers(self, header_matrix):
        """thead ë‚´ì˜ ë³µì¡í•œ í—¤ë” ê²°í•©"""
        if not header_matrix:
            return []
        
        if len(header_matrix) == 1:
            return header_matrix[0]
        
        # ë‹¤ì¸µ í—¤ë” ê²°í•© (ê¸°ì¡´ ë¡œì§ í™œìš©)
        return self.combine_multi_level_headers(header_matrix)

    def _adjust_span_info_for_kept_columns(self, span_info, keep_columns):
        """ìœ íš¨í•œ ì»¬ëŸ¼ì— ë§ê²Œ span ì •ë³´ ì¡°ì •"""
        adjusted_span_info = []
        
        # ì›ë³¸ ì»¬ëŸ¼ ì¸ë±ìŠ¤ -> ìƒˆ ì»¬ëŸ¼ ì¸ë±ìŠ¤ ë§¤í•‘
        col_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(keep_columns)}
        
        for row_spans in span_info:
            adjusted_row_spans = []
            for span in row_spans:
                old_col = span['col']
                old_end_col = span['end_col']
                
                # ì‹œì‘ ì»¬ëŸ¼ì´ ìœ íš¨í•œ ì»¬ëŸ¼ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
                if old_col in col_mapping:
                    # ë ì»¬ëŸ¼ë„ ë§¤í•‘
                    new_end_col = old_col  # ê¸°ë³¸ê°’
                    for kept_col in keep_columns:
                        if kept_col <= old_end_col:
                            new_end_col = kept_col
                    
                    adjusted_span = {
                        **span,
                        'col': col_mapping[old_col],
                        'end_col': col_mapping.get(new_end_col, col_mapping[old_col]),
                        'adjusted_colspan': col_mapping.get(new_end_col, col_mapping[old_col]) - col_mapping[old_col] + 1
                    }
                    adjusted_row_spans.append(adjusted_span)
            
            adjusted_span_info.append(adjusted_row_spans)
        
        return adjusted_span_info
    
    def process_complex_headers_with_span_info(self, matrix, span_info):
        """span ì •ë³´ë¥¼ í™œìš©í•œ ë³µì¡í•œ í—¤ë” êµ¬ì¡° ì²˜ë¦¬"""
        if len(matrix) < 2 or not span_info:
            return matrix
        
        # thead ì˜ì—­ ê°ì§€ (ê°œì„ ëœ ë¡œì§)
        header_rows = []
        data_start_idx = 0
        
        # span ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í—¤ë” í–‰ ìˆ˜ ê²°ì •
        max_header_rows = len([row_spans for row_spans in span_info if any(span.get('rowspan', 1) > 1 or span.get('colspan', 1) > 1 for span in row_spans)])
        if max_header_rows == 0:
            max_header_rows = 2  # ê¸°ë³¸ê°’
        
        for i, row in enumerate(matrix):
            # span ì •ë³´ê°€ ìˆëŠ” í–‰ê¹Œì§€ë§Œ í—¤ë”ë¡œ ê°„ì£¼
            if i < len(span_info) and i < max_header_rows:
                # í•´ë‹¹ í–‰ì— span ì •ë³´ê°€ ìˆìœ¼ë©´ í—¤ë”ë¡œ ê°„ì£¼
                if span_info[i]:  # span ì •ë³´ê°€ ìˆëŠ” í–‰
                    header_rows.append(row)
                    continue
            
            # ìˆ«ìê°€ ë§ì€ í–‰ì´ ë‚˜ì˜¤ë©´ ë°ì´í„° ì‹œì‘ìœ¼ë¡œ íŒë‹¨
            numeric_count = sum(1 for cell in row if cell and re.search(r'\d', str(cell)))
            if numeric_count > len(row) * 0.3:  # 30% ì´ìƒì´ ìˆ«ìë©´ ë°ì´í„° í–‰
                data_start_idx = i
                break
            
            # ì¼ë°˜ì ì¸ ë°ì´í„° íŒ¨í„´ ê°ì§€
            if i > 1 and self._looks_like_data_row(row):
                data_start_idx = i
                break
                
            header_rows.append(row)
        
        if len(header_rows) < 2:
            return matrix
        
        # span ì •ë³´ë¥¼ í™œìš©í•œ í—¤ë” ê²°í•©
        combined_header = self.combine_headers_with_span_info(header_rows, span_info[:len(header_rows)])
        
        # ìƒˆë¡œìš´ ë§¤íŠ¸ë¦­ìŠ¤ êµ¬ì„±
        new_matrix = [combined_header]
        if data_start_idx < len(matrix):
            new_matrix.extend(matrix[data_start_idx:])
        
        return new_matrix
    
    def _looks_like_data_row(self, row):
        """ë°ì´í„° í–‰ì²˜ëŸ¼ ë³´ì´ëŠ”ì§€ íŒë‹¨"""
        if not row:
            return False
        
        # ì²« ë²ˆì§¸ ì…€ì´ ì¼ë°˜ì ì¸ ë°ì´í„° íŒ¨í„´ì¸ì§€ í™•ì¸
        first_cell = row[0] if row else ""
        
        # ê¸°ì—…ëª…, í•­ëª©ëª… ë“±ì˜ íŒ¨í„´
        data_patterns = [
            r'^[ê°€-í£]+$',  # í•œê¸€ë§Œ (ê¸°ì—…ëª… ë“±)
            r'^[ê°€-í£\s]+[ê°€-í£]$',  # í•œê¸€ + ê³µë°± (ë³µí•© í•­ëª©ëª…)
            r'ê¸°íƒ€$',  # 'ê¸°íƒ€'ë¡œ ëë‚˜ëŠ” í•­ëª©
            r'ê³„$',   # 'ê³„'ë¡œ ëë‚˜ëŠ” í•­ëª©
            r'í•©ê³„$', # 'í•©ê³„'ë¡œ ëë‚˜ëŠ” í•­ëª©
        ]
        
        for pattern in data_patterns:
            if re.match(pattern, first_cell):
                return True
        
        return False
    
    def combine_headers_with_span_info(self, header_rows, header_span_info):
        """span ì •ë³´ë¥¼ í™œìš©í•œ í—¤ë” ê²°í•©"""
        if not header_rows or not header_span_info:
            return header_rows[0] if header_rows else []
        
        num_cols = len(header_rows[-1]) if header_rows else 0
        combined_header = []
        
        # ê° ì»¬ëŸ¼ì— ëŒ€í•´ ìƒìœ„ í—¤ë” ì •ë³´ ìˆ˜ì§‘
        for col_idx in range(num_cols):
            column_categories = []
            
            # ê° í—¤ë” í–‰ì˜ span ì •ë³´ì—ì„œ í•´ë‹¹ ì»¬ëŸ¼ì„ í¬í•¨í•˜ëŠ” ì…€ ì°¾ê¸°
            for row_idx, row_spans in enumerate(header_span_info):
                for span in row_spans:
                    # í˜„ì¬ ì»¬ëŸ¼ì´ ì´ span ë²”ìœ„ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
                    if span['col'] <= col_idx <= span['end_col']:
                        if span['text'] and span['text'].strip():
                            column_categories.append(span['text'])
                        break
            
            # ì¹´í…Œê³ ë¦¬ ê²°í•©
            if len(column_categories) == 0:
                combined_name = f"ì»¬ëŸ¼{col_idx + 1}"
            elif len(column_categories) == 1:
                combined_name = column_categories[0]
            else:
                # ë‹¤ì¤‘ ì¹´í…Œê³ ë¦¬ì¸ ê²½ìš° ê²°í•©
                # ë§ˆì§€ë§‰ì´ êµ¬ì²´ì ì¸ í•­ëª©ì´ë©´ ìƒìœ„ ì¹´í…Œê³ ë¦¬ì™€ ê²°í•©
                last_category = column_categories[-1]
                if self._is_specific_financial_item(last_category):
                    # ìƒìœ„ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
                    parent_category = None
                    for cat in column_categories[:-1]:
                        if self._is_period_category(cat):
                            parent_category = cat
                            break
                    
                    if parent_category:
                        combined_name = f"{parent_category} - {last_category}"
                    else:
                        combined_name = " - ".join(column_categories)
                else:
                    combined_name = " - ".join(column_categories)
            
            combined_header.append(combined_name)
        
        return combined_header
    
    def _is_specific_financial_item(self, text):
        """êµ¬ì²´ì ì¸ ì¬ë¬´ í•­ëª©ì¸ì§€ íŒë‹¨"""
        financial_items = [
            'ë§¤ì¶œì±„ê¶Œ', 'ë¯¸ìˆ˜ê¸ˆ', 'ì§€ë¶„ìœ¨', 'ì·¨ë“ì›ê°€', 'ì¥ë¶€ê°€ì•¡', 'ë³´ìœ ì£¼ì‹ìˆ˜',
            'ìì‚°', 'ë¶€ì±„', 'ìë³¸', 'ë§¤ì¶œ', 'ë¹„ìš©', 'ì´ìµ', 'ì†ì‹¤', 'ì‹œì¥ê°€ì¹˜',
            'í‰ê°€ì „ê¸ˆì•¡', 'í‰ê°€ì¶©ë‹¹ê¸ˆ', 'ì¶©ë‹¹ê¸ˆ', 'í‰ê°€'
        ]
        return any(item in text for item in financial_items)
    
    def _is_period_category(self, text):
        """ê¸°ê°„ ì¹´í…Œê³ ë¦¬ì¸ì§€ íŒë‹¨"""
        period_categories = ['ë‹¹ê¸°', 'ì „ê¸°', 'ë‹¹ê¸°ë§', 'ì „ê¸°ë§', 'ë‹¹ë¶„ê¸°', 'ì „ë¶„ê¸°']
        return any(period in text for period in period_categories)

    def process_complex_headers(self, matrix):
        """ë³µì¡í•œ í—¤ë” êµ¬ì¡° ì²˜ë¦¬ (ë‹¤ì¸µ í—¤ë”) - í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ í•¨ìˆ˜"""
        if len(matrix) < 2:
            return matrix
        
        # thead ì˜ì—­ ê°ì§€ (ì²˜ìŒ ëª‡ í–‰ì´ ëª¨ë‘ í—¤ë”ì¸ì§€ í™•ì¸)
        header_rows = []
        data_start_idx = 0
        
        for i, row in enumerate(matrix):
            # ìˆ«ìê°€ ë§ì€ í–‰ì´ ë‚˜ì˜¤ë©´ ë°ì´í„° ì‹œì‘ìœ¼ë¡œ íŒë‹¨
            numeric_count = sum(1 for cell in row if cell and re.search(r'\d', str(cell)))
            if numeric_count > len(row) * 0.5 and i > 0:  # 50% ì´ìƒì´ ìˆ«ìì´ê³  ì²« í–‰ì´ ì•„ë‹ˆë©´
                data_start_idx = i
                break
            header_rows.append(row)
        
        if len(header_rows) < 2:
            return matrix  # ë‹¨ìˆœ í—¤ë”ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        
        # ë‹¤ì¸µ í—¤ë”ë¥¼ ë‹¨ì¼ í—¤ë”ë¡œ ë³€í™˜
        combined_header = self.combine_multi_level_headers(header_rows)
        
        # ìƒˆë¡œìš´ ë§¤íŠ¸ë¦­ìŠ¤ êµ¬ì„±
        new_matrix = [combined_header]
        if data_start_idx < len(matrix):
            new_matrix.extend(matrix[data_start_idx:])
        
        return new_matrix

    def combine_multi_level_headers(self, header_rows):
        """ë‹¤ì¸µ í—¤ë”ë¥¼ ê²°í•©í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ì»¬ëŸ¼ëª… ìƒì„± (ìœ„ì¹˜ ê¸°ë°˜ ìƒìœ„ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ê°•í™”)"""
        if not header_rows:
            return []
        
        combined_header = []
        num_cols = max(len(row) for row in header_rows) if header_rows else 0
        
        # 1ë‹¨ê³„: ì²« ë²ˆì§¸ í–‰ì—ì„œ ìƒìœ„ ì¹´í…Œê³ ë¦¬ ë²”ìœ„ íŒŒì•…
        category_ranges = self._extract_category_ranges(header_rows)
        
        # ê° ì»¬ëŸ¼ì— ëŒ€í•´ ìƒìœ„ í—¤ë” ì •ë³´ë¥¼ ì •í™•íˆ ë§¤í•‘
        for col_idx in range(num_cols):
            # í•´ë‹¹ ì»¬ëŸ¼ì˜ ëª¨ë“  ìƒìœ„ í—¤ë” ì •ë³´ ìˆ˜ì§‘
            column_headers = []
            
            # ê° í—¤ë” ë ˆë²¨ì—ì„œ í•´ë‹¹ ì»¬ëŸ¼ì˜ í—¤ë” ì°¾ê¸°
            for row_idx, header_row in enumerate(header_rows):
                if col_idx < len(header_row):
                    cell_value = header_row[col_idx]
                    if cell_value and cell_value.strip():
                        column_headers.append(cell_value)
            
            # í—¤ë” ê²°í•© ë¡œì§
            if len(column_headers) == 0:
                combined_name = f"ì»¬ëŸ¼{col_idx + 1}"
            elif len(column_headers) == 1:
                # ë‹¨ì¼ í—¤ë”ì¸ ê²½ìš° - ìœ„ì¹˜ ê¸°ë°˜ ìƒìœ„ ì¹´í…Œê³ ë¦¬ ê°•ì œ ë§¤í•‘
                header_text = column_headers[0]
                
                # ìœ„ì¹˜ ê¸°ë°˜ìœ¼ë¡œ ìƒìœ„ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
                category = self._find_category_by_position(col_idx, category_ranges)
                
                if category and self._is_specific_financial_item(header_text):
                    combined_name = f"{category} - {header_text}"
                else:
                    combined_name = header_text
            else:
                # ë‹¤ì¤‘ í—¤ë”ì¸ ê²½ìš°
                last_header = column_headers[-1]
                
                # ìƒìœ„ ì¹´í…Œê³ ë¦¬ ì°¾ê¸° (ê¸°ì¡´ ë°©ì‹ + ìœ„ì¹˜ ê¸°ë°˜ ë³´ì™„)
                category = None
                for header in column_headers[:-1]:
                    if header in ['ë‹¹ê¸°', 'ì „ê¸°', 'ë‹¹ê¸°ë§', 'ì „ê¸°ë§']:
                        category = header
                        break
                
                # ì¹´í…Œê³ ë¦¬ë¥¼ ì°¾ì§€ ëª»í–ˆìœ¼ë©´ ìœ„ì¹˜ ê¸°ë°˜ìœ¼ë¡œ ì°¾ê¸°
                if not category:
                    category = self._find_category_by_position(col_idx, category_ranges)
                
                if category and self._is_specific_financial_item(last_header):
                    combined_name = f"{category} - {last_header}"
                else:
                    combined_name = " - ".join(column_headers) if len(column_headers) > 1 else column_headers[0]
            
            combined_header.append(combined_name)
        
        return combined_header
    
    def _extract_category_ranges(self, header_rows):
        """ì²« ë²ˆì§¸ í—¤ë” í–‰ì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ ì»¬ëŸ¼ ë²”ìœ„ ì¶”ì¶œ (colspan ê¸°ë°˜ ì •í™•í•œ ê³„ì‚°)"""
        if not header_rows:
            return {}
        
        category_ranges = {}
        first_row = header_rows[0]
        
        # ì‹¤ì œ ì»¬ëŸ¼ ìœ„ì¹˜ ì¶”ì 
        current_col_pos = 0
        
        for i, cell in enumerate(first_row):
            if cell and cell.strip():
                cell_text = cell.strip()
                
                if cell_text in ['ë‹¹ê¸°', 'ì „ê¸°', 'ë‹¹ê¸°ë§', 'ì „ê¸°ë§']:
                    # ì´ ì¹´í…Œê³ ë¦¬ê°€ ì°¨ì§€í•˜ëŠ” ì»¬ëŸ¼ ìˆ˜ ê³„ì‚°
                    # ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ê¹Œì§€ì˜ ë¹ˆ ì…€ ê°œìˆ˜ë¡œ colspan ì¶”ì •
                    colspan = 1
                    
                    # ë‹¤ìŒ ë¹„ì–´ìˆì§€ ì•Šì€ ì…€ê¹Œì§€ì˜ ê±°ë¦¬ë¡œ colspan ê³„ì‚°
                    for j in range(i + 1, len(first_row)):
                        if first_row[j] and first_row[j].strip():
                            break
                        colspan += 1
                    
                    # ë§ˆì§€ë§‰ ì¹´í…Œê³ ë¦¬ì¸ ê²½ìš° ë‚¨ì€ ëª¨ë“  ì»¬ëŸ¼
                    if i == len([c for c in first_row if c and c.strip()]) - 1:
                        remaining_cols = len(first_row) - current_col_pos
                        if remaining_cols > colspan:
                            colspan = remaining_cols
                    
                    # ì¹´í…Œê³ ë¦¬ ë²”ìœ„ ì €ì¥
                    end_col_pos = current_col_pos + colspan
                    category_ranges[cell_text] = {
                        'start': current_col_pos,
                        'end': end_col_pos - 1,
                        'columns': list(range(current_col_pos, end_col_pos))
                    }
                    current_col_pos = end_col_pos
                else:
                    # ì¹´í…Œê³ ë¦¬ê°€ ì•„ë‹Œ ì¼ë°˜ í—¤ë”
                    current_col_pos += 1
        
        return category_ranges
    
    def _find_category_by_position(self, col_idx, category_ranges):
        """ì»¬ëŸ¼ ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒìœ„ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°"""
        for category, range_info in category_ranges.items():
            if col_idx in range_info['columns']:
                return category
        return None
    
    def _infer_category_from_context(self, col_idx, total_cols, header_rows):
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ ì¹´í…Œê³ ë¦¬ ì¶”ë¡ """
        if col_idx == 0:
            return None  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì€ ë³´í†µ êµ¬ë¶„/ê¸°ì—…ëª… ë“±
        
        # ì²« ë²ˆì§¸ í—¤ë” í–‰ì—ì„œ ìƒìœ„ ì¹´í…Œê³ ë¦¬ íŒ¨í„´ ì°¾ê¸°
        if len(header_rows) >= 1:
            first_row = header_rows[0]
            
            # íŒ¨í„´ ë¶„ì„: "ë‹¹ê¸°ë§", "ì „ê¸°ë§" ë“±ì˜ ìœ„ì¹˜ íŒŒì•…
            category_positions = {}
            for i, cell in enumerate(first_row):
                if cell in ['ë‹¹ê¸°', 'ì „ê¸°', 'ë‹¹ê¸°ë§', 'ì „ê¸°ë§']:
                    category_positions[i] = cell
            
            # í˜„ì¬ ì»¬ëŸ¼ì´ ì–´ë–¤ ì¹´í…Œê³ ë¦¬ ì˜ì—­ì— ì†í•˜ëŠ”ì§€ íŒë‹¨
            for pos, category in category_positions.items():
                # ì‹¤ì œ í…Œì´ë¸” êµ¬ì¡° ë¶„ì„:
                # ê¸°ì—…ëª…(0) | ë‹¹ê¸°ë§(1-4) | ì „ê¸°ë§(5)
                if category in ['ë‹¹ê¸°', 'ë‹¹ê¸°ë§']:
                    if 1 <= col_idx <= 4:  # ë‹¹ê¸°ë§ ì˜ì—­
                        return category
                elif category in ['ì „ê¸°', 'ì „ê¸°ë§']:
                    if col_idx >= 5:  # ì „ê¸°ë§ ì˜ì—­
                        return category
        
        # ê¸°ë³¸ ìœ„ì¹˜ ê¸°ë°˜ ì¶”ë¡ 
        return self._infer_category_from_position(col_idx, total_cols)
    
    def _infer_category_from_position(self, col_idx, total_cols):
        """ì»¬ëŸ¼ ìœ„ì¹˜ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ë¡  (ë‹¹ê¸°/ì „ê¸°)"""
        # ì¼ë°˜ì ì¸ íŒ¨í„´: ì²« ë²ˆì§¸ ì»¬ëŸ¼ì€ êµ¬ë¶„, ê·¸ ë‹¤ìŒë¶€í„° ë‹¹ê¸°/ì „ê¸°ê°€ ë²ˆê°ˆì•„ ë‚˜íƒ€ë‚¨
        if col_idx == 0:
            return None  # êµ¬ë¶„ ì»¬ëŸ¼
        
        # ì»¬ëŸ¼ì„ ì ˆë°˜ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë‹¹ê¸°/ì „ê¸° íŒë‹¨
        data_cols = total_cols - 1  # êµ¬ë¶„ ì»¬ëŸ¼ ì œì™¸
        half_point = (data_cols // 2) + 1
        
        if col_idx <= half_point:
            return "ë‹¹ê¸°"
        else:
            return "ì „ê¸°"

    def is_data_table(self, matrix: List[List[str]], table_element=None) -> bool:
        """ë°ì´í„° í…Œì´ë¸” ì—¬ë¶€ íŒë³„ (thead/tbody êµ¬ì¡° ìš°ì„  í™•ì¸)"""
        if not matrix or len(matrix) < 2:
            return False
        
        # 1ìˆœìœ„: HTML êµ¬ì¡° í™•ì¸ (thead/tbodyê°€ ìˆìœ¼ë©´ ë°ì´í„° í…Œì´ë¸”)
        if table_element:
            has_thead = table_element.find('thead') is not None
            has_tbody = table_element.find('tbody') is not None
            
            if has_thead or has_tbody:
                return True
            
            # TABLE í´ë˜ìŠ¤ê°€ ìˆìœ¼ë©´ ë°ì´í„° í…Œì´ë¸”ë¡œ ê°„ì£¼
            table_class = table_element.get('class', [])
            if isinstance(table_class, list):
                table_class = ' '.join(table_class)
            if 'table' in table_class.lower():
                return True
        
        # 2ìˆœìœ„: ë‚´ìš© ê¸°ë°˜ íŒë³„ (ìˆ«ì ë¹„ìœ¨)
        total_cells = sum(len(row) for row in matrix)
        numeric_cells = 0
        
        for row in matrix:
            for cell in row:
                if cell and re.search(r'\d', str(cell)):
                    numeric_cells += 1
        
        # ìˆ«ì ë¹„ìœ¨ ê¸°ì¤€ì„ ë‚®ì¶¤ (30% â†’ 20%)
        return numeric_cells / total_cells > 0.2 if total_cells > 0 else False

    def extract_table_metadata(self, table_element, matrix: List[List[str]]) -> Dict[str, Any]:
        """í…Œì´ë¸” ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ê°•í™”ëœ ë²„ì „)"""
        # ì£¼ë³€ í…ìŠ¤íŠ¸ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        context_text = ""
        
        # ì´ì „ í˜•ì œ ìš”ì†Œë“¤ì—ì„œ ì œëª©/ì„¤ëª… ì°¾ê¸°
        prev_elements = []
        current = table_element.previous_sibling
        for _ in range(5):  # ìµœëŒ€ 5ê°œ ì´ì „ ìš”ì†Œ í™•ì¸
            if current is None:
                break
            if hasattr(current, 'get_text'):
                text = self.clean_text(current.get_text())
                if text and len(text) > 5:
                    prev_elements.append(text)
            current = current.previous_sibling
        
        context_text = " ".join(reversed(prev_elements))
        
        # í…Œì´ë¸” ë‚´ìš© ë¶„ì„
        table_text = " ".join(str(x or "") for r in matrix for x in r)
        combined_text = context_text + " " + table_text
        
        metadata = {}
        
        # ë‹¨ìœ„ ì¶”ì¶œ (ë” ì •í™•í•œ íŒ¨í„´)
        unit_patterns = [
            r'\(ë‹¨ìœ„\s*[:ï¼š]?\s*([^)]+)\)',
            r'ë‹¨ìœ„\s*[:ï¼š]\s*([ê°€-í£ì›ë°±ë§Œì²œ]+)',
            r'\(ë‹¨ìœ„\s*([^)]+)\)'
        ]
        
        unit = None
        scale_factor = 1
        for pattern in unit_patterns:
            unit_match = re.search(pattern, combined_text)
            if unit_match:
                unit_text = unit_match.group(1).strip()
                unit = self.unit_mapping.get(unit_text, unit_text)
                scale_factor = self.scale_factors.get(unit, 1)
                break
        
        metadata['unit'] = unit
        metadata['scale_factor'] = scale_factor
        
        # ê¸°ê°„ ì¶”ì¶œ
        period_matches = re.findall(r'ì œ\s*(\d+)\s*ê¸°', combined_text)
        if period_matches:
            periods = [f"ì œ {p} ê¸°" for p in period_matches]
            metadata['periods'] = periods
            metadata['current_period'] = periods[0] if periods else None
        
        # ë‚ ì§œ ë²”ìœ„ ì¶”ì¶œ
        date_patterns = [
            r'(20\d{2})\.(\d{2})\.(\d{2})\s*~\s*(20\d{2})\.(\d{2})\.(\d{2})',
            r'(20\d{2})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼\s*~\s*(20\d{2})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼'
        ]
        
        for pattern in date_patterns:
            date_match = re.search(pattern, combined_text)
            if date_match:
                groups = date_match.groups()
                if len(groups) >= 6:
                    metadata['period_start'] = f"{groups[0]}-{groups[1].zfill(2)}-{groups[2].zfill(2)}"
                    metadata['period_end'] = f"{groups[3]}-{groups[4].zfill(2)}-{groups[5].zfill(2)}"
                break
        
        # í…Œì´ë¸” ì œëª© ì¶”ì¶œ (ê°•í™”ëœ íŒ¨í„´)
        title_patterns = [
            r'([ê°€-í£\s]+(?:ì¬ë¬´ìƒíƒœí‘œ|ì†ìµê³„ì‚°ì„œ|í¬ê´„ì†ìµê³„ì‚°ì„œ|ìë³¸ë³€ë™í‘œ|í˜„ê¸ˆíë¦„í‘œ))',
            r'([ê°€-í£\sÂ·â€¢â€“â€”â€•-]{5,30})\s*\(ë‹¨ìœ„',  # ë‹¨ìœ„ ì•ì˜ ì œëª©
            r'<í‘œ\s*(\d+)>\s*([ê°€-í£\sÂ·â€¢â€“â€”â€•-]{3,30})',  # <í‘œ N> í˜•ì‹
            r'([ê°€-í£\s]{3,20})\s*\(',  # ê´„í˜¸ ì•ì˜ ì œëª©
            r'í‘œ\s*\d+\s*([ê°€-í£\s]+)',  # í‘œ N ë’¤ì˜ ì œëª©
            r'([ê°€-í£\s]{3,30})\s*\(ë°±ë§Œì›\)',  # ë°±ë§Œì› ì•ì˜ ì œëª©
            r'([ê°€-í£\s]{3,30})\s*\(ì²œì›\)',   # ì²œì› ì•ì˜ ì œëª©
        ]
        
        for pattern in title_patterns:
            match = re.search(pattern, combined_text)  # context_text ëŒ€ì‹  combined_textë„ í™•ì¸
            if match:
                title = self.clean_text(match.group(1) if '<í‘œ' not in pattern else match.group(2))
                if len(title) > 2:
                    metadata['table_title'] = title
                    break
        
        # context_textì—ì„œë„ í•œë²ˆ ë” ì‹œë„
        if not metadata.get('table_title'):
            for pattern in title_patterns:
                match = re.search(pattern, context_text)
                if match:
                    title = self.clean_text(match.group(1) if '<í‘œ' not in pattern else match.group(2))
                    if len(title) > 2:
                        metadata['table_title'] = title
                        break
        
        # ì¬ë¬´ì œí‘œ ìœ í˜• íŒë³„
        if any(keyword in combined_text for keyword in ['ì¬ë¬´ìƒíƒœí‘œ', 'ëŒ€ì°¨ëŒ€ì¡°í‘œ']):
            metadata['statement_type'] = 'ì¬ë¬´ìƒíƒœí‘œ'
        elif any(keyword in combined_text for keyword in ['ì†ìµê³„ì‚°ì„œ', 'í¬ê´„ì†ìµ']):
            metadata['statement_type'] = 'ì†ìµê³„ì‚°ì„œ'
        elif 'í˜„ê¸ˆíë¦„' in combined_text:
            metadata['statement_type'] = 'í˜„ê¸ˆíë¦„í‘œ'
        elif 'ìë³¸ë³€ë™' in combined_text:
            metadata['statement_type'] = 'ìë³¸ë³€ë™í‘œ'
        else:
            metadata['statement_type'] = 'ê¸°íƒ€'
        
        return metadata

    def create_table_summary_chunk(self, matrix: List[List[str]], table_metadata: Dict[str, Any], doc_metadata: Dict[str, Any]) -> Dict[str, Any]:
        """í…Œì´ë¸” ìš”ì•½ ì²­í¬ ìƒì„± (rag_optimized_parser ë°©ì‹)"""
        # í…Œì´ë¸” ê°œìš” ìƒì„±
        summary_parts = []
        
        if table_metadata.get('table_title'):
            summary_parts.append(f"í…Œì´ë¸”: {table_metadata['table_title']}")
        
        if table_metadata.get('statement_type'):
            summary_parts.append(f"ìœ í˜•: {table_metadata['statement_type']}")
        
        if table_metadata.get('periods'):
            summary_parts.append(f"ê¸°ê°„: {', '.join(table_metadata['periods'])}")
        
        if table_metadata.get('unit'):
            summary_parts.append(f"ë‹¨ìœ„: {table_metadata['unit']}")
        
        # ì£¼ìš” í•­ëª©ë“¤ ë‚˜ì—´
        if len(matrix) > 1:
            items = [row[0] for row in matrix[1:] if row and row[0]]
            if items:
                summary_parts.append(f"ì£¼ìš” í•­ëª©: {', '.join(items[:5])}")
                if len(items) > 5:
                    summary_parts.append(f"ë“± ì´ {len(items)}ê°œ í•­ëª©")
        
        content = ". ".join(summary_parts)
        
        # ì£¼ì„ ì •ë³´ ì¶”ê°€
        note_info = f"ì£¼ì„ {table_metadata.get('note_number', '?')}. {table_metadata.get('note_title', '')}"
        if note_info.strip() != "ì£¼ì„ ?.":
            content = f"{note_info} - {content}"
        
        chunk_metadata = {
            **doc_metadata,
            **table_metadata,
            'item_count': len(matrix) - 1 if len(matrix) > 1 else 0,
            'column_count': len(matrix[0]) if matrix else 0
        }
        
        return {
            "id": self.generate_chunk_id(content),
            "content": content,
            "content_type": "table_summary",
            "metadata": chunk_metadata
        }

    def create_financial_data_chunks(self, matrix: List[List[str]], table_metadata: Dict[str, Any], doc_metadata: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ì¬ë¬´ ë°ì´í„° ì²­í¬ ìƒì„± (ê°•í™”ëœ ë²„ì „)"""
        chunks = []
        
        if len(matrix) < 2:
            return chunks
        
        # í—¤ë” ë¶„ì„
        header = matrix[0]
        data_rows = matrix[1:]
        
        # ë‹¨ìœ„ ë° ìŠ¤ì¼€ì¼ ì •ë³´
        unit = table_metadata.get('unit')
        scale_factor = table_metadata.get('scale_factor', 1)
        
        # ê° ë°ì´í„° í–‰ì„ ì˜ë¯¸ ìˆëŠ” ì²­í¬ë¡œ ë³€í™˜
        for row_idx, row in enumerate(data_rows):
            if not any(cell for cell in row):
                continue
            
            item_name = row[0] if row else ""
            if not item_name or len(item_name.strip()) < 2:
                continue
            
            # ì¬ë¬´ í•­ëª© ë¶„ë¥˜
            financial_category = self.classify_financial_item(item_name)
            
            # ê¸ˆì•¡ ë°ì´í„° ì¶”ì¶œ (ì •ê·œí™” ì ìš©)
            amounts = {}
            table_json_row = {}
            
            for i, cell in enumerate(row[1:], 1):
                if i < len(header):
                    col_name = header[i]
                    amount_info = self.normalize_amount(cell, unit, scale_factor)
                    
                    # ì²­í¬ìš© amounts (ê¸°ì¡´ í˜•ì‹ ìœ ì§€)
                    if amount_info['value'] is not None:
                        amounts[col_name] = amount_info
                    
                    # table_jsonìš© ë°ì´í„°
                    if amount_info['normalized_value'] is not None:
                        table_json_row[col_name] = amount_info['normalized_value']
                    elif cell and cell.strip() not in ['-', '', 'â€•', 'â€”']:
                        table_json_row[col_name] = cell.strip()
            
            if not amounts:
                continue
            
            # table_jsonì„ ì—´(column) ê¸°ì¤€ìœ¼ë¡œ êµ¬ì„±
            table_json_columns = {}
            table_json_columns[item_name] = {}
            
            for col_name, amount_info in amounts.items():
                if amount_info['normalized_value'] is not None:
                    # ì›ë³¸ display ê°’ì„ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ normalized_value ì‚¬ìš©
                    display_value = amount_info.get('display', str(amount_info['normalized_value']))
                    table_json_columns[item_name][col_name] = display_value
            
            # ì²­í¬ ë‚´ìš© ìƒì„±
            content_parts = [f"{item_name}:"]
            
            for col_name, amount_info in amounts.items():
                if amount_info['value'] is not None:
                    content_parts.append(f"{col_name} {amount_info['display']}")
            
            content = " ".join(content_parts)
            
            # ë‹¨ìœ„ ì •ë³´ ì¶”ê°€
            if unit:
                content += f" (ë‹¨ìœ„: {unit})"
            
            # ì£¼ì„ ì •ë³´ ì¶”ê°€
            note_info = f"ì£¼ì„ {table_metadata.get('note_number', '?')}. {table_metadata.get('note_title', '')}"
            if note_info.strip() != "ì£¼ì„ ?.":
                content = f"{note_info} - {content}"
            
            # ë©”íƒ€ë°ì´í„° ê°„ì†Œí™” (RAGì— í•„ìš”í•œ ì •ë³´ë§Œ)
            chunk_metadata = {
                'note_number': table_metadata.get('note_number'),
                'note_title': table_metadata.get('note_title'),
                'table_number': table_metadata.get('table_number'),
                'financial_item': item_name,
                'financial_category': financial_category,
                'unit': table_metadata.get('unit'),
                'report_year': doc_metadata.get('report_year'),
                'company': doc_metadata.get('company')
            }
            
            chunk = {
                "id": self.generate_chunk_id(content),
                "content": content,
                "content_type": "financial_data",
                "metadata": chunk_metadata,
                "table_json": table_json_columns  # ì—´ ê¸°ì¤€ JSON êµ¬ì¡° (ì¤‘ë³µ ì œê±°)
            }
            
            chunks.append(chunk)
        
        return chunks

    def generate_rag_chunks(self):
        """RAG/ë²¡í„°DBì— ì í•©í•œ ê°œë³„ ì²­í¬ ìƒì„± (ê¸°ì¡´ ë°©ì‹ - í˜¸í™˜ì„± ìœ ì§€)"""
        rag_chunks = []
        
        for note_chunk in self.parsed_chunks:
            note_number = note_chunk["note_number"]
            note_title = note_chunk["title"]
            content = note_chunk["content"]
            
            # 1. ë…¸íŠ¸ ì½˜í…ì¸  ì²­í¬ (ê¸°ì¡´ ë°©ì‹)
            content_chunk = {
                "id": self.generate_chunk_id(f"note_{note_number}_{content}"),
                "content": f"ì£¼ì„ {note_number}. {note_title}\n\n{content}",
                "content_type": "note_content",
                "metadata": {
                    **note_chunk["metadata"],
                    "note_number": note_number,
                    "note_title": note_title,
                    "chunk_source": "note_content"
                }
            }
            rag_chunks.append(content_chunk)
            
            # 2. ê°œì„ ëœ í…Œì´ë¸” ì²­í¬ë“¤ ì¶”ê°€
            enhanced_tables = note_chunk["tables"].get("enhanced_data", [])
            for table_data in enhanced_tables:
                # í…Œì´ë¸” ìš”ì•½ ì²­í¬
                if table_data.get("summary_chunk"):
                    rag_chunks.append(table_data["summary_chunk"])
                
                # ì¬ë¬´ ë°ì´í„° ì²­í¬ë“¤
                if table_data.get("data_chunks"):
                    rag_chunks.extend(table_data["data_chunks"])
        
        return rag_chunks

    def generate_rag_optimized_chunks(self):
        """RAG/ë²¡í„°DBì— ìµœì í™”ëœ ì²­í¬ ìƒì„± (ì•„ì¹´ì´ë¸Œ í˜•ì‹)"""
        rag_chunks = []
        
        # 1. ì¬ë¬´ì œí‘œ ì²­í¬ë“¤ ë¨¼ì € ì¶”ê°€
        for statement in self.financial_statements:
            statement_chunk = self._create_financial_statement_chunk(statement)
            rag_chunks.append(statement_chunk)
        
        # 2. ì£¼ì„ ì²­í¬ë“¤ ì¶”ê°€
        for note_chunk in self.parsed_chunks:
            note_number = note_chunk["note_number"]
            note_title = note_chunk["title"]
            content = note_chunk["content"]
            base_metadata = note_chunk["metadata"]
            
            # ì£¼ì„ë³„ë¡œ í•˜ë‚˜ì˜ ì™„ì „í•œ ì²­í¬ ìƒì„± (ì•„ì¹´ì´ë¸Œ í˜•ì‹)
            company = base_metadata.get('company', 'Unknown')
            year = base_metadata.get('report_year')
            
            # í…Œì´ë¸” ë°ì´í„° í†µí•©
            integrated_tables = {}
            enhanced_tables = note_chunk["tables"].get("enhanced_data", [])
            
            for table_data in enhanced_tables:
                table_number = table_data.get("table_number")
                if table_number:
                    # í…Œì´ë¸” ë°ì´í„°ë¥¼ í–‰ ê¸°ì¤€ìœ¼ë¡œ í†µí•©
                    table_dict = {}
                    data_chunks = table_data.get("data_chunks", [])
                    
                    for data_chunk in data_chunks:
                        table_json = data_chunk.get("table_json", {})
                        for item_name, row_data in table_json.items():
                            if item_name not in table_dict:
                                table_dict[item_name] = {}
                            table_dict[item_name].update(row_data)
                    
                    if table_dict:
                        # í…Œì´ë¸” ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ê°œì„ 
                        summary_metadata = table_data.get("summary_chunk", {}).get("metadata", {})
                        
                        # title ì¶”ì¶œ (ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ì‹œë„)
                        table_title = None
                        if summary_metadata.get("table_title"):
                            table_title = summary_metadata["table_title"]
                        else:
                            # data_chunksì—ì„œ title ì°¾ê¸°
                            for data_chunk in data_chunks:
                                chunk_meta = data_chunk.get("metadata", {})
                                if chunk_meta.get("table_title"):
                                    table_title = chunk_meta["table_title"]
                                    break
                        
                        # unit ì¶”ì¶œ (ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ì‹œë„)
                        table_unit = None
                        if summary_metadata.get("unit"):
                            table_unit = summary_metadata["unit"]
                        else:
                            # data_chunksì—ì„œ unit ì°¾ê¸°
                            for data_chunk in data_chunks:
                                chunk_meta = data_chunk.get("metadata", {})
                                if chunk_meta.get("unit"):
                                    table_unit = chunk_meta["unit"]
                                    break
                        
                        integrated_tables[f"table_{table_number}"] = {
                            "table_number": table_number,
                            "title": table_title,
                            "unit": table_unit,
                            "data": table_dict
                        }
            
            # í…ìŠ¤íŠ¸ ì •ë¦¬ ì ìš©
            cleaned_content = self.clean_text(content)
            
            # ì•„ì¹´ì´ë¸Œ í˜•ì‹ ì²­í¬ ìƒì„±
            chunk = {
                "doc_id": self.generate_doc_id(company, year, note_number),
                "company": company,
                "report_year": year,
                "note_number": note_number,
                "note_title": note_title,
                "content_type": "note_complete",
                "text_content": cleaned_content,
                "tables": integrated_tables,
                "table_count": len(integrated_tables),
                "metadata": {
                    "content_length": len(cleaned_content),
                    "table_count": len(integrated_tables),
                    "has_tables": len(integrated_tables) > 0
                }
            }
            
            rag_chunks.append(chunk)
        
        return rag_chunks
    
    def _create_financial_statement_chunk(self, statement):
        """ì¬ë¬´ì œí‘œ ì²­í¬ ìƒì„± (ì£¼ì„ê³¼ ë™ì¼í•œ êµ¬ì¡°)"""
        statement_type = statement["statement_type"]
        tables = statement["tables"]
        
        # í…Œì´ë¸” ë°ì´í„° í†µí•© (ì£¼ì„ê³¼ ì™„ì „íˆ ë™ì¼í•œ ë°©ì‹)
        integrated_tables = {}
        statement_text_parts = [f"{statement_type} ì£¼ìš” ì¬ë¬´ ì •ë³´"]
        
        for table_data in tables:
            table_number = table_data["table_number"]
            matrix = table_data["matrix"]
            metadata = table_data["metadata"]
            
            # ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜ (ë…¸íŠ¸ë¶ ì½”ë“œ ê¸°ë°˜ ê°œì„ )
            table_dict = {}
            if len(matrix) > 1:  # ì¬ë¬´ì œí‘œ ë°ì´í„° í…Œì´ë¸”
                # ë…¸íŠ¸ë¶ ì½”ë“œì˜ build_header ë¡œì§ í™œìš©
                cols, header_rows_count, body_rows = self.build_header(matrix, max_header_rows=4)
                
                print(f"         ğŸ“‹ í—¤ë”: {cols[:4]} (í—¤ë” í–‰ìˆ˜: {header_rows_count})")
                print(f"         ğŸ“Š ë°ì´í„° í–‰ìˆ˜: {len(body_rows)}")
                
                # ë°ì´í„° í–‰ ì²˜ë¦¬
                for row_idx, row in enumerate(body_rows):
                    if row and len(row) > 0 and row[0] and str(row[0]).strip():
                        item_name = self.clean_text(str(row[0]))
                        
                        # ì¬ë¬´ì œí‘œ í•­ëª©ì¸ì§€ í™•ì¸ (ë” ë„“ì€ ë²”ìœ„)
                        if (len(item_name) > 1 and 
                            (re.search(r'[â… -â…«]', item_name) or  # ë¡œë§ˆìˆ«ì
                             re.search(r'[ê°€-í£]', item_name) or   # í•œê¸€ í¬í•¨
                             re.search(r'\d+\.', item_name))):    # ìˆ«ì. í˜•íƒœ
                            
                            table_dict[item_name] = {}
                            
                            # ê° ì»¬ëŸ¼ì˜ ê°’ ì¶”ì¶œ
                            for col_idx, value in enumerate(row):
                                if col_idx > 0 and col_idx < len(cols):  # ì²« ë²ˆì§¸ ì»¬ëŸ¼(í•­ëª©ëª…) ì œì™¸
                                    col_name = cols[col_idx]
                                    
                                    if value and str(value).strip():
                                        clean_value = str(value).strip()
                                        # ì˜ë¯¸ìˆëŠ” ê°’ì¸ì§€ í™•ì¸ (ìˆ«ìë‚˜ í…ìŠ¤íŠ¸)
                                        if (clean_value not in ['', '-', 'â€•', 'â€”'] and 
                                            (re.search(r'\d', clean_value) or len(clean_value) > 1)):
                                            
                                            # ê°™ì€ ì»¬ëŸ¼ëª…ì´ ìˆìœ¼ë©´ ê°’ í†µí•© (ê³µë°±ìœ¼ë¡œ ì—°ê²°)
                                            if col_name in table_dict[item_name]:
                                                existing_value = table_dict[item_name][col_name]
                                                if existing_value != clean_value:  # ë‹¤ë¥¸ ê°’ì´ë©´ í†µí•©
                                                    table_dict[item_name][col_name] = f"{existing_value} {clean_value}".strip()
                                            else:
                                                table_dict[item_name][col_name] = clean_value
                            
                            # ë¹ˆ ë°ì´í„°ë©´ ì œê±°
                            if not table_dict[item_name]:
                                del table_dict[item_name]
                
                print(f"         ğŸ“Š ì¶”ì¶œëœ í•­ëª© ìˆ˜: {len(table_dict)}")
            
            if table_dict:
                integrated_tables[f"table_{table_number}"] = {
                    "table_number": table_number,
                    "title": metadata.get('table_title', statement_type),
                    "unit": metadata.get('unit'),
                    "data": table_dict
                }
                
                # ì£¼ìš” í•­ëª©ë“¤ì„ í…ìŠ¤íŠ¸ì— ì¶”ê°€
                main_items = list(table_dict.keys())[:5]  # ì²˜ìŒ 5ê°œ í•­ëª©
                if main_items:
                    statement_text_parts.append(f"ì£¼ìš” í•­ëª©: {', '.join(main_items)}")
        
        # ì¬ë¬´ì œí‘œ ì²­í¬ ìƒì„± (ì£¼ì„ê³¼ ë™ì¼í•œ êµ¬ì¡°)
        company = "ì‚¼ì„±ì „ìì£¼ì‹íšŒì‚¬"
        year = self.file_year or 2014
        
        text_content = ". ".join(statement_text_parts)
        
        # ì£¼ì„ êµ¬ì¡°ì™€ ì™„ì „íˆ ë™ì¼í•˜ê²Œ ìƒì„±
        chunk = {
            "doc_id": self.generate_doc_id(company, year, f"fs_{statement_type.lower()}"),
            "company": company,
            "report_year": year,
            "note_number": f"FS_{statement_type}",
            "note_title": statement_type,
            "content_type": "note_complete",  # ì£¼ì„ê³¼ ë™ì¼í•˜ê²Œ
            "text_content": text_content,
            "tables": integrated_tables if integrated_tables else {},  # ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ
            "table_count": len(integrated_tables),
            "metadata": {
                "content_length": len(text_content),
                "table_count": len(integrated_tables),
                "has_tables": len(integrated_tables) > 0
            }
        }
        
        return chunk

    def save_results(self, input_file_path, output_dir="/Users/dan/Desktop/snu_project/data/processed/universal_audit_parser_fixed"):
        """ê²°ê³¼ë¥¼ ì§€ì •ëœ ê²½ë¡œì— ì €ì¥"""
        os.makedirs(output_dir, exist_ok=True)
        
        # ì…ë ¥ íŒŒì¼ëª…ì—ì„œ ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
        base_name = os.path.splitext(os.path.basename(input_file_path))[0]
        output_file = os.path.join(output_dir, f"{base_name}_parsed.json")
        
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(self.parsed_chunks, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # RAG ì²­í¬ë„ ì €ì¥ (ê¸°ì¡´ ë°©ì‹)
        rag_chunks = self.generate_rag_chunks()
        rag_output_dir = "/Users/dan/Desktop/snu_project/data/processed/rag_chunks_fixed"
        os.makedirs(rag_output_dir, exist_ok=True)
        rag_output_file = os.path.join(rag_output_dir, f"{base_name}_rag_chunks.json")
        
        with open(rag_output_file, "w", encoding="utf-8") as f:
            json.dump(rag_chunks, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ RAG ì²­í¬ê°€ {rag_output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # RAG ìµœì í™” ì²­í¬ë„ ì €ì¥ (ìƒˆë¡œìš´ í˜•ì‹)
        rag_optimized_chunks = self.generate_rag_optimized_chunks()
        rag_optimized_output_dir = "/Users/dan/Desktop/snu_project/data/processed/rag_chunks_optimized"
        os.makedirs(rag_optimized_output_dir, exist_ok=True)
        rag_optimized_output_file = os.path.join(rag_optimized_output_dir, f"{base_name}_rag_optimized.json")
        
        with open(rag_optimized_output_file, "w", encoding="utf-8") as f:
            json.dump(rag_optimized_chunks, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ RAG ìµœì í™” ì²­í¬ê°€ {rag_optimized_output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return output_file, rag_output_file, rag_optimized_output_file

    def print_summary(self):
        print("\n" + "="*80)
        print("ğŸ“Š íŒŒì‹± ê²°ê³¼ ìš”ì•½")
        print("="*80)
        print(f"íŒŒì¼ ì—°ë„: {self.file_year}ë…„")
        print(f"íŒŒì¼ í˜•ì‹: {self.file_format}")
        print(f"ì´ ì¬ë¬´ì œí‘œ ê°œìˆ˜: {len(self.financial_statements)}ê°œ")
        print(f"ì´ ì£¼ì„ ê°œìˆ˜: {len(self.parsed_chunks)}ê°œ")
        
        # ì¬ë¬´ì œí‘œ ìš”ì•½
        if self.financial_statements:
            print("\nğŸ“‹ ë°œê²¬ëœ ì¬ë¬´ì œí‘œ:")
            for stmt in self.financial_statements:
                print(f"   - {stmt['statement_type']}: {stmt['table_count']}ê°œ í…Œì´ë¸”")
        
        print("\nğŸ“ ì£¼ì„ ìƒì„¸ ì •ë³´:")
        
        total_tables = 0
        total_enhanced_chunks = 0
        for chunk in self.parsed_chunks:
            table_count = chunk['tables']['count']
            enhanced_data = chunk['tables'].get('enhanced_data', [])
            enhanced_chunks = sum(len(t.get('data_chunks', [])) + (1 if t.get('summary_chunk') else 0) for t in enhanced_data)
            
            total_tables += table_count
            total_enhanced_chunks += enhanced_chunks
            
            print(f"\nì£¼ì„ {chunk['note_number']:2s}: {chunk['title']}")
            preview = chunk["content"][:100].replace("\\n", " ")
            print(f"   ğŸ“„ ë‚´ìš©: {preview}...")
            print(f"   ğŸ“Š ê¸¸ì´: {chunk['content_length']}ì")
            print(f"   ğŸ“‹ í…Œì´ë¸”: {table_count}ê°œ")
            print(f"   ğŸ” ê°œì„ ëœ ì²­í¬: {enhanced_chunks}ê°œ")
        
        print(f"\nì´ í…Œì´ë¸”: {total_tables}ê°œ")
        print(f"ì´ ê°œì„ ëœ ì²­í¬: {total_enhanced_chunks}ê°œ")
        
        found_numbers = {int(c["note_number"]) for c in self.parsed_chunks if c["note_number"].isdigit()}
        expected_numbers = set(range(1, 36))
        missing = sorted(list(expected_numbers - found_numbers))
        if missing:
            print(f"\nâŒ ëˆ„ë½ëœ ì£¼ì„: {missing}")
        else:
            print(f"\nâœ… 1~35ë²ˆ ì£¼ì„ ëª¨ë‘ ì™„ë²½í•˜ê²Œ íŒŒì‹±ë¨!")

def main():
    parser = UniversalAuditParser()
    
    # ì…ë ¥ íŒŒì¼ ì°¾ê¸°
    input_files = parser.find_input_files()
    
    if not input_files:
        print("âŒ ì²˜ë¦¬í•  ê°ì‚¬ë³´ê³ ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê° íŒŒì¼ ì²˜ë¦¬
    for file_path in input_files:
        try:
            print(f"\n{'='*100}")
            print(f"ğŸ”„ ì²˜ë¦¬ ì¤‘: {file_path}")
            print(f"{'='*100}")
            
            chunks = parser.parse_file(file_path)
            output_files = parser.save_results(file_path)
            parser.print_summary()
            
            print(f"\nâœ… {file_path} ì²˜ë¦¬ ì™„ë£Œ!")
            if isinstance(output_files, tuple):
                print(f"ğŸ“ ê¸°ë³¸ íŒŒì‹± ê²°ê³¼: {output_files[0]}")
                print(f"ğŸ“ RAG ì²­í¬ (ê¸°ì¡´): {output_files[1]}")
                print(f"ğŸ“ RAG ìµœì í™” ì²­í¬: {output_files[2]}")
            else:
                print(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {output_files}")
            
        except Exception as e:
            print(f"âŒ {file_path} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            continue

if __name__ == "__main__":
    main()
