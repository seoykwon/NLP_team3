#!/usr/bin/env python3
"""
Streamlitì„ ì‚¬ìš©í•œ RAG QA ì›¹ ì¸í„°í˜ì´ìŠ¤
"""

import streamlit as st
import os
import sys
from pathlib import Path
import logging
from typing import Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.append(str(project_root / "scripts"))

from hierarchy_rag_qa_system import HierarchyRAGQASystem

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_openai_api_key() -> str:
    """OpenAI API í‚¤ ë¡œë“œ"""
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        return api_key
    
    # .env íŒŒì¼ì—ì„œ API í‚¤ í™•ì¸
    try:
        from dotenv import load_dotenv
        load_dotenv()
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            return api_key
    except ImportError:
        pass
    
    return None

def initialize_rag_system() -> HierarchyRAGQASystem:
    """ê³„ì¸µê´€ê³„ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    if 'rag_system' not in st.session_state:
        api_key = load_openai_api_key()
        if not api_key:
            st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ .env íŒŒì¼ì— ì¶”ê°€í•˜ì„¸ìš”.")
            st.stop()
        
        try:
            with st.spinner("ê³„ì¸µê´€ê³„ RAG QA ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘..."):
                rag_system = HierarchyRAGQASystem(openai_api_key=api_key)
                st.session_state.rag_system = rag_system
                st.success("ê³„ì¸µê´€ê³„ RAG QA ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        except Exception as e:
            st.error(f"RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            st.stop()
    
    return st.session_state.rag_system

def display_chat_message(role: str, content: str, relevant_chunks: list = None):
    """ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ"""
    with st.chat_message(role):
        st.markdown(content)
        
        if relevant_chunks and role == "assistant":
            with st.expander("ì°¸ì¡°ëœ ë¬¸ì„œ ì •ë³´"):
                for i, chunk in enumerate(relevant_chunks[:3], 1):
                    st.markdown(f"**ì²­í¬ {i}** (ìœ ì‚¬ë„: {chunk['score']:.3f})")
                    st.markdown(f"- ë‚´ìš©: {chunk['text'][:200]}...")
                    
                    metadata = chunk.get('metadata', {})
                    if metadata:
                        metadata_info = []
                        if metadata.get('company'):
                            metadata_info.append(f"íšŒì‚¬: {metadata['company']}")
                        if metadata.get('report_year'):
                            metadata_info.append(f"ì—°ë„: {metadata['report_year']}")
                        if metadata.get('account_name'):
                            metadata_info.append(f"ê³„ì •: {metadata['account_name']}")
                        if metadata.get('value'):
                            metadata_info.append(f"ê¸ˆì•¡: {metadata['value']:,}ë°±ë§Œì›")
                        
                        if metadata_info:
                            st.markdown(f"- ë©”íƒ€ë°ì´í„°: {', '.join(metadata_info)}")
                    st.markdown("---")

def main():
    """ë©”ì¸ Streamlit ì•±"""
    st.set_page_config(
        page_title="ì‚¼ì„±ì „ì ê°ì‚¬ë³´ê³ ì„œ RAG QA",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ì»¤ìŠ¤í…€ CSS
    st.markdown("""
    <style>
    .main-header {
        background: linear-gradient(90deg, #1f4e79 0%, #2e7d32 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #2e7d32;
        margin: 0.5rem 0;
    }
    .chunk-card {
        background: #e8f5e8;
        padding: 0.8rem;
        border-radius: 6px;
        margin: 0.5rem 0;
        border-left: 3px solid #4caf50;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # í—¤ë”
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“Š ì‚¼ì„±ì „ì ê°ì‚¬ë³´ê³ ì„œ ê³„ì¸µê´€ê³„ RAG QA ì‹œìŠ¤í…œ</h1>
        <p>GPT-4 ê¸°ë°˜ ì§€ëŠ¥í˜• ì¬ë¬´ ë°ì´í„° ë¶„ì„ í”Œë«í¼ (ìƒí•˜ìœ„ ê³„ì¸µê´€ê³„ ì§€ì›)</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ê²€ìƒ‰ ì„¤ì •")
        
        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„°
        top_k = st.slider("ê²€ìƒ‰í•  ì²­í¬ ìˆ˜", min_value=3, max_value=10, value=5)
        score_threshold = st.slider("ìœ ì‚¬ë„ ì„ê³„ê°’", min_value=0.0, max_value=1.0, value=0.7, step=0.1)
        
        st.markdown("---")
        
        # ìƒ˜í”Œ ì§ˆë¬¸ë“¤
        st.header("ğŸ’¡ ìƒ˜í”Œ ì§ˆë¬¸")
        sample_questions = [
            "ìœ ë™ìì‚°ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
            "í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°ì€ ì–¼ë§ˆì¸ê°€ìš”?",
            "2024ë…„ ì¬ë¬´ìƒíƒœí‘œ ìƒ ë‹¹ê¸° ìœ ë™ìì‚°ì€ ì–¼ë§ˆì¸ê°€?",
            "2019ë…„ ì¬ë¬´ìƒíƒœí‘œìƒ ì¢…ì†ê¸°ì—…, ê´€ê³„ê¸°ì—… ë° ê³µë™ê¸°ì—… íˆ¬ìëŠ” ì–¼ë§ˆì¸ê°€ìš”?",
            "2024ë…„ ì†ìµê³„ì‚°ì„œìƒ ë‹¹ê¸° ë²•ì¸ì„¸ë¹„ìš©ì€ ì–¼ë§ˆì•¼?",
            "2023ë…„ì˜ ë²•ì¸ì„¸ë¹„ìš©(ìˆ˜ìµ)ì€ ì–¼ë§ˆì•¼?",
            "2021ë…„ ì¬ë¬´ìƒíƒœí‘œì—ì„œ ë‹¹ê¸° ìœ ë™ë¹„ìœ¨ì„ ê³„ì‚°í•˜ë©´ ì–¼ë§ˆì¸ê°€ìš”?"
        ]
        
        for i, question in enumerate(sample_questions, 1):
            if st.button(f"{i}. {question[:30]}...", key=f"sample_{i}"):
                st.session_state.sample_question = question
                st.rerun()
        
        st.markdown("---")
        
        # ì‹œìŠ¤í…œ ì •ë³´
        st.header("â„¹ï¸ ì‹œìŠ¤í…œ ì •ë³´")
        st.markdown("""
        <div class="metric-card">
        <strong>ğŸ¤– AI ëª¨ë¸</strong><br>
        â€¢ ì„ë² ë”©: BGE-M3-KO<br>
        â€¢ LLM: ChatGPT-4<br>
        â€¢ ë²¡í„°DB: Qdrant
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div class="metric-card">
        <strong>ğŸ“Š ë°ì´í„° ë²”ìœ„</strong><br>
        â€¢ íšŒì‚¬: ì‚¼ì„±ì „ì<br>
        â€¢ ê¸°ê°„: 2014-2024ë…„<br>
        â€¢ ë¬¸ì„œ: ê°ì‚¬ë³´ê³ ì„œ
        </div>
        """, unsafe_allow_html=True)
        
        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”„ ì‹œìŠ¤í…œ ì¬ì´ˆê¸°í™”", type="secondary"):
            if 'rag_system' in st.session_state:
                del st.session_state.rag_system
            st.rerun()
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    rag_system = initialize_rag_system()
    
    # ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # í™˜ì˜ ë©”ì‹œì§€
    if not st.session_state.messages:
        st.session_state.messages.append({
            "role": "assistant", 
            "content": "ì•ˆë…•í•˜ì„¸ìš”! ì‚¼ì„±ì „ì ê°ì‚¬ë³´ê³ ì„œì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ì§ˆë¬¸í•´ì£¼ì„¸ìš”.\n\n**ê³„ì¸µê´€ê³„ ì§€ì›**: ìƒí•˜ìœ„ ê³„ì¸µê´€ê³„ê°€ ìˆëŠ” ê³¼ëª©ë“¤ì„ í•¨ê»˜ ë‹µë³€ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤!\n\nì˜ˆë¥¼ ë“¤ì–´:\n- ìœ ë™ìì‚°ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš” (í•˜ìœ„ í•­ëª©ë“¤ë„ í•¨ê»˜ í‘œì‹œ)\n- í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°ì€ ì–¼ë§ˆì¸ê°€ìš”?\n- 2017ë…„ ì‚¼ì„±ì „ìì˜ ìœ ë™ìì‚°ì€ ì–¼ë§ˆì¸ê°€ìš”?\n- 2020ë…„ ë§¤ì¶œì±„ê¶Œì˜ ë³€í™”ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n- ìµœê·¼ 3ë…„ê°„ í˜„ê¸ˆíë¦„ì€ ì–´ë–¤ ì¶”ì„¸ì¸ê°€ìš”?"
        })
    
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.messages:
        display_chat_message(
            message["role"], 
            message["content"],
            message.get("relevant_chunks")
        )
    
    # ìƒ˜í”Œ ì§ˆë¬¸ ì²˜ë¦¬
    if hasattr(st.session_state, 'sample_question'):
        prompt = st.session_state.sample_question
        del st.session_state.sample_question
    else:
        prompt = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
    
    if prompt:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        display_chat_message("user", prompt)
        
        # ë‹µë³€ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                try:
                    result = rag_system.ask_question(
                        prompt, 
                        top_k=top_k, 
                        score_threshold=score_threshold
                    )
                    
                    # ë‹µë³€ í‘œì‹œ
                    st.markdown(result["answer"])
                    
                    # ê³„ì¸µê´€ê³„ ì •ë³´ í‘œì‹œ
                    if result.get("hierarchy_info"):
                        with st.expander("ğŸ—ï¸ ê³„ì¸µê´€ê³„ ì •ë³´", expanded=False):
                            st.markdown(result["hierarchy_info"])
                    
                    # ê´€ë ¨ ì²­í¬ í‘œì‹œ
                    if result["relevant_chunks"]:
                        with st.expander(f"ğŸ“š ì°¸ì¡°ëœ ë¬¸ì„œ ì •ë³´ ({len(result['relevant_chunks'])}ê°œ)", expanded=False):
                            for i, chunk in enumerate(result["relevant_chunks"], 1):
                                # ìœ ì‚¬ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ê²°ì •
                                score = chunk['score']
                                if score >= 0.8:
                                    color = "#4caf50"  # ë…¹ìƒ‰
                                elif score >= 0.7:
                                    color = "#ff9800"  # ì£¼í™©ìƒ‰
                                else:
                                    color = "#f44336"  # ë¹¨ê°„ìƒ‰
                                
                                st.markdown(f"""
                                <div class="chunk-card">
                                    <strong>ğŸ“„ ì²­í¬ {i}</strong> 
                                    <span style="color: {color}; font-weight: bold;">(ìœ ì‚¬ë„: {score:.3f})</span><br>
                                    <em>{chunk['text'][:150]}...</em>
                                </div>
                                """, unsafe_allow_html=True)
                                
                                metadata = chunk.get('metadata', {})
                                if metadata:
                                    metadata_info = []
                                    if metadata.get('doc_id'):
                                        metadata_info.append(f"ğŸ“‹ ë¬¸ì„œ: {metadata['doc_id']}")
                                    if metadata.get('content_type'):
                                        metadata_info.append(f"ğŸ“Š ìœ í˜•: {metadata['content_type']}")
                                    
                                    if metadata_info:
                                        st.markdown(f"<small>{' | '.join(metadata_info)}</small>", unsafe_allow_html=True)
                                st.markdown("")
                    
                    # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶”ê°€
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": result["answer"],
                        "relevant_chunks": result["relevant_chunks"],
                        "hierarchy_info": result.get("hierarchy_info", "")
                    })
                    
                except Exception as e:
                    error_msg = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": error_msg
                    })
    
    # í•˜ë‹¨ ì •ë³´
    st.markdown("---")
    
    # í†µê³„ ì •ë³´
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ’¬ ì´ ëŒ€í™” ìˆ˜", len(st.session_state.messages))
    
    with col2:
        st.metric("ğŸ” ê²€ìƒ‰ ì²­í¬ ìˆ˜", top_k)
    
    with col3:
        st.metric("ğŸ“Š ìœ ì‚¬ë„ ì„ê³„ê°’", f"{score_threshold:.1f}")
    
    with col4:
        st.metric("ğŸ“… ë°ì´í„° ê¸°ê°„", "2014-2024")
    
    # íŒê³¼ ê°€ì´ë“œ
    st.markdown("---")
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### ğŸ’¡ ì§ˆë¬¸ íŒ
        - **ê³„ì¸µê´€ê³„ í™œìš©**: "ìœ ë™ìì‚°ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”" (í•˜ìœ„ í•­ëª©ë“¤ë„ í•¨ê»˜ í‘œì‹œ)
        - **êµ¬ì²´ì ì¸ ì§ˆë¬¸**: "2023ë…„ ìœ ë™ìì‚°" vs "ìì‚°"
        - **ì—°ë„ ëª…ì‹œ**: "2019ë…„ ì†ìµê³„ì‚°ì„œìƒ..."
        - **ì •í™•í•œ í•­ëª©ëª…**: "ë²•ì¸ì„¸ë¹„ìš©", "ë§¤ì¶œì±„ê¶Œ" ë“±
        """)
    
    with col2:
        st.markdown("""
        ### ğŸ” ê²€ìƒ‰ ìµœì í™”
        - **ë†’ì€ ìœ ì‚¬ë„**: ë” ì •í™•í•œ ë‹µë³€
        - **ë” ë§ì€ ì²­í¬**: ë” í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸
        - **ìƒ˜í”Œ ì§ˆë¬¸**: ë¹ ë¥¸ ì‹œì‘ì„ ìœ„í•´ í™œìš©
        """)

if __name__ == "__main__":
    main()
