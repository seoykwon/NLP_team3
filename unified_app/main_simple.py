#!/usr/bin/env python3
"""
í†µí•© RAG QA ì‹œìŠ¤í…œ - ê°„ë‹¨ ë²„ì „
ê¸°ì¤€ì„œ, ìƒë²•, ê°ì‚¬ë³´ê³ ì„œ RAG ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ
"""

import streamlit as st
import os
import sys
from pathlib import Path
import logging
from typing import Optional
import pandas as pd
import re

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì • (ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
project_root = Path("/Users/kwonseoyoung/Desktop/comb")
sys.path.append(str(project_root))
sys.path.append(str(project_root / "audit" / "scripts"))
sys.path.append(str(project_root / "extra" / "ìŠ¤íŠ¸ë¦¼ë¦¿"))
sys.path.append(str(project_root / "graph" / "code"))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="í†µí•© RAG QA ì‹œìŠ¤í…œ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# CSS ìŠ¤íƒ€ì¼ - ë³´ë¼ìƒ‰-í•‘í¬ìƒ‰-í°ìƒ‰ í…Œë§ˆ
st.markdown("""
<style>
    /* ì „ì²´ ì•± ìŠ¤íƒ€ì¼ - ì• ë‹ˆë©”ì´ì…˜ ë°°ê²½ */
    .stApp {
        background: linear-gradient(135deg, #f8f5ff 0%, #ffe8f7 30%, #f0e6ff 60%, #ffffff 100%);
        background-size: 400% 400%;
        animation: gradientShift 10s ease infinite;
        color: #000000 !important;
        min-height: 100vh;
    }
    
    @keyframes gradientShift {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }
    
    /* ëª¨ë“  í…ìŠ¤íŠ¸ ê²€ì •ìƒ‰ */
    * {
        color: #000000 !important;
    }
    
    /* ë©”ì¸ í—¤ë” - ê¸€ë¡œìš° íš¨ê³¼ì™€ ì• ë‹ˆë©”ì´ì…˜ */
    .main-title {
        background: linear-gradient(135deg, #9c27b0 0%, #e91e63 30%, #f48fb1 70%, #f8bbd9 100%);
        background-size: 300% 300%;
        animation: headerGlow 8s ease-in-out infinite;
        color: white !important;
        padding: 2.8rem;
        border-radius: 25px;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 12px 45px rgba(156, 39, 176, 0.4), 
                    inset 0 1px 0 rgba(255, 255, 255, 0.3);
        border: 2px solid rgba(255, 255, 255, 0.3);
        backdrop-filter: blur(15px);
        position: relative;
        overflow: hidden;
    }
    
    .main-title::before {
        content: '';
        position: absolute;
        top: -50%;
        left: -50%;
        width: 200%;
        height: 200%;
        background: linear-gradient(45deg, transparent, rgba(255, 255, 255, 0.15), transparent);
        animation: shimmer 4s infinite;
        pointer-events: none;
    }
    
    @keyframes headerGlow {
        0%, 100% { 
            background-position: 0% 50%;
            box-shadow: 0 12px 45px rgba(156, 39, 176, 0.4), 
                        inset 0 1px 0 rgba(255, 255, 255, 0.3);
        }
        50% { 
            background-position: 100% 50%;
            box-shadow: 0 18px 55px rgba(233, 30, 99, 0.5), 
                        inset 0 1px 0 rgba(255, 255, 255, 0.4);
        }
    }
    
    @keyframes shimmer {
        0% { transform: translateX(-100%) translateY(-100%) rotate(45deg); }
        100% { transform: translateX(100%) translateY(100%) rotate(45deg); }
    }
    
    .main-title h1, .main-title p {
        color: white !important;
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
    }
    
    /* ì‹œìŠ¤í…œ ì„ íƒ ë²„íŠ¼ */
    .system-buttons {
        display: flex;
        justify-content: center;
        gap: 1.5rem;
        margin: 2rem 0;
        flex-wrap: wrap;
    }
    
    .system-btn {
        background: linear-gradient(135deg, #ffffff 0%, #fdf2f8 100%);
        border: 2px solid #e91e63;
        color: #000000 !important;
        padding: 1.2rem 2.5rem;
        border-radius: 15px;
        cursor: pointer;
        transition: all 0.3s ease;
        font-weight: bold;
        text-decoration: none;
        display: inline-block;
        box-shadow: 0 4px 15px rgba(233, 30, 99, 0.2);
    }
    
    .system-btn:hover {
        background: linear-gradient(135deg, #e91e63 0%, #9c27b0 100%);
        color: white !important;
        transform: translateY(-3px);
        box-shadow: 0 8px 25px rgba(156, 39, 176, 0.4);
        text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
    }
    
    .system-btn.active {
        background: linear-gradient(135deg, #9c27b0 0%, #e91e63 100%);
        color: white !important;
        text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
        box-shadow: 0 6px 20px rgba(156, 39, 176, 0.3);
    }
    
    /* ìƒ˜í”Œ ì§ˆë¬¸ ë°•ìŠ¤ */
    .sample-questions {
        background: linear-gradient(135deg, #ffffff 0%, #fdf2f8 50%, #f8f5ff 100%);
        padding: 2rem;
        border-radius: 18px;
        margin: 1.5rem 0;
        box-shadow: 0 6px 25px rgba(156, 39, 176, 0.2),
                    inset 0 1px 0 rgba(255, 255, 255, 0.8);
        border-left: 6px solid #e91e63;
        border-top: 2px solid #f8bbd9;
        position: relative;
        overflow: hidden;
        transition: all 0.3s ease;
    }
    
    .sample-questions:hover {
        transform: translateY(-3px);
        box-shadow: 0 10px 35px rgba(156, 39, 176, 0.25),
                    inset 0 1px 0 rgba(255, 255, 255, 0.9);
    }
    
    .sample-question-btn {
        background: linear-gradient(135deg, #ffffff 0%, #fdf2f8 100%);
        border: 2px solid rgba(233, 30, 99, 0.3);
        color: #000000 !important;
        padding: 0.7rem 1.2rem;
        margin: 0.4rem;
        border-radius: 10px;
        cursor: pointer;
        display: inline-block;
        transition: all 0.3s ease;
        font-size: 0.9rem;
        box-shadow: 0 2px 8px rgba(156, 39, 176, 0.1);
    }
    
    .sample-question-btn:hover {
        background: linear-gradient(135deg, #f8bbd9 0%, #fce4ec 100%);
        border-color: #e91e63;
        transform: translateY(-2px);
        box-shadow: 0 4px 15px rgba(156, 39, 176, 0.2);
    }
    
    /* ì±„íŒ… ì˜ì—­ */
    .chat-container {
        background: linear-gradient(135deg, #ffffff 0%, #fdf2f8 50%, #f8f5ff 100%);
        border-radius: 20px;
        padding: 2.5rem;
        margin: 1.5rem 0;
        box-shadow: 0 8px 30px rgba(156, 39, 176, 0.2),
                    inset 0 1px 0 rgba(255, 255, 255, 0.8);
        min-height: 500px;
        border: 2px solid rgba(233, 30, 99, 0.3);
        transition: all 0.3s ease;
        position: relative;
        overflow: hidden;
    }
    
    .chat-container:hover {
        box-shadow: 0 12px 40px rgba(156, 39, 176, 0.25),
                    inset 0 1px 0 rgba(255, 255, 255, 0.9);
        border-color: rgba(233, 30, 99, 0.4);
    }
    
    /* ë‹µë³€ ë°•ìŠ¤ */
    .answer-box {
        background: linear-gradient(135deg, #f3e5f5 0%, #fce4ec 100%);
        border-left: 6px solid #9c27b0;
        border-top: 2px solid #e91e63;
        padding: 1.5rem;
        margin: 1.5rem 0;
        border-radius: 12px;
        color: #000000 !important;
        box-shadow: 0 4px 15px rgba(156, 39, 176, 0.1);
    }
    
    /* ì—ëŸ¬ ë°•ìŠ¤ */
    .error-box {
        background: linear-gradient(135deg, #ffeaea 0%, #fff0f0 100%);
        border-left: 6px solid #f44336;
        border-top: 2px solid #ff6b6b;
        padding: 1.5rem;
        margin: 1.5rem 0;
        border-radius: 12px;
        color: #000000 !important;
        box-shadow: 0 4px 15px rgba(244, 67, 54, 0.15);
    }
    
    /* Streamlit ìš”ì†Œë“¤ ìŠ¤íƒ€ì¼ ì˜¤ë²„ë¼ì´ë“œ */
    .stChatMessage {
        color: #000000 !important;
        background: rgba(248, 245, 255, 0.8);
        border: 1px solid rgba(233, 30, 99, 0.2);
        border-radius: 12px;
    }
    
    .stButton > button {
        background: linear-gradient(90deg, #9c27b0 0%, #e91e63 50%, #f8bbd9 100%);
        color: white !important;
        border: none;
        border-radius: 10px;
        padding: 0.7rem 1.2rem;
        font-weight: bold;
        box-shadow: 0 4px 15px rgba(156, 39, 176, 0.3);
        text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
        transition: all 0.3s ease;
    }
    
    .stButton > button:hover {
        background: linear-gradient(90deg, #8e24aa 0%, #d81b60 50%, #f48fb1 100%);
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(156, 39, 176, 0.4);
    }
    
    .stTextInput > div > div > input {
        color: #000000 !important;
        background: rgba(255, 255, 255, 0.9) !important;
        border: 2px solid rgba(233, 30, 99, 0.3);
        border-radius: 8px;
    }
    
    .stTextInput > div > div > input:focus {
        border-color: #e91e63;
        box-shadow: 0 0 10px rgba(233, 30, 99, 0.3);
    }
    
    .stSelectbox > div > div > select {
        color: #000000 !important;
        background: rgba(255, 255, 255, 0.9) !important;
        border: 2px solid rgba(233, 30, 99, 0.3);
        border-radius: 8px;
    }
    
    .stTextArea > div > div > textarea {
        color: #000000 !important;
        background: rgba(255, 255, 255, 0.9) !important;
        border: 2px solid rgba(233, 30, 99, 0.3);
        border-radius: 8px;
    }
    
    .stTextArea > div > div > textarea:focus {
        border-color: #e91e63;
        box-shadow: 0 0 10px rgba(233, 30, 99, 0.3);
    }
    
    /* ìŠ¤í”¼ë„ˆ */
    .stSpinner > div {
        border-color: #e91e63 transparent transparent transparent;
    }
    
    /* í”„ë¡œê·¸ë˜ìŠ¤ ë°” */
    .stProgress > div > div {
        background-color: #e91e63;
    }
</style>
""", unsafe_allow_html=True)

def load_openai_api_key() -> Optional[str]:
    """OpenAI API í‚¤ ë¡œë“œ"""
    # .env íŒŒì¼ ë¨¼ì € ë¡œë“œ
    try:
        from dotenv import load_dotenv
        load_dotenv()
    except ImportError:
        pass
    
    api_key = os.getenv("OPENAI_API_KEY")
    return api_key

def get_sample_questions(system_type):
    """ì‹œìŠ¤í…œë³„ ìƒ˜í”Œ ì§ˆë¬¸ ë°˜í™˜"""
    samples = {
        "audit": [
            "ì‚¼ì„±ì „ìì˜ ë§¤ì¶œì•¡ ë³€í™” ì¶”ì´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
            "2016ë…„ë¶€í„° 2023ë…„ê¹Œì§€ ì˜ì—…ì´ìµì˜ ì—°ë„ë³„ ë³€í™” ì¶”ì´ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”", 
            "ìœ ë™ìì‚°ì˜ ìµœê·¼ ëª‡ ë…„ê°„ ì¦ê° í˜„í™©ì„ ì—°ë„ë³„ë¡œ ì•Œë ¤ì£¼ì„¸ìš”"
        ],
        "legal": [
            "ì¤€ë¹„ê¸ˆì˜ ìë³¸ì „ì…ì€ ì´ì‚¬íšŒì—ì„œ ê²°ì •í•  ìˆ˜ ìˆëŠ”ê°€?",
            "ìƒë²•ìƒ ì´ì‚¬ì˜ ì˜ë¬´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "ì£¼ì‹íšŒì‚¬ì˜ ì„¤ë¦½ ì ˆì°¨ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"
        ],
        "kifrs": [
            "ê°œë°œë¹„ ìì‚° ì¸ì‹ ìš”ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ë¦¬ìŠ¤ íšŒê³„ì²˜ë¦¬ ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "ê¸ˆìœµìì‚°ì˜ ë¶„ë¥˜ ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?"
        ]
    }
    return samples.get(system_type, [])

def extract_years_from_question(question: str):
    """ì§ˆë¬¸ì—ì„œ ì—°ë„ë“¤ì„ ì¶”ì¶œ"""
    years = re.findall(r"(20\d{2}|19\d{2})", question)
    return [int(year) for year in years] if years else []

def format_amount(value):
    """ê¸ˆì•¡ì„ ì²œ ë‹¨ìœ„ ì½¤ë§ˆë¡œ í¬ë§·"""
    if value is None:
        return "N/A"
    try:
        if value < 0:
            return f"({abs(value):,})"
        return f"{value:,}"
    except:
        return str(value)

def should_show_chart(question: str, answer: str):
    """ì°¨íŠ¸ë¥¼ í‘œì‹œí•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨"""
    # ì—°ë„ë³„, ì¶”ì´, ë³€í™” ë“±ì˜ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì°¨íŠ¸ í‘œì‹œ
    chart_keywords = ["ì—°ë„ë³„", "ì¶”ì´", "ë³€í™”", "ì¦ê°", "ë¹„êµ", "ë…„ë¶€í„°", "ê¹Œì§€"]
    years = extract_years_from_question(question)
    
    # ì—¬ëŸ¬ ì—°ë„ê°€ ì–¸ê¸‰ë˜ê±°ë‚˜ ì°¨íŠ¸ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì°¨íŠ¸ í‘œì‹œ
    return len(years) > 1 or any(keyword in question for keyword in chart_keywords)

def extract_financial_data_from_answer(answer: str):
    """ë‹µë³€ì—ì„œ ì¬ë¬´ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ ì°¨íŠ¸ìš© ë°ì´í„°ë¡œ ë³€í™˜"""
    try:
        data = {}
        
        # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ ì—°ë„ì™€ ê¸ˆì•¡ì„ ì¶”ì¶œ
        patterns = [
            # "2024ë…„: 82,320,322ë°±ë§Œì›" ë˜ëŠ” "- 2024ë…„: 82,320,322ë°±ë§Œì›"
            r"(?:^|\s|-)\s*(20\d{2})ë…„?\s*:?\s*([0-9,]+)(?:ë°±ë§Œì›|ì›)?",
            # "2024ë…„ 82,320,322ë°±ë§Œì›"
            r"(20\d{2})ë…„?\s+([0-9,]+)(?:ë°±ë§Œì›|ì›)?",
            # "2024: 82,320,322"
            r"(20\d{2})\s*:\s*([0-9,]+)",
            # í‘œ í˜•íƒœ: "2024    82,320,322"
            r"(20\d{2})\s+([0-9,]+)(?:\s|$)",
            # ê´„í˜¸ ì•ˆì˜ ìŒìˆ˜: "2024ë…„: (1,234,567)ë°±ë§Œì›"
            r"(?:^|\s|-)\s*(20\d{2})ë…„?\s*:?\s*\(([0-9,]+)\)(?:ë°±ë§Œì›|ì›)?",
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, answer, re.MULTILINE | re.IGNORECASE)
            for year_str, amount_str in matches:
                try:
                    year = int(year_str)
                    # 2014-2024 ë²”ìœ„ ë‚´ì˜ ì—°ë„ë§Œ ì²˜ë¦¬
                    if 2014 <= year <= 2024:
                        # ì½¤ë§ˆ ì œê±°í•˜ê³  ìˆ«ìë¡œ ë³€í™˜
                        amount = int(amount_str.replace(",", ""))
                        # ê´„í˜¸ íŒ¨í„´ì€ ìŒìˆ˜ë¡œ ì²˜ë¦¬
                        if "()" in pattern:
                            amount = -amount
                        data[year] = amount
                except (ValueError, IndexError):
                    continue
        
        # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸
        logger.info(f"ì¶”ì¶œëœ ì¬ë¬´ ë°ì´í„°: {data}")
        
        # ìµœì†Œ 2ê°œ ì—°ë„ ì´ìƒì˜ ë°ì´í„°ê°€ ìˆì–´ì•¼ ì°¨íŠ¸ í‘œì‹œ
        return data if len(data) >= 2 else None
        
    except Exception as e:
        logger.error(f"Financial data extraction error: {e}")
        return None

def enhance_question_for_comprehensive_data(question: str) -> str:
    """ì§ˆë¬¸ì„ ë” í¬ê´„ì ì¸ ë°ì´í„° ê²€ìƒ‰ì„ ìœ„í•´ ê°œì„ """
    # ì—°ë„ë³„ ë°ì´í„° ìš”ì²­ì´ë©´ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§Œë“¤ê¸°
    if any(keyword in question for keyword in ["ì—°ë„ë³„", "ì¶”ì´", "ëª¨ë“  ì—°ë„", "í‘œë¡œ"]):
        enhanced = f"{question} ì‚¼ì„±ì „ì ì—°ê²°ì¬ë¬´ì œí‘œ ê¸°ì¤€ìœ¼ë¡œ 2014ë…„, 2015ë…„, 2016ë…„, 2017ë…„, 2018ë…„, 2019ë…„, 2020ë…„, 2021ë…„, 2022ë…„, 2023ë…„, 2024ë…„ ê° ì—°ë„ë³„ ë°ì´í„°ë¥¼ ëª¨ë‘ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."
        return enhanced
    return question

def extract_sales_data_from_json(question: str) -> str:
    """JSON íŒŒì¼ì—ì„œ ì§ì ‘ ë§¤ì¶œì•¡ ë°ì´í„° ì¶”ì¶œ"""
    try:
        import json
        
        sales_data = {}
        processed_dir = project_root / "audit" / "data" / "processed"
        
        # 2014ë…„ë¶€í„° 2024ë…„ê¹Œì§€ ë°ì´í„° ìˆ˜ì§‘
        for year in range(2014, 2025):
            json_file = processed_dir / f"ê°ì‚¬ë³´ê³ ì„œ_{year}_rag_optimized.json"
            if json_file.exists():
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # ì†ìµê³„ì‚°ì„œì—ì„œ ë§¤ì¶œì•¡ ì°¾ê¸°
                    for item in data:
                        if (item.get('note_title') == 'ì†ìµê³„ì‚°ì„œ' and 
                            'tables' in item):
                            
                            for table_key, table in item['tables'].items():
                                if ('data' in table and 
                                    'â… . ë§¤ì¶œì•¡' in table['data']):
                                    
                                    sales_info = table['data']['â… . ë§¤ì¶œì•¡']
                                    
                                    # ë‹¹ê¸° ë°ì´í„° ì°¾ê¸°
                                    for key, value in sales_info.items():
                                        if 'ë‹¹' in key and value != '':
                                            # ì½¤ë§ˆ ì œê±°í•˜ê³  ìˆ«ìë¡œ ë³€í™˜
                                            clean_value = value.replace(',', '')
                                            if clean_value.isdigit():
                                                sales_data[year] = int(clean_value)
                                                break
                                    break
                            if year in sales_data:
                                break
                                
                except Exception as e:
                    logger.error(f"Error reading {year} data: {e}")
                    continue
        
        if len(sales_data) >= 5:  # 5ê°œ ì´ìƒ ì—°ë„ ë°ì´í„°ê°€ ìˆìœ¼ë©´
            # ë‹µë³€ ìƒì„±
            answer = "## ì‚¼ì„±ì „ì ì—°ë„ë³„ ë§¤ì¶œì•¡ ë¶„ì„\n\n"
            answer += "### ğŸ“Š ì—°ë„ë³„ ë§¤ì¶œì•¡ (ë‹¨ìœ„: ë°±ë§Œì›)\n\n"
            
            years = sorted(sales_data.keys())
            for year in years:
                formatted_amount = f"{sales_data[year]:,}"
                answer += f"- **{year}ë…„**: {formatted_amount}ë°±ë§Œì›\n"
            
            answer += f"\n### ğŸ“ˆ ì£¼ìš” ë¶„ì„\n"
            answer += f"- **ìµœê³  ë§¤ì¶œì•¡**: {max(years)}ë…„ {sales_data[max(years, key=sales_data.get)]:,}ë°±ë§Œì›\n"
            answer += f"- **ìµœì € ë§¤ì¶œì•¡**: {min(years)}ë…„ {sales_data[min(years, key=sales_data.get)]:,}ë°±ë§Œì›\n"
            answer += f"- **ë°ì´í„° ê¸°ê°„**: {min(years)}ë…„ ~ {max(years)}ë…„ ({len(sales_data)}ê°œ ì—°ë„)\n"
            
            # ì°¨íŠ¸ ë°ì´í„°ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            if should_show_chart(question, answer):
                st.session_state.chart_data = {
                    "years": [str(year) for year in years],
                    "values": [sales_data[year] for year in years],
                    "question": question
                }
            
            return answer
            
    except Exception as e:
        logger.error(f"JSON ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None
    
    return None

def process_audit_question(question: str, api_key: str):
    """ê°ì‚¬ë³´ê³ ì„œ RAG ì²˜ë¦¬ - ê¸°ì¡´ audit í´ë”ì˜ JSON ë°ì´í„° ì§ì ‘ í™œìš©"""
    try:
        # ë¨¼ì € ê¸°ì¡´ Qdrant RAG ì‹œìŠ¤í…œ ì‹œë„
        audit_scripts_path = project_root / "audit" / "scripts"
        audit_scripts_abs = str(audit_scripts_path.absolute())
        if audit_scripts_abs not in sys.path:
            sys.path.insert(0, audit_scripts_abs)
        
        from hierarchy_rag_qa_system import HierarchyRAGQASystem
        
        if 'audit_rag_system' not in st.session_state:
            with st.spinner("ê°ì‚¬ë³´ê³ ì„œ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘..."):
                st.session_state.audit_rag_system = HierarchyRAGQASystem(openai_api_key=api_key)
        
        # ì§ˆë¬¸ì„ ë” í¬ê´„ì ìœ¼ë¡œ ê°œì„ 
        enhanced_question = enhance_question_for_comprehensive_data(question)
        logger.info(f"ì›ë³¸ ì§ˆë¬¸: {question}")
        logger.info(f"ê°œì„ ëœ ì§ˆë¬¸: {enhanced_question}")
        
        # ë¨¼ì € JSON ë°ì´í„°ì—ì„œ ì§ì ‘ ë§¤ì¶œì•¡ ë°ì´í„° ì¶”ì¶œ ì‹œë„
        if any(keyword in question.lower() for keyword in ["ë§¤ì¶œì•¡", "ë§¤ì¶œ", "sales", "revenue"]):
            direct_answer = extract_sales_data_from_json(question)
            if direct_answer:
                return direct_answer
        
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            # Qdrant RAG ì‹œìŠ¤í…œìœ¼ë¡œ ë‹µë³€ ìƒì„±
            result = st.session_state.audit_rag_system.ask_question(enhanced_question, top_k=50, score_threshold=0.1)
            answer = result.get("answer", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # Qdrant ì—°ê²° ì˜¤ë¥˜ ì²´í¬
            if "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in answer:
                return "âš ï¸ ê°ì‚¬ë³´ê³ ì„œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. Qdrant ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            
            # ì°¨íŠ¸ í‘œì‹œ ì—¬ë¶€ íŒë‹¨ ë° ì²˜ë¦¬
            chart_displayed = False
            if should_show_chart(question, answer):
                financial_data = extract_financial_data_from_answer(answer)
                
                if financial_data:
                    # ë‹µë³€ì— ì°¨íŠ¸ ì •ë³´ ì¶”ê°€
                    answer += "\n\nğŸ“Š **ë°ì´í„° ì‹œê°í™”**\n"
                    
                    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
                    years = sorted(financial_data.keys())
                    values = [financial_data[year] for year in years]
                    
                    df = pd.DataFrame({
                        "ì—°ë„": [str(year) for year in years],
                        "ê¸ˆì•¡": [format_amount(v) for v in values],
                        "ë‹¨ìœ„": ["ë°±ë§Œì›"] * len(years)
                    })
                    
                    # ë°ì´í„° í…Œì´ë¸”ì„ í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€
                    answer += "\n**ğŸ“‹ ë°ì´í„° í…Œì´ë¸”:**\n"
                    for _, row in df.iterrows():
                        answer += f"- {row['ì—°ë„']}ë…„: {row['ê¸ˆì•¡']} {row['ë‹¨ìœ„']}\n"
                    
                    # ë°ì´í„° ì œí•œ ì‚¬í•­ ì•ˆë‚´
                    if len(values) < 10:  # ì „ì²´ ì—°ë„(2014-2024)ë³´ë‹¤ ì ìœ¼ë©´
                        answer += f"\nâš ï¸ **ë°ì´í„° ì œí•œ**: í˜„ì¬ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ {len(values)}ê°œ ì—°ë„ì˜ ë°ì´í„°ë§Œ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤. "
                        answer += "ì „ì²´ ê¸°ê°„(2014-2024)ì˜ ë°ì´í„°ê°€ í•„ìš”í•œ ê²½ìš°, ì›ë³¸ ê°ì‚¬ë³´ê³ ì„œë¥¼ ì§ì ‘ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
                    
                    # ì°¨íŠ¸ëŠ” ë³„ë„ë¡œ í‘œì‹œí•  ê²ƒì„ í‘œì‹œ
                    answer += "\nğŸ’¡ *ì•„ë˜ì—ì„œ ì‹œê°í™” ì°¨íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.*"
                    
                    # ì„¸ì…˜ ìƒíƒœì— ì°¨íŠ¸ ë°ì´í„° ì €ì¥
                    st.session_state.chart_data = {
                        "years": [str(year) for year in years],
                        "values": values,
                        "question": question
                    }
                    chart_displayed = True
            
            return answer
    
    except Exception as e:
        logger.error(f"Audit RAG error: {e}")
        return f"ê°ì‚¬ë³´ê³ ì„œ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {str(e)}"

def process_legal_question(question: str, api_key: str):
    """ìƒë²• RAG ì²˜ë¦¬"""
    try:
        # ìƒë²• ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if 'legal_rag_system' not in st.session_state:
            st.session_state.legal_rag_system = create_legal_rag_system(api_key)
        
        with st.spinner("ìƒë²• ë‹µë³€ ìƒì„± ì¤‘..."):
            answer, results = st.session_state.legal_rag_system.search_and_answer(question, topk=5)
            return answer
    
    except Exception as e:
        logger.error(f"Legal RAG error: {e}")
        return f"ìƒë²• ì‹œìŠ¤í…œ ì˜¤ë¥˜: {str(e)}"

def create_legal_rag_system(api_key: str):
    """ìƒë²• RAG ì‹œìŠ¤í…œ ìƒì„±"""
    import json
    import numpy as np
    import faiss
    import re
    from sentence_transformers import SentenceTransformer
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import linear_kernel
    from openai import OpenAI
    
    class SimpleCommercialLawRAG:
        def __init__(self):
            # ìƒë²• ë°ì´í„° ê²½ë¡œ (extra í´ë” ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì •)
            self.base_path = project_root / "extra" / "ìƒë²• 2"
            self.index_path = self.base_path / "kcc_index_json" / "kcc.index"
            self.ids_path = self.base_path / "kcc_index_json" / "ids.npy"
            self.metas_path = self.base_path / "kcc_index_json" / "metas.json"
            self.model_name = "intfloat/multilingual-e5-base"
            
            self.openai_client = OpenAI(api_key=api_key)
            self.index = None
            self.ids = None
            self.metas = None
            self.model = None
            self.tfidf = None
            self.X_tfidf = None
            
            self.load_resources()
        
        def load_resources(self):
            """ë¦¬ì†ŒìŠ¤ ë¡œë“œ"""
            try:
                # íŒŒì¼ ì¡´ì¬ í™•ì¸
                if not all([self.index_path.exists(), self.ids_path.exists(), self.metas_path.exists()]):
                    raise FileNotFoundError("ìƒë²• ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                # ì¸ë±ìŠ¤/ë©”íƒ€ ë¡œë“œ
                self.index = faiss.read_index(str(self.index_path))
                self.ids = np.load(self.ids_path, allow_pickle=True).tolist()
                with open(self.metas_path, "r", encoding="utf-8") as f:
                    self.metas = json.load(f)
                
                # ëª¨ë¸ ë¡œë“œ
                self.model = SentenceTransformer(self.model_name)
                
                # TF-IDF ì¸ë±ìŠ¤ êµ¬ì¶•
                self._build_tfidf()
                
            except Exception as e:
                raise Exception(f"ìƒë²• ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        
        def _build_tfidf(self):
            """TF-IDF ì¸ë±ìŠ¤ êµ¬ì¶•"""
            texts = []
            for m in self.metas:
                alias = " ".join(m.get("aliases", []))
                raw = m.get("raw_text", "")
                texts.append((alias + " " + raw).strip())
            
            self.tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=1, max_df=0.95)
            self.X_tfidf = self.tfidf.fit_transform(texts)
        
        def normalize_query(self, q: str):
            """ì§ˆì˜ ì •ê·œí™”"""
            qn = q.strip()
            # ì¡°ë¬¸ ë²ˆí˜¸ ì •ê·œí™”
            m = re.search(r"(\d+)\s*ì˜\s*(\d+)", qn)
            if m:
                qn += f" {m.group(1)}-{m.group(2)} ì œ{m.group(1)}ì¡°ì˜{m.group(2)}"
            return qn
        
        def search_and_answer(self, query: str, topk: int = 5):
            """ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±"""
            if not all([self.index, self.model, self.tfidf]):
                return "ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", []
            
            # ì§ˆì˜ ì •ê·œí™” ë° ì„ë² ë”©
            qn = self.normalize_query(query)
            qv = self.model.encode([qn], convert_to_numpy=True, normalize_embeddings=True)
            
            # FAISS ê²€ìƒ‰
            D, I = self.index.search(qv, topk*3)
            I, D = I[0], D[0]
            
            # TF-IDF ê²€ìƒ‰
            qv_t = self.tfidf.transform([qn])
            S_t = linear_kernel(qv_t, self.X_tfidf).ravel()
            
            # í•˜ì´ë¸Œë¦¬ë“œ ê²°í•©
            results = []
            seen = set()
            
            # ì„ë² ë”© ê²°ê³¼ ì¶”ê°€
            for i, score in zip(I, D):
                if i >= 0 and i not in seen:
                    m = self.metas[int(i)]
                    results.append({
                        "id": self.ids[int(i)],
                        "article_id": m.get("article_id"),
                        "title": m.get("title"),
                        "content": m.get("raw_text", ""),
                        "score": float(score)
                    })
                    seen.add(i)
            
            # TF-IDF ìƒìœ„ ê²°ê³¼ ë³´ì™„
            tfidf_top = S_t.argsort()[::-1][:topk]
            for i in tfidf_top:
                if i not in seen and len(results) < topk:
                    m = self.metas[i]
                    results.append({
                        "id": self.ids[i],
                        "article_id": m.get("article_id"),
                        "title": m.get("title"),
                        "content": m.get("raw_text", ""),
                        "score": float(S_t[i])
                    })
                    seen.add(i)
            
            # ìƒìœ„ ê²°ê³¼ë§Œ ì„ íƒ
            results = results[:topk]
            
            # GPT ë‹µë³€ ìƒì„±
            answer = self._generate_answer(query, results)
            
            return answer, results
        
        def _generate_answer(self, query, results):
            """GPT ë‹µë³€ ìƒì„±"""
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_parts = []
            for r in results:
                article_id = str(r["article_id"])
                header = f"ìƒë²• ì œ{article_id}ì¡°"
                if "ì˜" in article_id:
                    header = f"ìƒë²• ì œ{article_id.replace('ì˜', 'ì¡°ì˜')}"
                
                title = r.get("title", "")
                if title:
                    header += f"({title})"
                
                content = r.get("content", "")[:500]  # ê¸¸ì´ ì œí•œ
                context_parts.append(f"### {header}\n{content}")
            
            context = "\n\n".join(context_parts)
            
            system_msg = (
                "ë„ˆëŠ” í•œêµ­ ìƒë²• ì „ë¬¸ê°€ì•¼. ì œê³µëœ ì¡°ë¬¸ë“¤ì„ ê·¼ê±°ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´. "
                "ë‹µë³€ ëì— ì°¸ì¡°í•œ ì¡°ë¬¸ ë²ˆí˜¸ë¥¼ ëª…ì‹œí•´."
            )
            
            user_msg = f"ì§ˆë¬¸: {query}\n\nê·¼ê±° ì¡°ë¬¸:\n{context}"
            
            try:
                resp = self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    temperature=0.2,
                    messages=[
                        {"role": "system", "content": system_msg},
                        {"role": "user", "content": user_msg}
                    ]
                )
                return resp.choices[0].message.content.strip()
            except Exception as e:
                return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
    
    return SimpleCommercialLawRAG()

def process_kifrs_question(question: str, api_key: str):
    """K-IFRS RAG ì²˜ë¦¬"""
    try:
        # K-IFRS ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if 'kifrs_rag_system' not in st.session_state:
            st.session_state.kifrs_rag_system = create_kifrs_rag_system(api_key)
        
        with st.spinner("K-IFRS ë‹µë³€ ìƒì„± ì¤‘..."):
            answer, results = st.session_state.kifrs_rag_system.search_and_answer(question, topk=5)
            return answer
    
    except Exception as e:
        logger.error(f"K-IFRS RAG error: {e}")
        return f"K-IFRS ì‹œìŠ¤í…œ ì˜¤ë¥˜: {str(e)}"

def create_kifrs_rag_system(api_key: str):
    """K-IFRS RAG ì‹œìŠ¤í…œ ìƒì„±"""
    import json
    import numpy as np
    from sentence_transformers import SentenceTransformer
    from openai import OpenAI
    
    class SimpleKIFRSRAG:
        def __init__(self):
            # K-IFRS ë°ì´í„° ê²½ë¡œ
            self.base_path = project_root / "extra" / "ê¸°ì¤€ì„œ 2"
            self.json_path = self.base_path / "ê¸°ì¤€ì„œ íŒŒì‹±.json"
            self.cache_dir = self.base_path / "hf_cache"
            self.para_emb_path = self.cache_dir / "para_emb_intfloat_multilingual-e5-large.npy"
            self.model_name = "intfloat/multilingual-e5-large"
            
            self.openai_client = OpenAI(api_key=api_key)
            self.docs = []
            self.paragraphs = []
            self.para_vecs = None
            self.model = None
            
            self.load_resources()
        
        def load_resources(self):
            """ë¦¬ì†ŒìŠ¤ ë¡œë“œ"""
            try:
                # JSON ë°ì´í„° ë¡œë“œ
                if not self.json_path.exists():
                    raise FileNotFoundError("K-IFRS ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                with self.json_path.open(encoding='utf-8') as f:
                    data = json.load(f)
                
                self.docs = data.get('documents', [])
                
                # ë¬¸ë‹¨ ë°ì´í„° êµ¬ì„±
                for d in self.docs:
                    std = d.get('standard_no')
                    title = d.get('title', '')
                    for p in d.get('paragraphs', []):
                        self.paragraphs.append({
                            "std": std,
                            "title": title,
                            "para_id": p.get('para_id'),
                            "text": p.get('text', ''),
                            "page": p.get('page')
                        })
                
                # ì„ë² ë”© ë¡œë“œ (ìˆëŠ” ê²½ìš°)
                if self.para_emb_path.exists():
                    self.para_vecs = np.load(self.para_emb_path)
                
                # ëª¨ë¸ ë¡œë“œ
                self.model = SentenceTransformer(self.model_name)
                
            except Exception as e:
                raise Exception(f"K-IFRS ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        
        def search_and_answer(self, query: str, topk: int = 5):
            """ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±"""
            try:
                if self.para_vecs is not None:
                    # ë²¡í„° ê²€ìƒ‰ ì‚¬ìš©
                    query_emb = self.model.encode([f"query: {query}"], normalize_embeddings=True)[0]
                    similarities = np.dot(self.para_vecs, query_emb)
                    top_indices = np.argpartition(similarities, -topk*3)[-topk*3:]
                    top_indices = top_indices[np.argsort(similarities[top_indices])[::-1][:topk]]
                else:
                    # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ (ì„ë² ë”© íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°)
                    query_emb = self.model.encode([query], normalize_embeddings=True)[0]
                    similarities = []
                    for para in self.paragraphs:
                        para_emb = self.model.encode([para["text"]], normalize_embeddings=True)[0]
                        sim = np.dot(query_emb, para_emb)
                        similarities.append(sim)
                    
                    similarities = np.array(similarities)
                    top_indices = similarities.argsort()[::-1][:topk]
                
                results = []
                for idx in top_indices:
                    para = self.paragraphs[idx]
                    results.append({
                        "std": para["std"],
                        "title": para["title"],
                        "para_id": para["para_id"],
                        "text": para["text"],
                        "page": para.get("page"),
                        "score": float(similarities[idx]) if isinstance(similarities, np.ndarray) else 0.0
                    })
                
                # GPT ë‹µë³€ ìƒì„±
                answer = self._generate_answer(query, results)
                
                return answer, results
            
            except Exception as e:
                return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", []
        
        def _generate_answer(self, query, results):
            """GPT ë‹µë³€ ìƒì„±"""
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_parts = []
            for r in results:
                header = f"[{r['std']}:{r['para_id']}] {r['title']} (p.{r.get('page', '?')})"
                text = r['text'][:500]  # ê¸¸ì´ ì œí•œ
                context_parts.append(f"{header}\n{text}")
            
            context = "\n\n".join(context_parts)
            
            system_msg = (
                "ë„ˆëŠ” K-IFRS íšŒê³„ê¸°ì¤€ ì „ë¬¸ê°€ì•¼. ì œê³µëœ ë¬¸ë‹¨ë“¤ì„ ê·¼ê±°ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´. "
                "ë‹µë³€ ëì— ì°¸ì¡°í•œ ê¸°ì¤€ì„œ ë²ˆí˜¸ë¥¼ ëª…ì‹œí•´."
            )
            
            user_msg = f"ì§ˆë¬¸: {query}\n\nê·¼ê±° ë¬¸ë‹¨:\n{context}"
            
            try:
                resp = self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    temperature=0.2,
                    messages=[
                        {"role": "system", "content": system_msg},
                        {"role": "user", "content": user_msg}
                    ]
                )
                return resp.choices[0].message.content.strip()
            except Exception as e:
                return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
    
    return SimpleKIFRSRAG()

def main():
    # ë©”ì¸ í—¤ë”
    st.markdown("""
    <div class="main-title">
        <h1>ğŸ¤– í†µí•© RAG QA ì‹œìŠ¤í…œ</h1>
        <p>ê°ì‚¬ë³´ê³ ì„œ, ìƒë²•, K-IFRS ê¸°ì¤€ì„œ ì§€ëŠ¥í˜• ì§ˆì˜ì‘ë‹µ</p>
    </div>
    """, unsafe_allow_html=True)
    
    # API í‚¤ í™•ì¸
    api_key = load_openai_api_key()
    if not api_key:
        st.error("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'selected_system' not in st.session_state:
        st.session_state.selected_system = 'audit'
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    # ì‹œìŠ¤í…œ ì„ íƒ ë²„íŠ¼
    st.markdown("### ğŸ“š ì‹œìŠ¤í…œ ì„ íƒ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“Š ê°ì‚¬ë³´ê³ ì„œ", use_container_width=True, type="primary" if st.session_state.selected_system == 'audit' else "secondary"):
            st.session_state.selected_system = 'audit'
            st.session_state.messages = []  # ì‹œìŠ¤í…œ ë³€ê²½ ì‹œ ì±„íŒ… ì´ˆê¸°í™”
            st.rerun()
    
    with col2:
        if st.button("âš–ï¸ ìƒë²•", use_container_width=True, type="primary" if st.session_state.selected_system == 'legal' else "secondary"):
            st.session_state.selected_system = 'legal'
            st.session_state.messages = []
            st.rerun()
    
    with col3:
        if st.button("ğŸ“‹ K-IFRS ê¸°ì¤€ì„œ", use_container_width=True, type="primary" if st.session_state.selected_system == 'kifrs' else "secondary"):
            st.session_state.selected_system = 'kifrs'
            st.session_state.messages = []
            st.rerun()
    
    # í˜„ì¬ ì„ íƒëœ ì‹œìŠ¤í…œ í‘œì‹œ
    system_names = {
        'audit': 'ğŸ“Š ê°ì‚¬ë³´ê³ ì„œ',
        'legal': 'âš–ï¸ ìƒë²•',
        'kifrs': 'ğŸ“‹ K-IFRS ê¸°ì¤€ì„œ'
    }
    
    st.markdown(f"**í˜„ì¬ ì„ íƒëœ ì‹œìŠ¤í…œ**: {system_names[st.session_state.selected_system]}")
    
    # ìƒ˜í”Œ ì§ˆë¬¸ í‘œì‹œ
    st.markdown("### ğŸ’¡ ìƒ˜í”Œ ì§ˆë¬¸")
    sample_questions = get_sample_questions(st.session_state.selected_system)
    
    cols = st.columns(3)
    for i, question in enumerate(sample_questions):
        with cols[i]:
            if st.button(f"Q{i+1}: {question[:20]}...", key=f"sample_{i}", help=question, use_container_width=True):
                # ìƒ˜í”Œ ì§ˆë¬¸ì„ ì±„íŒ…ì— ì¶”ê°€
                st.session_state.messages.append({"role": "user", "content": question})
                
                # ë‹µë³€ ìƒì„±
                if st.session_state.selected_system == 'audit':
                    answer = process_audit_question(question, api_key)
                elif st.session_state.selected_system == 'legal':
                    answer = process_legal_question(question, api_key)
                else:  # kifrs
                    answer = process_kifrs_question(question, api_key)
                
                st.session_state.messages.append({"role": "assistant", "content": answer})
                st.rerun()
    
    # ì±„íŒ… ì˜ì—­
    st.markdown("### ğŸ’¬ ì±„íŒ…")
    
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    chat_container = st.container()
    with chat_container:
        for i, message in enumerate(st.session_state.messages):
            if message["role"] == "user":
                with st.chat_message("user"):
                    st.markdown(f"**ì§ˆë¬¸**: {message['content']}")
            else:
                with st.chat_message("assistant"):
                    st.markdown(f"""
                    <div class="answer-box">
                        {message['content']}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # ê°ì‚¬ë³´ê³ ì„œ ë‹µë³€ì´ê³  ì°¨íŠ¸ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì°¨íŠ¸ í‘œì‹œ
                    if (st.session_state.selected_system == 'audit' and 
                        hasattr(st.session_state, 'chart_data') and 
                        st.session_state.chart_data and
                        i == len(st.session_state.messages) - 1):  # ìµœì‹  ë©”ì‹œì§€ì¸ ê²½ìš°ë§Œ
                        
                        chart_data = st.session_state.chart_data
                        
                        # ë¼ì¸ ì°¨íŠ¸ í‘œì‹œ
                        if len(chart_data['values']) > 1:
                            chart_df = pd.DataFrame({
                                "ì—°ë„": chart_data['years'],
                                "ê¸ˆì•¡(ë°±ë§Œì›)": chart_data['values']
                            })
                            st.line_chart(chart_df.set_index("ì—°ë„"))
                        
                        # ë°ì´í„° í…Œì´ë¸” í‘œì‹œ
                        df_display = pd.DataFrame({
                            "ì—°ë„": chart_data['years'],
                            "ê¸ˆì•¡": [format_amount(v) for v in chart_data['values']],
                            "ë‹¨ìœ„": ["ë°±ë§Œì›"] * len(chart_data['years'])
                        })
                        st.dataframe(df_display, use_container_width=True, hide_index=True)
    
    # ì±„íŒ… ì…ë ¥
    user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
    
    if user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        # ë‹µë³€ ìƒì„±
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            if st.session_state.selected_system == 'audit':
                answer = process_audit_question(user_input, api_key)
            elif st.session_state.selected_system == 'legal':
                answer = process_legal_question(user_input, api_key)
            else:  # kifrs
                answer = process_kifrs_question(user_input, api_key)
        
        # ë‹µë³€ ì¶”ê°€
        st.session_state.messages.append({"role": "assistant", "content": answer})
        st.rerun()
    
    # í•˜ë‹¨ ì •ë³´
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 1rem;">
        <p><strong>ğŸ¤– í†µí•© RAG QA ì‹œìŠ¤í…œ</strong> | ê°ì‚¬ë³´ê³ ì„œ, ìƒë²•, K-IFRS ê¸°ì¤€ì„œ í†µí•© ê²€ìƒ‰</p>
        <p>ğŸ’¡ ì •í™•í•œ ì •ë³´ëŠ” ì›ë³¸ ë¬¸ì„œë¥¼ í™•ì¸í•˜ì„¸ìš”</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
