{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69559d3",
   "metadata": {},
   "source": [
    "\n",
    "# K-IFRS RAG — HF v2 (Cached-only QA)\n",
    "\n",
    "**요청대로: 벡터 재생성 없이, 이미 저장된 임베딩 `.npy`만 사용**해 QA를 수행하는 버전입니다.  \n",
    "- 타이틀/문단 임베딩은 `/mnt/data/hf_cache/*.npy`에서 **로드만** 합니다.  \n",
    "- 캐시가 없으면 **오류를 던지고 중단**합니다(실수로 재생성되지 않도록).  \n",
    "- 쿼리 임베딩만 모델로 생성(필수)하며, 문서 임베딩은 절대 재계산하지 않습니다.\n",
    "\n",
    "내장 기능: **BM25 + 벡터 하이브리드**, **Two-Track 라우팅**, **Vector-only Fallback**, **Alias 확장**  \n",
    "(재랭커는 선택: 필요시 주석 해제)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c22cb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON exists: True /Users/igangsan/Desktop/기준서/kifrs_combined_2_cleaned_v2_final4.json\n",
      "Cache dir exists: True /Users/igangsan/Desktop/기준서/hf_cache_3\n",
      "Title emb exists: True\n",
      "Para emb exists : True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import json, math, numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List\n",
    "\n",
    "# ===== 경로 =====\n",
    "BASE = Path('/Users/igangsan/Desktop/기준서')  # 필요시 수정\n",
    "JSON_PATH = BASE / 'kifrs_combined_2_cleaned_v2_final4.json'\n",
    "CACHE_DIR = BASE / 'hf_cache_3'\n",
    "TITLE_EMB_PATH = CACHE_DIR / 'title_emb_intfloat_multilingual-e5-large.npy'\n",
    "PARA_EMB_PATH  = CACHE_DIR / 'para_emb_intfloat_multilingual-e5-large.npy'\n",
    "\n",
    "print('JSON exists:', JSON_PATH.exists(), JSON_PATH)\n",
    "print('Cache dir exists:', CACHE_DIR.exists(), CACHE_DIR)\n",
    "print('Title emb exists:', TITLE_EMB_PATH.exists())\n",
    "print('Para emb exists :', PARA_EMB_PATH.exists())\n",
    "\n",
    "# 캐시가 없으면 바로 에러 (재생성 금지)\n",
    "if not (TITLE_EMB_PATH.exists() and PARA_EMB_PATH.exists()):\n",
    "    raise FileNotFoundError('임베딩 캐시(.npy)가 없습니다. 재생성을 허용하지 않는 cached-only 모드입니다. 캐시를 먼저 준비해 주세요.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99184304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded standards: 28 | Total paragraphs: 2145\n",
      "Titles: 28 | Paragraphs: 2145\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== JSON 로드 & 인덱스 구성 =====\n",
    "with JSON_PATH.open(encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "docs = data.get('documents', [])\n",
    "total_paras = sum(len(d.get('paragraphs', [])) for d in docs)\n",
    "print('Loaded standards:', len(docs), '| Total paragraphs:', total_paras)\n",
    "\n",
    "title_keys = []\n",
    "title_texts = []\n",
    "title_to_para_indices = defaultdict(list)\n",
    "paragraphs = []\n",
    "\n",
    "for d in docs:\n",
    "    std = d.get('standard_no')\n",
    "    ttl = d.get('title') or ''\n",
    "    src = d.get('source_file') or ''\n",
    "    key = (std, ttl, src)\n",
    "    if key not in title_keys:\n",
    "        title_keys.append(key)\n",
    "        head = (d.get('paragraphs', [{}])[:3])\n",
    "        head_txt = \" \".join([(p.get('text') or '') for p in head])\n",
    "        title_texts.append(f\"{ttl}\\n{src}\\n{head_txt[:1000]}\")\n",
    "    base_idx = len(paragraphs)\n",
    "    for p in d.get('paragraphs', []):\n",
    "        paragraphs.append({\n",
    "            \"std\": std, \"title\": ttl, \"source\": src,\n",
    "            \"page\": p.get('page'), \"para_id\": p.get('para_id'), \"text\": p.get('text') or ''\n",
    "        })\n",
    "        title_to_para_indices[key].append(base_idx); base_idx += 1\n",
    "\n",
    "print('Titles:', len(title_keys), '| Paragraphs:', len(paragraphs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2af7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== 토크나이저 & BM25 =====\n",
    "import re\n",
    "HAN_ENG_NUM = re.compile(r'[가-힣A-Za-z0-9]+', re.UNICODE)\n",
    "STOP = set(['그리고','등','및','또는','그러나','이는','그','이','저','것','수','등의'])\n",
    "\n",
    "def normalize(t: str) -> str:\n",
    "    return t.strip().lower()\n",
    "\n",
    "def tokenize(t: str):\n",
    "    return HAN_ENG_NUM.findall(normalize(t))\n",
    "\n",
    "def filter_tokens(tokens: List[str]) -> List[str]:\n",
    "    return [w for w in tokens if w not in STOP and len(w) > 1]\n",
    "\n",
    "class BM25:\n",
    "    def __init__(self, docs_tokens, k1=1.5, b=0.75):\n",
    "        self.docs_tokens = docs_tokens\n",
    "        self.N = len(docs_tokens)\n",
    "        self.k1 = k1; self.b = b\n",
    "        self.avgdl = sum(len(d) for d in docs_tokens) / max(1, self.N)\n",
    "        self.df = Counter()\n",
    "        for doc in docs_tokens:\n",
    "            for term in set(doc):\n",
    "                self.df[term] += 1\n",
    "        self.idf = {t: math.log(1 + (self.N - df + 0.5)/(df + 0.5)) for t, df in self.df.items()}\n",
    "        self.tf = [Counter(doc) for doc in docs_tokens]\n",
    "\n",
    "    def _score_doc(self, q_tokens, i):\n",
    "        score, tf, dl = 0.0, self.tf[i], len(self.docs_tokens[i])\n",
    "        for term in q_tokens:\n",
    "            idf = self.idf.get(term)\n",
    "            if idf is None: \n",
    "                continue\n",
    "            f = tf.get(term, 0)\n",
    "            if f == 0: \n",
    "                continue\n",
    "            denom = f + self.k1 * (1 - self.b + self.b * dl / self.avgdl)\n",
    "            score += idf * (f * (self.k1 + 1)) / denom\n",
    "        return score\n",
    "\n",
    "    def search(self, q_tokens, topk=50):\n",
    "        scores = []\n",
    "        for i in range(self.N):\n",
    "            s = self._score_doc(q_tokens, i)\n",
    "            if s != 0.0:\n",
    "                scores.append((i, s))\n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return scores[:topk]\n",
    "\n",
    "    def search_subset(self, q_tokens, allowed: set, topk=50):\n",
    "        scores = []\n",
    "        for i in allowed:\n",
    "            s = self._score_doc(q_tokens, i)\n",
    "            if s != 0.0:\n",
    "                scores.append((i, s))\n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return scores[:topk]\n",
    "\n",
    "# BM25 인덱스 (토큰만 필요)\n",
    "title_tokens = [filter_tokens(tokenize(t)) for t in title_texts]\n",
    "bm25_title = BM25(title_tokens)\n",
    "\n",
    "para_texts = [p['text'] for p in paragraphs]\n",
    "para_tokens = [filter_tokens(tokenize(t)) for t in para_texts]\n",
    "bm25_para = BM25(para_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c42c1fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings: (28, 1024) (2145, 1024)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== 캐시 임베딩 로드 (문서 임베딩만) =====\n",
    "title_vecs = np.load(TITLE_EMB_PATH)\n",
    "para_vecs  = np.load(PARA_EMB_PATH)\n",
    "print('Loaded embeddings:', title_vecs.shape, para_vecs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12bebcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fintech/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== 쿼리 임베딩 모델 (문서 임베딩 재생성 없음) =====\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "EMBED_MODEL_NAME = \"intfloat/multilingual-e5-large\"\n",
    "embed_model = SentenceTransformer(EMBED_MODEL_NAME)\n",
    "\n",
    "def embed_queries(texts: List[str]) -> np.ndarray:\n",
    "    inputs = [f\"query: {t}\" for t in texts]\n",
    "    return embed_model.encode(inputs, normalize_embeddings=True, convert_to_numpy=True, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34aa7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== 유틸 & Alias =====\n",
    "def topk_by_cosine(q_vec: np.ndarray, mat: np.ndarray, k: int = 50):\n",
    "    sims = (mat @ q_vec)  # 정규화 가정\n",
    "    idxs = np.argpartition(-sims, kth=min(k, len(sims)-1))[:k]\n",
    "    idxs = idxs[np.argsort(-sims[idxs])]\n",
    "    return [(int(i), float(sims[i])) for i in idxs]\n",
    "\n",
    "ALIAS = {\n",
    "    \"개발비\": [\"개발활동\", \"무형자산\"],\n",
    "    \"감가상각\": [\"정액법\", \"체감잔액법\", \"생산량비례법\"],\n",
    "    \"매출\": [\"수익\"],\n",
    "    \"선수수익\": [\"계약부채\"],\n",
    "    \"미수수익\": [\"계약자산\"],\n",
    "    \"비연결재무제표\": [\"별도재무제표\"],\n",
    "}\n",
    "\n",
    "def expand_query(q: str) -> str:\n",
    "    terms = set()\n",
    "    for k, syns in ALIAS.items():\n",
    "        if k in q:\n",
    "            terms.update(syns)\n",
    "    if terms:\n",
    "        return q + \" \" + \" \".join(sorted(terms))\n",
    "    return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "659096a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== 라우팅 & 검색 (Two-Track + Vector-only Fallback) =====\n",
    "def route_titles(query: str, topn: int = 5, w_bm25=0.4, w_vec=0.6, debug=False):\n",
    "    q_exp = expand_query(query)\n",
    "    qtok = filter_tokens(tokenize(q_exp))\n",
    "    bm_hits = bm25_title.search(qtok, topk=max(topn*6, 30))\n",
    "\n",
    "    qv = embed_queries([q_exp])[0]\n",
    "    vec_hits = topk_by_cosine(qv, title_vecs, k=max(topn*6, 30))\n",
    "    vec_dict = dict(vec_hits)\n",
    "\n",
    "    combined = []\n",
    "    seen = set([i for i,_ in bm_hits])\n",
    "    for i, s_bm in bm_hits:\n",
    "        s_vec = vec_dict.get(i, 0.0)\n",
    "        combined.append((i, w_bm25*s_bm + w_vec*s_vec, s_bm, s_vec))\n",
    "    for i, s_vec in vec_hits:\n",
    "        if i in seen: \n",
    "            continue\n",
    "        combined.append((i, w_vec*s_vec, 0.0, s_vec))\n",
    "\n",
    "    combined.sort(key=lambda x: x[1], reverse=True)\n",
    "    routed = combined[:topn]\n",
    "    if debug:\n",
    "        print(\"[Routing] top candidates:\")\n",
    "        for r in routed:\n",
    "            i, s, sb, sv = r\n",
    "            std, ttl, src = title_keys[i]\n",
    "            print(f\" - {std} | {ttl} | score={s:.3f} (bm25={sb:.3f}, vec={sv:.3f})\")\n",
    "    return routed\n",
    "\n",
    "def hybrid_search_within_titles(query: str, title_idxs: List[int],\n",
    "                                topk_bm25=150, topk_final=12,\n",
    "                                w_bm25=0.4, w_vec=0.6,\n",
    "                                use_reranker: bool = False, rerank_top: int = 20,\n",
    "                                debug=False):\n",
    "    allowed = set()\n",
    "    for ti in title_idxs:\n",
    "        allowed.update(title_to_para_indices[title_keys[ti]])\n",
    "    if debug:\n",
    "        print(f\"[Within] allowed paragraphs: {len(allowed)}\")\n",
    "\n",
    "    if not allowed:\n",
    "        if debug: print(\"[Within] allowed empty -> fallback to global search\")\n",
    "        return global_hybrid_search(query, topk_bm25=200, topk_final=15,\n",
    "                                    w_bm25=w_bm25, w_vec=w_vec,\n",
    "                                    use_reranker=use_reranker, rerank_top=rerank_top)\n",
    "\n",
    "    q_exp = expand_query(query)\n",
    "    qtok = filter_tokens(tokenize(q_exp))\n",
    "    bm_hits = bm25_para.search_subset(qtok, allowed, topk=topk_bm25)\n",
    "\n",
    "    # ★ BM25=0이면 벡터만으로 랭킹\n",
    "    if not bm_hits:\n",
    "        if debug: print(\"[Within] BM25 hits=0 -> vector-only ranking\")\n",
    "        qv = embed_queries([q_exp])[0]\n",
    "        idxs = np.array(list(allowed), dtype=int)\n",
    "        sims = para_vecs[idxs] @ qv                    # sims.shape == (len(idxs),)\n",
    "        order = np.argsort(-sims)[:topk_final]         # order: sims 내부 인덱스\n",
    "        chosen = idxs[order]                           # 전역 문단 인덱스로 매핑\n",
    "\n",
    "        results = [\n",
    "    {**paragraphs[int(j)], \"score\": float(sims[int(i)]), \"bm25\": 0.0, \"vector\": float(sims[int(i)])}\n",
    "    for i, j in zip(order, chosen)\n",
    "                    ]\n",
    "        return results\n",
    "\n",
    "    qv = embed_queries([q_exp])[0]\n",
    "    vec_scores = {i: float(np.dot(para_vecs[i], qv)) for i, _ in bm_hits}\n",
    "\n",
    "    combined = []\n",
    "    for i, s_bm in bm_hits:\n",
    "        s_vec = vec_scores.get(i, 0.0)\n",
    "        combined.append((i, w_bm25*s_bm + w_vec*s_vec, s_bm, s_vec))\n",
    "    combined.sort(key=lambda x: x[1], reverse=True)\n",
    "    combined = combined[:topk_final]\n",
    "\n",
    "    results = [{**paragraphs[i], \"score\": s, \"bm25\": s_bm, \"vector\": s_vec} for (i, s, s_bm, s_vec) in combined]\n",
    "    return results\n",
    "\n",
    "def global_hybrid_search(query: str, topk_bm25=200, topk_final=15,\n",
    "                         w_bm25=0.4, w_vec=0.6, use_reranker=False, rerank_top=20, debug=False):\n",
    "    q_exp = expand_query(query)\n",
    "    qtok = filter_tokens(tokenize(q_exp))\n",
    "    bm_hits = bm25_para.search(qtok, topk=topk_bm25)\n",
    "\n",
    "    if not bm_hits:\n",
    "        if debug: print(\"[Global] BM25 hits=0 -> vector-only ranking\")\n",
    "        qv = embed_queries([q_exp])[0]\n",
    "        sims = np.dot(para_vecs, qv)\n",
    "        order = np.argsort(-sims)[:topk_final]\n",
    "        return [{**paragraphs[i], \"score\": float(sims[i]), \"bm25\": 0.0, \"vector\": float(sims[i])} for i in order]\n",
    "\n",
    "    qv = embed_queries([q_exp])[0]\n",
    "    vec_scores = {i: float(np.dot(para_vecs[i], qv)) for i, _ in bm_hits}\n",
    "\n",
    "    combined = []\n",
    "    for i, s_bm in bm_hits:\n",
    "        s_vec = vec_scores.get(i, 0.0)\n",
    "        combined.append((i, w_bm25*s_bm + w_vec*s_vec, s_bm, s_vec))\n",
    "    combined.sort(key=lambda x: x[1], reverse=True)\n",
    "    combined = combined[:topk_final]\n",
    "    return [{**paragraphs[i], \"score\": s, \"bm25\": s_bm, \"vector\": s_vec} for (i, s, s_bm, s_vec) in combined]\n",
    "\n",
    "def hierarchical_search_two_track(query: str, top_titles=4, **kw):\n",
    "    print(f\"[Query] {query}\")\n",
    "    routed = route_titles(query, topn=top_titles, debug=True)\n",
    "    title_idx = [i for (i, *_ ) in routed]\n",
    "    if not title_idx:\n",
    "        print(\"[Two-Track] routed empty -> GLOBAL\")\n",
    "        return routed, global_hybrid_search(query, **kw)\n",
    "    results = hybrid_search_within_titles(query, title_idx, **kw)\n",
    "    return routed, results\n",
    "\n",
    "def print_titles(routed):\n",
    "    for rank, (i, s, s_bm, s_vec) in enumerate(routed, 1):\n",
    "        std, ttl, src = title_keys[i]\n",
    "        print(f\"{rank:>2}. [{std}] {ttl}  <{src}>  score={s:.3f} (bm25={s_bm:.3f}, vec={s_vec:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e03895a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Q: 개발비 자산 인식 요건은 무엇인가요?\n",
      "[Query] 개발비 자산 인식 요건은 무엇인가요?\n",
      "[Routing] top candidates:\n",
      " - 1103 | 사업결합 | score=2.724 (bm25=5.570, vec=0.827)\n",
      " - 1038 | 무형자산 | score=2.013 (bm25=3.751, vec=0.854)\n",
      " - 1036 | 자산손상 | score=1.526 (bm25=2.577, vec=0.825)\n",
      " - 1023 | 차입원가 | score=1.245 (bm25=1.862, vec=0.834)\n",
      "Top titles:\n",
      " 1. [1103] 사업결합  <K-IFRS_제1103호_사업결합.pdf>  score=2.724 (bm25=5.570, vec=0.827)\n",
      " 2. [1038] 무형자산  <K-IFRS_제1038호_무형자산.pdf>  score=2.013 (bm25=3.751, vec=0.854)\n",
      " 3. [1036] 자산손상  <K-IFRS_제1036호_자산손상.pdf>  score=1.526 (bm25=2.577, vec=0.825)\n",
      " 4. [1023] 차입원가  <K-IFRS_제1023호_차입원가.pdf>  score=1.245 (bm25=1.862, vec=0.834)\n",
      "   1. [1038:5] (무형자산) p.3 score=5.284\n",
      "      이 기준서는 광고, 교육훈련, 사업개시, 연구와 개발활동 등에 대한지출에 적용한다. 연구와 개발활동의 목적은 지식의 개발에 있다.따라서 이러한 활동으로 인하여 물리적 형체(예: 시제품)가 있는 자산이 만들어지더라도, 그 자산의 물리적 요소는 무형자산 요소 즉,그 자산이 갖는 지식에 부수적인 것으로 본다.\n",
      "   2. [1038:57] (무형자산) p.18 score=4.566\n",
      "      다음 사항을 모두 제시할 수 있는 경우에만 개발활동(또는 내부 프로젝트의 개발단계)에서 발생한 무형자산을 인식한다.⑴ 무형자산을 사용하거나 판매하기 위해 그 자산을 완성할 수 있는 기술적 실현가능성⑵ 무형자산을 완성하여 사용하거나 판매하려는 기업의 의도⑶ 무형자산을 사용하거나 판매할 수 있는 기업의 능력⑷ 무형자산이 미래경제적효익을 창출하는 방법. 그 중에서도 특히무형자산의 산출물이나 무형자산 자체를 거래하는 시장이 존재함을 …\n",
      "   3. [1036:7] (자산손상) p.5 score=4.213\n",
      "      문단 8~17에서는 언제 회수가능액을 산정하여야 하는지를 규정한다. 이 요구사항에서는 ‘자산’이라는 용어를 사용하고 있지만 개별자산뿐만 아니라 현금창출단위에도 똑같이 적용한다. 이 기준서의나머지 부분은 다음과 같이 구성되어 있다.⑴ 문단 18~57에서는 회수가능액 측정에 관한 요구사항을 제시한다. 이 요구사항에서도 ‘자산’이라는 용어를 사용하지만 개별자산뿐만 아니라 현금창출단위에도 똑같이 적용한다.⑵ 문단 58~108에서는 손…\n",
      "   4. [1038:31] (무형자산) p.11 score=3.968\n",
      "      무형자산의 개발과 관련한 영업활동 중에는 해당 자산을 경영자가의도하는 방식으로 운영될 수 있는 상태에 이르도록 하는 데 반드시 필요하지는 않은 활동도 있다. 이러한 부수적인 영업활동은 개발활동 전이나 개발활동 중에 발생할 수 있다. 이러한 부수적인 영업활동은 자산을 경영자가 의도하는 방식으로 운영될 수 있는 상태에 이르도록 하는 데 반드시 필요한 것은 아니기 때문에 부수적인영업활동과 관련된 수익과 비용은 즉시 당기손익으로 인식…\n",
      "   5. [1038:124] (무형자산) p.38 score=3.824\n",
      "      무형자산을 재평가금액으로 회계처리하는 경우에는 다음 사항을 공시한다.⑴ 무형자산의 유형별로 다음 사항을 기재한다.㈎ 재평가 시행일㈏ 재평가된 무형자산의 장부금액㈐ 재평가된 무형자산의 유형에 대하여 최초 인식 후에 문단74의 원가모형에 따라 측정하였다면 인식하였을 장부금액⑵ 기초와 기말의 무형자산 관련 재평가잉여금의 금액. 당기 중 변동사항과 주주에 대한 배당의 제한이 있다면 그 내용을 기재한 다.⑶\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== Demo (캐시 사용 QA) =====\n",
    "queries = [\n",
    "    #\"유형자산의 감가상각의 방법에는 무엇이 있나요?\",\n",
    "    \"개발비 자산 인식 요건은 무엇인가요?\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(\"\\n=== Q:\", q)\n",
    "    routed, results = hierarchical_search_two_track(q, top_titles=4,\n",
    "                                                    topk_bm25=150,\n",
    "                                                    topk_final=10,\n",
    "                                                    w_bm25=0.4, w_vec=0.6,\n",
    "                                                    use_reranker=False)\n",
    "    print(\"Top titles:\")\n",
    "    print_titles(routed)\n",
    "    for i, r in enumerate(results[:5], 1):\n",
    "        snippet = r['text'].replace('\\n', ' ')\n",
    "        if len(snippet) > 240: snippet = snippet[:240] + '…'\n",
    "        print(f\"  {i:>2}. [{r['std']}:{r['para_id']}] ({r['title']}) p.{r.get('page','?')} score={r['score']:.3f}\")\n",
    "        print(\"     \", snippet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9acc75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Imports ======\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# ====== 환경변수 세팅 ======\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"   # ← 맨 위에 추가\n",
    "client = OpenAI()  # 이후부터는 client 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f144508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== OpenAI LLM 연결 (환경변수 OPENAI_API_KEY 필요) =====\n",
    "from openai import OpenAI\n",
    "import os, re\n",
    "\n",
    "OPENAI_MODEL = os.environ.get(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def _join_chunks(chunks, max_chars=1800):\n",
    "    buf = []\n",
    "    total = 0\n",
    "    for ch in chunks:\n",
    "        tag = f\"[{ch.get('std')}:{ch.get('para_id')}] {ch.get('title')} p.{ch.get('page','?')}\"\n",
    "        txt = ch.get('text','').strip().replace(\"\\n\",\" \")\n",
    "        entry = tag + \"\\n\" + txt\n",
    "        if total + len(entry) > max_chars:\n",
    "            break\n",
    "        buf.append(entry)\n",
    "        total += len(entry)\n",
    "    return \"\\n\\n\".join(buf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a0ef6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== LLM 재랭킹 + 답변 생성 =====\n",
    "def llm_rerank(query: str, candidates: list, top_m: int = 6):\n",
    "    \"\"\"LLM을 사용해 상위 후보들 중 정답 근거 가능성이 높은 문단을 재선정.\n",
    "    '가끔 1위가 오답, 하위가 정답' 문제를 완화합니다.\"\"\"\n",
    "    # 후보들을 메타+본문으로 정리\n",
    "    packed = []\n",
    "    for c in candidates:\n",
    "        meta = f\"[{c.get('std')}:{c.get('para_id')}] ({c.get('title')}) p.{c.get('page','?')} score={c.get('score',0):.3f}\"\n",
    "        text = c.get('text','').strip().replace(\"\\n\", \" \")\n",
    "        packed.append({\"meta\": meta, \"text\": text})\n",
    "    # 번호와 함께 구성\n",
    "    numbered = []\n",
    "    for i, it in enumerate(packed, 1):\n",
    "        numbered.append(f\"{i}. {it['meta']}\\n{it['text']}\")\n",
    "    blocks = \"\\n\\n\".join(numbered)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "당신은 엄격한 근거 기반 심사관입니다.\n",
    "질문과 후보 문단 목록을 보고, 질문에 가장 정확한 '근거'가 되는 문단 순서 Top-{top_m}만 고르세요.\n",
    "반드시 번호만 콤마로 출력하세요. (예: 7,3,1,5,2)\n",
    "\n",
    "[질문]\n",
    "{query}\n",
    "\n",
    "[후보 문단]\n",
    "{blocks}\n",
    "\"\"\"\n",
    "\n",
    "    chat = openai_client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"너는 사실검증 심사관이다. 허상 없이 근거가 있는 후보만 고른다.\"},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    content = chat.choices[0].message.content.strip()\n",
    "    # 번호 파싱\n",
    "    picked = []\n",
    "    for tok in re.findall(r\"\\d+\", content):\n",
    "        i = int(tok)\n",
    "        if 1 <= i <= len(candidates):\n",
    "            picked.append(i-1)\n",
    "    # 중복 제거, 상위 top_m 유지\n",
    "    order=[]; seen=set()\n",
    "    for i in picked:\n",
    "        if i not in seen:\n",
    "            order.append(i); seen.add(i)\n",
    "    order = order[:top_m] if len(order) >= top_m else order + [i for i in range(len(candidates)) if i not in seen][:top_m-len(order)]\n",
    "    return [candidates[i] for i in order]\n",
    "\n",
    "def answer_with_rag_llm(query: str, *, top_titles=4, topk_bm25=150, topk_final=15, rerank_take=6, w_bm25=0.4, w_vec=0.6, debug=False):\n",
    "    # 1) 1차 검색 (하향식 라우팅 + 문단 하이브리드)\n",
    "    routed, results = hierarchical_search_two_track(query, top_titles=top_titles,\n",
    "                                                    topk_bm25=topk_bm25,\n",
    "                                                    topk_final=topk_final,\n",
    "                                                    w_bm25=w_bm25, w_vec=w_vec,\n",
    "                                                    use_reranker=False)\n",
    "    if debug:\n",
    "        print(\"[RAG] first-stage results:\", len(results))\n",
    "    # 2) LLM 재랭킹 (상위 후보 중 '정답 근거'를 재선정)\n",
    "    chosen = llm_rerank(query, results[:max(10, rerank_take*2)], top_m=rerank_take)\n",
    "    if debug:\n",
    "        print(\"[Rerank] chosen:\", [f\"{c.get('std')}:{c.get('para_id')}\" for c in chosen])\n",
    "    # 3) 컨텍스트 구성\n",
    "    ctx = _join_chunks(chosen, max_chars=2200)\n",
    "    qa_prompt = f\"\"\"\n",
    "당신은 K-IFRS 회계 기준 전문가입니다.\n",
    "아래 [근거 문단]만을 토대로 질문에 간결하고 정확하게 답하세요.\n",
    "근거에 숫자/연도가 있으면 한국식 표기 유지.\n",
    "필요하면 핵심 근거를 한두 문장 인용하되, 문맥을 바꾸지 마세요.\n",
    "\n",
    "[질문]\n",
    "{query}\n",
    "\n",
    "[근거 문단]\n",
    "{ctx}\n",
    "\"\"\"\n",
    "\n",
    "    chat = openai_client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\":\"system\",\"content\":\"너는 한국어로 답변하는 회계 기준 전문가다. 허상 금지, 모르면 모른다고 말한다.\"},\n",
    "            {\"role\":\"user\",\"content\": qa_prompt}\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    answer = chat.choices[0].message.content.strip()\n",
    "    return {\"answer\": answer, \"evidence\": chosen, \"titles\": routed}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5cb611e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Q: 자본변동표에서 2016년 총계는?\n",
      "[Query] 자본변동표에서 2016년 총계는?\n",
      "[Routing] top candidates:\n",
      " - 1016 | 유형자산 | score=0.468 (bm25=0.000, vec=0.780)\n",
      " - 1021 | 환율변동효과 | score=0.467 (bm25=0.000, vec=0.779)\n",
      " - 1008 | 회계정책, 회계추정치 변경과 오류 | score=0.465 (bm25=0.000, vec=0.774)\n",
      " - 1007 | 현금흐름표 | score=0.464 (bm25=0.000, vec=0.774)\n",
      "[RAG] first-stage results: 1\n",
      "[Rerank] chosen: ['1007:60']\n",
      "\n",
      "[Answer]\n",
      " 근거 문단에는 2016년 총계에 대한 정보가 포함되어 있지 않습니다. 따라서 2016년 총계에 대한 답변을 드릴 수 없습니다.\n",
      "\n",
      "[Evidence]\n",
      "- [1007:60] 현금흐름표 p.20\n",
      "\n",
      "=== Q: 개발비 자산 인식 요건은 무엇인가요?\n",
      "[Query] 개발비 자산 인식 요건은 무엇인가요?\n",
      "[Routing] top candidates:\n",
      " - 1103 | 사업결합 | score=2.724 (bm25=5.570, vec=0.827)\n",
      " - 1038 | 무형자산 | score=2.013 (bm25=3.751, vec=0.854)\n",
      " - 1036 | 자산손상 | score=1.526 (bm25=2.577, vec=0.825)\n",
      " - 1023 | 차입원가 | score=1.245 (bm25=1.862, vec=0.834)\n",
      "[RAG] first-stage results: 15\n",
      "[Rerank] chosen: ['1038:57', '1038:5', '1038:31', '1038:124', '1038:3', '1038:74']\n",
      "\n",
      "[Answer]\n",
      " 개발비 자산 인식 요건은 다음과 같습니다:\n",
      "\n",
      "1. 무형자산을 사용하거나 판매하기 위해 그 자산을 완성할 수 있는 기술적 실현가능성.\n",
      "2. 무형자산을 완성하여 사용하거나 판매하려는 기업의 의도.\n",
      "3. 무형자산을 사용하거나 판매할 수 있는 기업의 능력.\n",
      "4. 무형자산이 미래경제적효익을 창출하는 방법, 특히 거래 시장의 존재 또는 내부 사용의 유용성.\n",
      "5. 무형자산의 개발을 완료하고 판매하거나 사용하는 데 필요한 기술적, 재정적 자원 등의 입수가능성.\n",
      "6. 개발과정에서 발생한 무형자산 관련 지출을 신뢰성 있게 측정할 수 있는 기업의 능력.\n",
      "\n",
      "이 모든 요건을 충족해야 개발비를 무형자산으로 인식할 수 있습니다.\n",
      "\n",
      "[Evidence]\n",
      "- [1038:57] 무형자산 p.18\n",
      "- [1038:5] 무형자산 p.3\n",
      "- [1038:31] 무형자산 p.11\n",
      "- [1038:124] 무형자산 p.38\n",
      "- [1038:3] 무형자산 p.2\n",
      "- [1038:74] 무형자산 p.24\n"
     ]
    }
   ],
   "source": [
    "# ===== Demo 2: LLM 기반 재랭크 + 답변 =====\n",
    "demo_queries = [\n",
    "    \"자본변동표에서 2016년 총계는?\",\n",
    "    \"개발비 자산 인식 요건은 무엇인가요?\"\n",
    "]\n",
    "for q in demo_queries:\n",
    "    print(\"\\n=== Q:\", q)\n",
    "    out = answer_with_rag_llm(q, debug=True)\n",
    "    print(\"\\n[Answer]\\n\", out[\"answer\"])\n",
    "    print(\"\\n[Evidence]\")\n",
    "    for e in out[\"evidence\"]:\n",
    "        print(f\"- [{e['std']}:{e['para_id']}] {e['title']} p.{e.get('page','?')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67edcd63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fintech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
